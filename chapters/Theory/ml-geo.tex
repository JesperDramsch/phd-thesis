\section{Machine Learning in Geoscience}
The development of the subfield of deep learning has lead to advances in many scientific fields that are not directly related to the larger field of artificial intelligence. This section focuses on historic use-cases of machine learning models in geoscience and evaluate these in the context of recent advances in deep learning. I provide an overview of supervised and unsupervised methods that have persevered. Furthermore, I distinguish implementations of deep neural network topologies and advanced machine learning methods in geoscientific applications. I go on to investigate where these methods differ from previously unsuccessful attempts at application.

Early on \acf{ml} has been reviewed in a geophysical context. Early publications of \ac{ml} in geoscience apply \acp{nn} to geophysical problems. Particularly seismic processing lends itself to explore \acp{nn} as general functional approximator \citep{Hornik1989-bl}. \citet{McCormack1991-pm} review of the emerging tool of neural networks in 1991. He highlights the application of pattern recognition and is very succinct in describing basic math associated with neural computing. The wording of most parts has changed, as compared to today. Generally this gives a good baseline and McCormack gives a good illustration and overview with examples in well log classification and trace editing. The author summarizes \ac{nn} applications over the 30 year prior to the review and hightlights automated well-log analysis and seismic trace editing. The review comes to a conclusion that these methods show promise as general approximators. 

\citet{Van_der_Baan2000-jz} review the most recent advancements in \acfp{nn} in geophysical applications. It goes into much detail on the neural networks employed in 2000 and the difficulties in building these models and training them. They identify the following subsurface geoscience applications through history: First-break picking, electromagnetics, magnetotellurics, seismic inversion, shear-wave splitting, well log analysis, trace editing, seismic deconvolution, and event classification. The authors evaluate the application of \acp{nn} as subpar to physics-based approaches. The paper concludes that neural networks are too expensive and complex to be of real value in geoscience. Generally, this review focuses very much on exploration geoscienc. 

\citet{Mjolsness2001-fq} review \ac{ml} in a broader context outside of exploration geoscience. They illustrate recent successes of \ac{ml} in analyzing sattelite data and computer robotic geology. The authors include graphical models, \acp{rmm}, \acp{hmm}, and \acp{svm}. They further highlight limitations to vector data, therefore failing richer data such as graphs and text data. Moreover, the authors from NASA JPL go into detail on pattern recognition in automated rovers to identify geological prospects on Mars. They state:
\begin{quote}
“The scientific need for geological feature catalogs has led to multiyear human surveys of Mars orbital imagery yielding tens of thousands of cataloged, characterized features including impact craters, faults, and ridges.” - \citep{Mjolsness2001-fq}
\end{quote}
The authors evaluate how especially the introduction of \ac{svm} have allowed the identification of geomorphological features without modeling the processes behind. Further they mention recurrent neural networks in gene expression data, a method that has experienced a renaissance in deep learning.

\subsection{History of Machine Learning in Geoscience}
Machine learning, statistical, and mathematical models have a long history in geoscience. Markov models have been used to describe sedimentology as early as the 1970s \citep{schwarzacher1972semi} and the use of k-means in geoscience as early as 1964 \citep{preston1964fourier}. In geophysics applications of \acp{nn} to perform seismic devonvolution were published in the 1980s \citet{Zhao1988-hu}. Early tree-based methods were chiefly used in economic geology and exploration geophysics for prospectivity mapping with \acfp{dt} \citep{newendorp1976decision,reddy1991decisiontree}. \ac{svm} has early on been applied to AVO classification \cite{Li2004-fk} and geological facies delineation for hydrological analysis \citep{Tartakovsky2004-ml}. This thesis mostly focuses on the application of \acp{nn}, however, we give an additional overview of geoscientific applications of shallow \ac{ml}.

\subsubsection{Machine Learning Applications in Geoscience}
Early applications of neural networks were prominent in seismic data processing and analysis. \citet{Zhao1988-hu} use a \ac{nn} to perform seismic deconvolution early on. An application of seismic inversion with \acp{nn} was published by \citet{Roth1994-na}. Early \ac{ml}-based electromagnetic geophysics performs subsurface localization \citep{Poulton1992-ft} and magnetotelluric inversion via Hopfield \acp{nn} \citep{Zhang1997-yp}. \citet{Feng1998-ck} applied \ac{nn} to model geomechanical microfractures in triaxial compression tests. Interestingly, \citet{Legget1996-nk} used a combination of \acf{som} and back-propagation \acp{nn} that function similar to modern day \acfp{cnn} to perform 3D horizon tracking \citep{Leggett2003-vq}. With the recent \ac{dl} explosion, papers on \acf{asi} have gotten very popular, given the similarity to 2D segmentation tasks (cf. \cref{tab:geonn}).

Modern \acp{cnn} have been applied to a wide variety of geoscience problems including seismic inversion \citep{Araya-Polo2018-xf}, and applications in seismology such as first break picking \citep{Ross2018-kt} or event classification \citep{Zhu2018-ma,Ross2018-rx}. In 2017 the application of \aclp{gan} in geoscience in digital rock modelling \citep{Mosser2017-ml}, geostatistical modelling \citep{Laloy2017-lp} and seismic inversion \citep{Mosser2018-nf,Mosser2018-hm}. Further applications extend to geochemical anomaly detection \citep{Zuo2018-kl} using \acfp{vae} and hydrogeological modelling \citep{Sahoo2017-xt}. Common applications include \ac{gpr}, various applications in seismic processing, analysis and interpretation, as well as seismology, listed in detail in \cref{tab:geonn}.

Recently, some applications of \aclp{dnn} to predict earthquake aftershocks \citep{devries2018deep} has been called into question by the publication \citetitle{mignan2019one} \citep{mignan2019one}. Criticizing the original publication for over-engineering a problem that is well-defined on less input data. A common critique of \ac{ml} and big data analytics by classical statistics and rigorous data science \citep{mignan2019deeper}.

\aclp{svm} have early-on been used for seismic data analysis \citep{Li2004-fk} and the popular approach of \acl{asi} \citep{Liu2015-pf,di2017seismic,Mardan2017-vr}. Additionally, early applications include seismological volcanic tremor classification \citep{Masotti2006-fi,Masotti2008-tu} and \acl{gpr} analysis \citep{pasolli2009automatic, Xie2013-fh}. The 2016 SEG \ac{ml} challenge was introduced using a \ac{svm} baseline \citep{Hall2016-xh}, with several other investigations into \acp{svm} for well log analysis \citep{anifowose2017carbonate, Cate2018-mb, Gupta2018-ut, Saporetti2018-sq}. Moreover, this method has been applied to seismology for event classification \citep{Malfante2018-yl} and magnitude determination \citep{Ochoa2018-wp}. Considering the strong mathematical foundation of \acp{svm}, they have been applied to applied to a variety of geoscience problems such as microseismic event classification \citep{Zhao2017-rx}, seismic well ties \citep{Chaki2018-mr}, landslide susceptibility \citep{Marjanovic2011-ot,Ballabio2012-xv}, and digital rocks \citep{Ma2012-qo}.

\aclp{rf} and other tree-based methods, including gradient boosting, have gained increased attention with the implementation into scikit-learn \citep{sklearn_api}. Similar to \ac{nn} applications, \acp{rf} are applied to \acl{asi} \citep{Guillen2015-re} with limited success. Seismological applications including localization \citep{Dodge2016-ah}, event classification in volcanic tremors \citep{Maggi2017-mr} and slow slip analysis \citep{Hulbert2018-xe}. Further geomechanical applications include fracture modelling \citep{Valera2017-yl} and fault failure prediction \citep{RouetLeduc2017-li,RouetLeduc2018-vd}. Gradint Boosted Trees were the most performant models in the 2016 SEG \ac{ml} challenge \citep{Hall2017-fk} for well-log analysis, propelling a variety of publications in facies prediction \citep{Bestagini2017-nh,Blouin2017-gt,Cate2018-mb,Saporetti2018-sq}. Moreover, random forests were applied to detect reservoir property changes from 4D seismic data \citep{Cao2017-gp}.

Furthermore, various methods have been applied to various doomains. \aclp{hmm} were used on seismological event classification \citep{Ohrnberger2001-cq,Beyreuther2008-mz, Bicego2013-ox}, well-log classification \citep{Jeong2014-jy, Wang2017-gi}, and landslide detection from seismic monitoring \citep{Dammeier2016-mf}. \ac{knn} has been used for well-log analysis \citep{Cate2017-na,Saporetti2018-sq}, seismic well ties \citep{Wang2017-lw} combined with \ac{dtw} and fault extraction in seismic interpretation \citep{hale2013methods}. The unsupervised k-means equivalent has been applied to seismic interpretation \citep{Di2017-qn}, ground motion model validation \citep{Khoshnevis2018-wq}, and seismic velocity picking \citep{Wei2018-nm}. The biologically inspired ant-tracking algorithm is commonly used for seismic interpretation \citep{Pedersen2002-de} and in conjunction with \acp{nn} \citep{Zheng2014-il}. Graph modelling has been applied to seismology in modelling the earthquake parameters \citep{Kuehn2011-tv}, basin modelling \citep{Martinelli2013-ch}, seismic interpretation \citep{Ferreira2018-gr} and flow modelling in \acp{dfn} \citep{Karra2018-of}.

\acl{ml} methods have been applied to various disciplines in geoscience, with the main objective increasing predictive capability or automating expensive and labour-intensive tasks. These approaches rely on diverse labelled data sets and are prone to common problems of \ac{ml} in geoscience inherent to geoscientific data and the implication of cost of data acquisition.

\subsection{Challenges of machine learning in geoscience}
Statistical methods and machine learning are based on several assumptions and demand some pre-requisites that can cause problems in geoscience. These include the assumption that data is \acf{iid} and the pre-requisite of a ground truth for supervised learning. In this section I discuss these challenges and present some approaches to solve these problems.

% Inherent properties of data
% Talk about IID in geoscience
% imbalanced data
% heterogeneities in geoscience and ml - > distributions

Geoscientific data is known to be very heterogeneous across vastly different scales (mm to km), which makes the system hard to model in general. Additionaly, a core assumption of statistics \ac{iid} is usually in conflict with the geological processes. Regionality of depositional patterns violates the assumption data is identically distributed and time-dependent processes, such as systems tracts in sedimentology, violate the independence assumption of individual samples. This fact has to be taken into account, when choosing models and sampling methods. Expanding on the sedimentology example, the time-varying deposition can be modelled as markovian \citep{schwarzacher1972semi}, instead of treating samples as strictly independent. Moreover, sampling of any data needs to honour the clustering in distribution of samples. Stratified sampling \citep{kish1965survey} can alleviate sampling bias. Additionally, stratified sampling can address the problem that geoscientific data often contains imbalanced data. Imbalanced data implies that the number of samples per class in the label data set is not uniformly distributed. These imbalances can stem from the fact that different depositional regimes cause different thicknesses in the stratigraphic columns, for example commonly leaving thicker sand columns and fine shale layers. Alternatively, imbalances can stem from the data collection process itself, be it that seismic data does not adequately image variations below 10~m or the location where data is collected, considering that e.g. E\&P companies do not choose the location for 3D seismic data acquisition randomly. This imbalance due to non-uniform sampling can not be solved by sampling itself, as the bias is implicit in the available data itself. 

% measurements and data
% availability of data
% Talk about no ground truth


In the computer vision community hand-labelled data sets like ImageNet, CIFAR, and PASCAL-VOC are openly available, which catalyzed the developed new architectures and approaches in deep learning. Geoscientific data is often expensive to acquire and companies are reluctant to make data available, less even for processed or interpreted data. Early machine learning workshops often showed results on the open Dutch F3 dataset, however, national data repositories have started to change this approach to foster innovation. With data becoming more available, the next problem is the lack of ground truth. Obtaining accurate labels for seismic data is impossible, as any inversion process is non-unique and digging is not practical. In other imaging-based fields (e.g. radiology) that rely on interpretation of imaging results, studies investigate both interinterpreter variations, by making several interpretations available and intra-interpreter variability by re-interpreting the dataset after a set time interval \citep{macerlean2013, alikhassi2018comparison,al2010inter}. Additionally, simulations provide a ground truth, but can implicitly include modelling assumptions in the data or commit the inverse crime \citep{wirgin2004inverse}. The inverse crime presents the problem of modelling and inverting data with the same theoretical ingredients.

% Talk about metrics
% Seismic dynamic range (clip = .97)
% noise

In geophysics itself, seismic data presents a unique challenge to computer vision problems, in that the \~3\textsuperscript{rd} percentile of amplitudes occupy large parts of the dynamic range. Displays of seismic data usually clip amplitudes to make most of the seismic amplitude content visible, this has also proven to be a viable preprocessing step before feeding seismic data to computer vision systems, such as convolutional neural networks. Machine learning systems have been known to be vulnerable to noise. This noise can be physical noise (i.e. low SNR) for simpler models or adversarial attacks that reverse engineer more complex models to fool said model. Adversarial attacks include a one-pixel attack on ImageNet classifiers \citep{su2019one}, humanly imperceptible noise \citep{goodfellow2014explaining}, or physical stickers \citep{brown2017adversarial}. In addition, geological data contains regions of geological interest and regions that are inconsequential, this has not been represented in metrics adequately \citep{purves2019towards}.

% solutions?
% talk about transfer learning (myth of big data)
% Self-supervision
% multi+task learning

Realistically, the sparsity of labelled ground truth data can be addressed in different ways. In the case when labels are available but not abundant, transfer learning of highly generalizable models like VGG-16 can be fine-tuned to seismic data. The VGG-16 architecture can also be included in U-Nets as a decoder to leverage the benefits of transfer learning in semantic segmentation tasks \citep{dramsch2018deep}. Moreover, weakly-supervised training can preform label propagation of labeled sections of the full data set to unlabeled sets. Unsupervised or self-supvervised training can be applicable, where no reliable ground truth is available, but a desired operation on the data is known or an internal structure of the data can be exploited \citep{dramsch20193dwarping}. Additionally, multi-task learning has been shown to be able to stabilize network performance in \acl{nlp} \citep{liu2019multi} and \acl{rl} \citep{yu2019meta}.

% explainability and complexity

One caveat of increasingly performant but complex machine learning models is stakeholder buy-in or trust. These issues can be adressed, by benchmarking complex models against simpler models and physics-based solutions. Additionally, model explainability has become an important topic of research \citep{NIPS2017_7062}. \citet{ribeiro2016should} introduce the \acf{lime} method to gain insight into black-box models for individual samples. \citet{shrikumar2017learning} propose a method to propagate activations in \aclp{dnn}. The Grad-CAM algorithm \citep{selvaraju2017grad} provides attention-like explanations for \acp{cnn} in computer vision tasks, to explain the main contributors to a classification output. Additionally, strict adherence to train-val-test splits and exploration of biases within the data can be essential. Considering these caveats and best practices in \acl{ml} for geosciences, the following chapter introduces the main chapters of this thesis. 