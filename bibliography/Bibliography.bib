@ARTICLE{Van_der_Baan2000-jz,
  title     = {Neural networks in geophysical applications},
  author    = {van der Baan, M and Jutten, C},
  abstract  = {Neural networks are increasingly popular in geophysics. Because
               they are universal approximators, these tools can approximate
               any continuous function with an arbitrary precision. Hence, they
               may yield important contributions to finding solutions to a
               variety of geophysical applications. However, knowledge of many
               methods and techniques recently developed to increase the
               performance and to facilitate the use of neural networks does
               not seem to be widespread in the geophysical community.
               Therefore, the power of these tools has not yet been explored to
               their full extent. In this paper, techniques are described for
               faster training, better overall performance, i.e.,
               generalization, and the automatic estimation of network size and
               architecture.},
  journal   = {Geophysics},
  publisher = {Society of Exploration Geophysicists},
  volume    =  65,
  number    =  4,
  pages     = {1032--1047},
  month     =  jul,
  year      =  2000,
  url       = {https://doi.org/10.1190/1.1444797},
  issn      = {0016-8033},
  doi       = {10.1190/1.1444797}
}

@article{kohonen1982self,
  title={Self-organized formation of topologically correct feature maps},
  author={Kohonen, Teuvo},
  journal={Biological cybernetics},
  volume={43},
  number={1},
  pages={59--69},
  year={1982},
  publisher={Springer}
}

@article{hochreiter1991untersuchungen,
  title={Untersuchungen zu dynamischen neuronalen Netzen},
  author={Hochreiter, Sepp},
  journal={Diploma, Technische Universit{\"a}t M{\"u}nchen},
  volume={91},
  number={1},
  year={1991}
}

@ARTICLE{McCormack1991-pm,
  title     = {Neural computing in geophysics},
  author    = {McCormack, M},
  abstract  = {The 17th century philosopher?mathematician Rene Descartes
               offered the statement ?Cogito, ergo sum? or ?I think, therefore
               I am? as proof of his personal existence. While modern computers
               using artificial intelligence technologies cannot match
               Descartes? profundity, they are beginning to mimic some
               endeavors previously thought to be completely restricted to the
               human domain. Neural computing is one area of artificial
               intelligence that has recently left the laboratory and is being
               used to solve real and practical problems in geophysics and
               geology. In this article, we explore the history, operation, and
               current status of neural computing, and discuss some
               applications of this new technology.},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  10,
  number    =  1,
  pages     = {11--15},
  month     =  jan,
  year      =  1991,
  url       = {https://doi.org/10.1190/1.1436771},
  issn      = {1070-485X},
  doi       = {10.1190/1.1436771}
}

@article{terzaghi1965sources,
  title={Sources of error in joint surveys},
  author={Terzaghi, Ruth D},
  journal={Geotechnique},
  volume={15},
  number={3},
  pages={287--304},
  year={1965},
  publisher={Thomas Telford Ltd}
}

@article{laake2014structural,
  title={Structural interpretation in color—A new RGB processing application for seismic data},
  author={Laake, Andreas},
  journal={Interpretation},
  volume={3},
  number={1},
  pages={SC1--SC8},
  year={2014},
  publisher={Society of Exploration Geophysicists and American Association of Petroleum~…}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={618--626},
  year={2017}
}

@incollection{NIPS2017_7062,
title = {A Unified Approach to Interpreting Model Predictions},
author = {Lundberg, Scott M and Lee, Su-In},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {4765--4774},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf}
}

@inproceedings{shrikumar2017learning,
  title={Learning important features through propagating activation differences},
  author={Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3145--3153},
  year={2017},
  organization={JMLR. org}
}

@article{brown2017adversarial,
  title={Adversarial patch},
  author={Brown, Tom B and Man{\'e}, Dandelion and Roy, Aurko and Abadi, Mart{\'\i}n and Gilmer, Justin},
  journal={arXiv preprint arXiv:1712.09665},
  year={2017}
}

@inproceedings{ribeiro2016should,
  title={Why should i trust you?: Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016},
  organization={ACM}
}

@article{liu2019multi,
  title={Multi-task deep neural networks for natural language understanding},
  author={Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng},
  journal={arXiv preprint arXiv:1901.11504},
  year={2019}
}

@article{macerlean2013,
author = {McErlean, Aoife and Panicek, David M. and Zabor, Emily C. and Moskowitz, Chaya S. and Bitar, Richard and Motzer, Robert J. and Hricak, Hedvig and Ginsberg, Michelle S.},
title = {Intra- and Interobserver Variability in CT Measurements in Oncology},
journal = {Radiology},
volume = {269},
number = {2},
pages = {451-459},
year = {2013},
doi = {10.1148/radiol.13122665},
URL = { https://doi.org/10.1148/radiol.13122665}
}

@article{yu2019meta,
  title={Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.10897},
  year={2019}
}

@inproceedings{purves2019towards,
  title={Towards Subsurface ML Metrics},
  author={Purves, S and Alaei, B and Lolis, D},
  booktitle={81st EAGE Conference and Exhibition 2019 Workshop Programme},
  year={2019}
}

@article{su2019one,
  title={One pixel attack for fooling deep neural networks},
  author={Su, Jiawei and Vargas, Danilo Vasconcellos and Sakurai, Kouichi},
  journal={IEEE Transactions on Evolutionary Computation},
  year={2019},
  publisher={IEEE}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@article{alikhassi2018comparison,
  title={Comparison of inter-and intra-observer variability of breast density assessments using the fourth and fifth editions of Breast Imaging Reporting and Data System},
  author={Alikhassi, Afsaneh and Gourabi, Hamed Esmaili and Baikpour, Masoud},
  journal={European journal of radiology open},
  volume={5},
  pages={67--72},
  year={2018},
  publisher={Elsevier}
}

@article{al2010inter,
  title={Inter-and intraobserver variation between radiologists in the detection of abnormal parenchymal lung changes on high-resolution computed tomography},
  author={Al-Khawari, Hanaa and Athyal, Reji P and Al-Saeed, Osama and Sada, Prio N and Al-Muthairi, Sana and Al-Awadhi, Adel},
  journal={Annals of Saudi medicine},
  volume={30},
  number={2},
  pages={129--133},
  year={2010},
  publisher={King Faisal Specialist Hospital \& Research Centre}
}

@article{wirgin2004inverse,
  title={The inverse crime},
  author={Wirgin, Armand},
  journal={arXiv preprint math-ph/0401050},
  year={2004}
}

@book{kish1965survey,
  title={Survey sampling},
  author={Kish, Leslie},
  number={04; HN29, K5.},
  year={1965}
}

@ARTICLE{Valera2017-yl,
  title         = {Machine learning for graph-based representations of
                   three-dimensional discrete fracture networks},
  author        = {Valera, Manuel and Guo, Zhengyang and Kelly, Priscilla and
                   Matz, Sean and Cantu, Vito Adrian and Percus, Allon G and
                   Hyman, Jeffrey D and Srinivasan, Gowri and Viswanathan, Hari
                   S},
  abstract      = {Structural and topological information play a key role in
                   modeling flow and transport through fractured rock in the
                   subsurface. Discrete fracture network (DFN) computational
                   suites such as dfnWorks are designed to simulate flow and
                   transport in such porous media. Flow and transport
                   calculations reveal that a small backbone of fractures
                   exists, where most flow and transport occurs. Restricting
                   the flowing fracture network to this backbone provides a
                   significant reduction in the network's effective size.
                   However, the particle tracking simulations needed to
                   determine the reduction are computationally intensive. Such
                   methods may be impractical for large systems or for robust
                   uncertainty quantification of fracture networks, where
                   thousands of forward simulations are needed to bound system
                   behavior. In this paper, we develop an alternative network
                   reduction approach to characterizing transport in DFNs, by
                   combining graph theoretical and machine learning methods. We
                   consider a graph representation where nodes signify
                   fractures and edges denote their intersections. Using random
                   forest and support vector machines, we rapidly identify a
                   subnetwork that captures the flow patterns of the full DFN,
                   based primarily on node centrality features in the graph.
                   Our supervised learning techniques train on
                   particle-tracking backbone paths found by dfnWorks, but run
                   in negligible time compared to those simulations. We find
                   that our predictions can reduce the network to approximately
                   20\% of its original size, while still generating
                   breakthrough curves consistent with those of the original
                   network.},
  month         =  may,
  year          =  2017,
  url           = {http://arxiv.org/abs/1705.09866},
  archivePrefix = {arXiv},
  eprint        = {1705.09866},
  primaryClass  = {physics.geo-ph},
  arxivid       = {1705.09866}
}

@ARTICLE{Zuo2011-so,
  title     = {Support vector machine: A tool for mapping mineral prospectivity},
  author    = {Zuo, Renguang and Carranza, Emmanuel John M},
  abstract  = {In this contribution, we describe an application of support
               vector machine (SVM), a supervised learning algorithm, to
               mineral prospectivity mapping. The free R package e1071 is used
               to construct a SVM with sigmoid kernel function to map
               prospectivity for Au deposits in western Meguma Terrain of Nova
               Scotia (Canada). The SVM classification accuracies of `deposit'
               are 100\%, and the SVM classification accuracies of the
               `non-deposit' are greater than 85\%. The SVM classifications of
               mineral prospectivity have 5--9\% lower total errors, 13--14\%
               higher false-positive errors and 25--30\% lower false-negative
               errors compared to those of the WofE prediction. The prospective
               target areas predicted by both SVM and WofE reflect,
               nonetheless, controls of Au deposit occurrence in the study area
               by NE--SW trending anticlines and contact zones between
               Goldenville and Halifax Formations. The results of the study
               indicate the usefulness of SVM as a tool for predictive mapping
               of mineral prospectivity.},
  journal   = {Comput. Geosci.},
  publisher = {Elsevier},
  volume    =  37,
  number    =  12,
  pages     = {1967--1975},
  month     =  dec,
  year      =  2011,
  url       = {http://www.sciencedirect.com/science/article/pii/S0098300410003249},
  keywords  = {Supervised learning algorithms; Kernel functions;
               Weights-of-evidence; Turbidite-hosted Au; Meguma Terrain},
  issn      = {0098-3004},
  doi       = {10.1016/j.cageo.2010.09.014}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ziyong2018-gz,
  title     = {Fuzzy fusion of geological and geophysical data for mapping
               hydrocarbon potential based on {GIS}},
  author    = {Ziyong, Z and Hangyu, Y and Xiaodan, G},
  abstract  = {Effective fusion of multiple data, including geographical,
               geological, geophysical, geochemical and dynamic data for
               hydrocarbon potential mapping, involves both a fusion algorithm
               and a convenient modelling platform. In this study, fuzzy logic
               and a geographical information system (GIS) are used to fuse
               geological and geophysical interpretations in mapping the gas
               potential of the Kazakhstan Marsel Territory Carboniferous
               system based on the assumed gas-accumulation model. Nonlinear
               membership functions are used to …},
  journal   = {Pet. Geosci.},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=91266},
  issn      = {1354-0793}
}

@ARTICLE{Zuo2018-kl,
  title     = {Big Data Analytics of Identifying Geochemical Anomalies
               Supported by Machine Learning Methods},
  author    = {Zuo, Renguang and Xiong, Yihui},
  abstract  = {Big data analytics brings a novel way for identifying
               geochemical anomalies in mineral exploration because it involves
               processing of the whole geochemical dataset to reveal
               statistical correlations between geochemical patterns and known
               mineralization. Traditional methods of processing exploration
               geochemical data mainly involve the identification of positive
               geochemical anomalies related to mineralization, but ignore
               negative geochemical anomalies. Therefore, the identified
               geochemical anomalies do not completely reflect the sought
               geochemical signature of mineralization, leading to uncertainty
               in geochemical prospecting. In this study, data for 39
               geochemical variables from a regional stream sediment
               geochemical survey of southwest Fujian Province of China were
               subjected to big data analytics for identifying geochemical
               anomalies related to skarn-type Fe polymetallic mineralization
               through deep autoencoder network. The receiver operating
               characteristic (ROC) and areas under curve (AUC) were applied to
               evaluate the performance of big data analytics. The AUC of the
               anomaly map obtained using all the geochemical variables is
               larger than the AUC of the anomaly map obtained using only five
               selected elements known to be associated with the mineralization
               (i.e., Fe2O3, Cu, Pb, Zn, Mn). This indicates that big data
               analytics, with the support of machine learning methods, is a
               powerful tool for identifying multivariate geochemical anomalies
               related to mineralization.},
  journal   = {Nat. Resour. Res.},
  publisher = {Springer},
  volume    =  27,
  number    =  1,
  pages     = {5--13},
  month     =  jan,
  year      =  2018,
  url       = {https://doi.org/10.1007/s11053-017-9357-0},
  issn      = {1520-7439, 1573-8981},
  doi       = {10.1007/s11053-017-9357-0}
}

@article{arjovsky2017wasserstein,
  title={Wasserstein gan},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  journal={arXiv preprint arXiv:1701.07875},
  year={2017}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{hinton2006reducing,
  title={Reducing the dimensionality of data with neural networks},
  author={Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
  journal={science},
  volume={313},
  number={5786},
  pages={504--507},
  year={2006},
  publisher={American Association for the Advancement of Science}
}

@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}

@article{hinton2012improving,
  title={Improving neural networks by preventing co-adaptation of feature detectors},
  author={Hinton, Geoffrey E and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R},
  journal={arXiv preprint arXiv:1207.0580},
  year={2012}
}

@inproceedings{zoph2018learning,
  title={Learning transferable architectures for scalable image recognition},
  author={Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8697--8710},
  year={2018}
}

@article{tan2019efficientnet,
  title={EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  author={Tan, Mingxing and Le, Quoc V},
  journal={arXiv preprint arXiv:1905.11946},
  year={2019}
}

@inproceedings{real2019regularized,
  title={Regularized evolution for image classifier architecture search},
  author={Real, Esteban and Aggarwal, Alok and Huang, Yanping and Le, Quoc V},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={4780--4789},
  year={2019}
}

@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@inproceedings{zhu2017unpaired,
  title={Unpaired image-to-image translation using cycle-consistent adversarial networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2223--2232},
  year={2017}
}

@ARTICLE{Zhu2018-ma,
  title         = {{PhaseNet}: A {Deep-Neural-Network-Based} Seismic Arrival
                   Time Picking Method},
  author        = {Zhu, Weiqiang and Beroza, Gregory C},
  abstract      = {As the number of seismic sensors grows, it is becoming
                   increasingly difficult for analysts to pick seismic phases
                   manually and comprehensively, yet such efforts are
                   fundamental to earthquake monitoring. Despite years of
                   improvements in automatic phase picking, it is difficult to
                   match the performance of experienced analysts. A more subtle
                   issue is that different seismic analysts may pick phases
                   differently, which can introduce bias into earthquake
                   locations. We present a deep-neural-network-based
                   arrival-time picking method called ``PhaseNet'' that picks
                   the arrival times of both P and S waves. Deep neural
                   networks have recently made rapid progress in feature
                   learning, and with sufficient training, have achieved
                   super-human performance in many applications. PhaseNet uses
                   three-component seismic waveforms as input and generates
                   probability distributions of P arrivals, S arrivals, and
                   noise as output. We engineer PhaseNet such that peaks in
                   probability provide accurate arrival times for both P and S
                   waves, and have the potential to increase the number of
                   S-wave observations dramatically over what is currently
                   available. This will enable both improved locations and
                   improved shear wave velocity models. PhaseNet is trained on
                   the prodigious available data set provided by
                   analyst-labeled P and S arrival times from the Northern
                   California Earthquake Data Center. The dataset we use
                   contains more than seven million waveform samples extracted
                   from over thirty years of earthquake recordings. We
                   demonstrate that PhaseNet achieves much higher picking
                   accuracy and recall rate than existing methods.},
  month         =  mar,
  year          =  2018,
  url           = {http://arxiv.org/abs/1803.03211},
  archivePrefix = {arXiv},
  eprint        = {1803.03211},
  primaryClass  = {physics.geo-ph},
  arxivid       = {1803.03211}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Zheng2014-il,
  title     = {Multi-attributes and neural network-based fault detection in
               {3D} seismic interpretation},
  author    = {Zheng, Z H and Kavousi, P and Di, H B},
  abstract  = {Article Preview Article Preview Seismic attributes have been
               widely used in seismic object detection. While no unique
               attribute is expected to perfectly identify the targeted object,
               various attributes contributing to the same purpose should be
               utilized simultaneously when performing detection. Artificial
               neural network has been successfully applied in seismic object
               detection by combining multiple attributes into a single
               object-sensitive attribute. An optimized neural network fault
               detection approach was introduced by a case study from …},
  journal   = {Adv. Mat. Res.},
  publisher = {Trans Tech Publ},
  year      =  2014,
  url       = {https://www.scientific.net/AMR.838-841.1497},
  issn      = {1022-6680}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Zhu2017-lz,
  title     = {Inversion of the permeability of a tight gas reservoir with the
               combination of a deep Boltzmann kernel extreme learning machine
               and nuclear magnetic resonance …},
  author    = {Zhu, L and Zhang, C and Wei, Y and Zhou, X and Huang, Y and
               Zhang, C},
  abstract  = {In view of the low accuracy of the existing nuclear
               magnetic-resonance (NMR) logging permeability model in tight
               sandstone reservoirs, we derive a relationship between the NMR T
               2 spectrum and permeability based on the transverse relaxation
               theory of NMR and the Kozeny-Carman equation. We determined the
               reasons for the low accuracy of the model through the
               theoretical analysis. We have developed the deep Boltzmann
               kernel extreme learning machine (DBKELM) to improve the
               deep-learning algorithm and to predict the …},
  journal   = {Interpretation},
  publisher = {library.seg.org},
  year      =  2017,
  url       = {https://library.seg.org/doi/abs/10.1190/int-2016-0188.1}
}

@INCOLLECTION{Zhao2017-rx,
  title     = {Using supervised machine learning to distinguish microseismic
               from noise events},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2017},
  author    = {Zhao, Z and Gross, L},
  abstract  = {Many noise sources that are characterized by an abrupt amplitude
               increasing give the appearance of genuine microseismic events.
               This includes human walking, passing vehicles and explosions.
               Some of them cannot be muted by bandpass filtering which is
               commonly applied as pre-processing technique for raw
               microseismic data processing. Due to the similarities of a
               genuine microseismic and unwanted noise events in their
               waveforms noise events tend to trigger the event detection
               threshold and be picked as a microseismic events in common event
               detection methods such as STA/LTA. In this paper, we have
               demonstrated how to use a classification algorithm known as
               support vector machine (SVM) to distinguish genuine microseismic
               from noise events. A total of 71 time-domain and
               frequency-domain features have been extracted and used to train
               the initial predictive model. Only 16 of them prove to be
               relevant as classifiers by neighborhood component analysis and
               have been used to train the final model. The optimized final
               model trained by Gaussian kernel has demonstrated the potential
               to accurately distinguish genuine microseismic events from noise
               events with a prediction accuracy of about 95\% in microseismic
               event classification and almost 92\% in noise event
               classification. We have also compared the performances of
               different SVM kernel functions in terms of training time and
               prediction accuracy. In all these applications the Gaussian
               kernel based SVM training took shortest training time but higher
               prediction accuracy. Presentation Date: Tuesday, September 26,
               2017 Start Time: 10:10 AM Location: Exhibit Hall C/D
               Presentation Type: POSTER},
  publisher = {Society of Exploration Geophysicists},
  pages     = {2918--2923},
  series    = {SEG Technical Program Expanded Abstracts},
  month     =  aug,
  year      =  2017,
  url       = {https://doi.org/10.1190/segam2017-17727697.1},
  doi       = {10.1190/segam2017-17727697.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Zhao2015-jg,
  title     = {A comparison of classification techniques for seismic facies
               recognition},
  author    = {Zhao, Tao and Jayaram, Vikram and Roy, Atish and Marfurt, Kurt J},
  abstract  = {During the past decade, the size of 3D seismic data volumes and
               the number of seismic attributes have increased to the extent
               that it is difficult, if not impossible, for interpreters to
               examine every seismic line and time slice. To address this
               problem, several seismic facies classification algorithms
               including k-means, self-organizing maps, generative topographic
               mapping, support vector machines, Gaussian mixture models, and
               artificial neural networks have been successfully used to
               extract features of geologic interest from multiple volumes …},
  journal   = {Interpretation},
  publisher = {GeoScienceWorld},
  volume    =  3,
  number    =  4,
  pages     = {SAE29--SAE58},
  month     =  nov,
  year      =  2015,
  url       = {https://pubs.geoscienceworld.org/interpretation/article-abstract/3/4/SAE29/75900},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2015-0044.1}
}

@ARTICLE{Zhao2017-gv,
  title     = {Constraining self-organizing map facies analysis with
               stratigraphy: An approach to increase the credibility in
               automatic seismic facies classification},
  author    = {Zhao, T and Li, F and Marfurt, K},
  abstract  = {AbstractPattern recognition-based seismic facies analysis
               techniques are commonly used in modern quantitative seismic
               interpretation. However, interpreters often treat techniques
               such as artificial neural networks and self-organizing maps
               (SOMs) as a ?black box? that somehow correlates a suite of
               attributes to a desired geomorphological or geomechanical
               facies. Even when the statistical correlations are good, the
               inability to explain such correlations through principles of
               geology or physics results in suspicion of the results. The most
               common multiattribute facies analysis begins by correlating a
               suite of candidate attributes to a desired output, keeping those
               that correlate best for subsequent analysis. The analysis then
               takes place in attribute space rather than (x, y, and z) space,
               removing spatial trends often observed by interpreters. We add a
               stratigraphy layering component to a SOM model that attempts to
               preserve the intersample relation along the vertical axis.
               Specifically, we use a mode decomposition algorithm to capture
               the sedimentary cycle pattern as an ?attribute.? If we correlate
               this attribute to the training data, it will favor SOM facies
               maps that follow stratigraphy. We apply this workflow to a
               Barnett Shale data set and find that the constrained SOM facies
               map shows layers that are easily overlooked on traditional
               unconstrained SOM facies map.},
  journal   = {Interpretation},
  publisher = {Society of Exploration Geophysicists},
  volume    =  5,
  number    =  2,
  pages     = {T163--T171},
  month     =  may,
  year      =  2017,
  url       = {https://doi.org/10.1190/INT-2016-0132.1},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2016-0132.1}
}

@ARTICLE{Zhao2016-ya,
  title     = {Characterizing a turbidite system in Canterbury Basin, New
               Zealand, using seismic attributes and distance-preserving
               self-organizing maps},
  author    = {Zhao, T and Zhang, J and Li, F and Marfurt, K},
  abstract  = {AbstractRecent developments in seismic attributes and seismic
               facies classification techniques have greatly enhanced the
               capability of interpreters to delineate and characterize
               features that are not prominent in conventional 3D seismic
               amplitude volumes. The use of appropriate seismic attributes
               that quantify the characteristics of different geologic facies
               can accelerate and partially automate the interpretation
               process. Self-organizing maps (SOMs) are a popular seismic
               facies classification tool that extract similar patterns
               embedded with multiple seismic attribute volumes. By preserving
               the distance in the input data space into the SOM latent space,
               the internal relation among data vectors on an SOM facies map is
               better presented, resulting in a more reliable classification.
               We have determined the effectiveness of the modified algorithm
               by applying it to a turbidite system in Canterbury Basin,
               offshore New Zealand. By incorporating seismic attributes and
               distance-preserving SOM classification, we were able to observe
               architectural elements that are overlooked when using a
               conventional seismic amplitude volume for interpretation.},
  journal   = {Interpretation},
  publisher = {Society of Exploration Geophysicists},
  volume    =  4,
  number    =  1,
  pages     = {SB79--SB89},
  month     =  feb,
  year      =  2016,
  url       = {https://doi.org/10.1190/INT-2015-0094.1},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2015-0094.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Zhao1988-hu,
  title     = {Minimum-variance deconvolution using artificial neural networks},
  author    = {Zhao, X and Mendel, J M},
  abstract  = {In this paper, we provide some background material on artificial
               neural networks (ANN's) and show how a modification of the
               Hopfleld type network structure can be used to solve the
               minimum-variance deconvolution (MVD) problem. One central issue
               involved ln the development and the specification of ANN focuses
               on the stability and the convergence of the entire network.
               Using the fact that an MVD result is the optimal solution of
               some quadratic objective function, the global Lyapunov stability
               function of ANN is used for the …},
  journal   = {SEG Technical Program Expanded Abstracts},
  publisher = {library.seg.org},
  year      =  1988,
  url       = {https://library.seg.org/doi/pdf/10.1190/1.1892433}
}

@INCOLLECTION{Zhang2001-hy,
  title     = {Chapter 10 {Self-Organizing} Map ({SOM}) network for tracking
               horizons and classifying seismic traces},
  booktitle = {Handbook of Geophysical Exploration: Seismic Exploration},
  author    = {Zhang, Lin and Quieren, John and Schuelke, James},
  editor    = {Poulton, Mary M},
  abstract  = {Publisher Summary Tracking a horizon can be automated by using a
               neural network to classify the wavelet morphology. This chapter
               explores in more detail how to use a Self Organizing Map (SOM),
               to track horizons, and then classify waveforms in the vicinity
               of the horizons. Tracking a particular seismic event (horizon)
               in three- dimensional (3-D) defines a surface, and the
               self-organizing map network can be applied to the seismic traces
               proximal to this surface, resulting in a classification of the
               seismic responses into geological features. The classified
               waveforms can show patterns related to geologic properties in
               the absence of well log data. With well log or other ancillary
               data, the classified waveforms can be correlated with properties
               such as porosity or shale volume. The chapter examines the use
               of the self-organizing map to track horizons and classify
               seismic traces from data collected in the Blackfoot field near
               Calgary, Alberta.},
  publisher = {Pergamon},
  volume    =  30,
  pages     = {155--170},
  month     =  jan,
  year      =  2001,
  url       = {http://www.sciencedirect.com/science/article/pii/S0950140101800240},
  doi       = {10.1016/S0950-1401(01)80024-0}
}

@ARTICLE{Zhang2015-pq,
  title     = {Brittleness evaluation of resource plays by integrating
               petrophysical and seismic data analysis},
  author    = {Zhang, B and Zhao, T and Jin, X and Marfurt, K},
  abstract  = {AbstractThe main considerations for well planning and hydraulic
               fracturing in unconventional resources plays include the amount
               of total organic carbon and how much hydrocarbon can be
               extracted. Brittleness is the direct measurement of a formation
               about the ability to create avenues for hydrocarbons when
               applying hydraulic fracturing. Brittleness can be directly
               estimated from laboratory stress-strain measurements,
               rock-elastic properties, and mineral content analysis using
               petrophysical analysis on well logs. However, the estimated
               brittleness using these methods only provides ?cylinder?
               estimates near the borehole. We proposed a workflow to estimate
               brittleness of resource plays in 3D by integrating the
               petrophysics and seismic data analysis. The workflow began by
               brittleness evaluation using mineral well logs at the borehole
               location. Then, we used a proximal support vector machine
               algorithm to construct a classification pattern between
               rock-elastic properties and brittleness for the selected
               benchmark well. The pattern was validated using well-log data
               that were not used for constructing the classification. Next, we
               prestack inverted the fidelity preserved seismic gathers to
               generate a suite of rock-elastic properties volumes. Finally, we
               obtained a satisfactory brittleness index of target formations
               by applying the trained classification pattern to the inverted
               rock-elastic-property volumes.},
  journal   = {Interpretation},
  publisher = {Society of Exploration Geophysicists},
  volume    =  3,
  number    =  2,
  pages     = {T81--T92},
  month     =  may,
  year      =  2015,
  url       = {https://doi.org/10.1190/INT-2014-0144.1},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2014-0144.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Zagayevskiy2016-bb,
  title     = {Grid-free petroleum reservoir characterization with truncated
               pluri-Gaussian simulation: Hekla case study},
  author    = {Zagayevskiy, Y and Deutsch, C V},
  abstract  = {A new geostatistical grid-free simulation (GFS) method has been
               developed recently that represents simulated continuous
               attributes of the natural phenomena, such as stratigraphic
               surface boundaries or petrophysical properties, as an analytical
               function of the coordinates of the simulation locations. Thus,
               GFS resolves challenges related to model regridding, increasing
               resolution around already simulated locations and integration of
               newly available data in a consistent manner. The present paper
               contains further developments in simulation …},
  journal   = {Pet. Geosci.},
  publisher = {pg.lyellcollection.org},
  year      =  2016,
  url       = {http://pg.lyellcollection.org/content/early/2016/06/23/petgeo2015-078.abstract},
  issn      = {1354-0793}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Zhang1997-yp,
  title     = {Magnetotelluric inversion using regularized Hopfield neural
               networks},
  author    = {Zhang, Y and Paulson, K V},
  abstract  = {Hopfield neural networks are massive parallel automata that
               support specific models and are adept in solving optimization
               problems. They suffer from a 'rough'solution space and
               convergence properties that are highly dependent on the starting
               model or prior. These detractions may be overcome by introducing
               regularization into the network in the form of local feedback
               smoothing. Application of regularized Hopfield networks to over
               50 optimization test cases has yielded successful results, even
               with uniform (minimal …},
  journal   = {Geophys. Prospect.},
  publisher = {earthdoc.org},
  year      =  1997,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=33881},
  issn      = {0016-8025}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Zhang2014-tr,
  title     = {Machine-learning based automated fault detection in seismic
               traces},
  author    = {Zhang, C and Frogner, C and Araya-Polo, M and {others}},
  abstract  = {Initial stages of velocity model building (VMB) start off from
               smooth models that capture geological assumptions of the
               subsurface region under analysis. Acceptable velocity models
               result from successive iterations of interpretation and seismic
               data processing. The interpreters ensure that
               additions/corrections made by seismic processing are compliant
               with geological and geophysical knowledge. Seismic processing
               adds to the model structural elements, faults are one of the
               most relevant of those events since they can signal …},
  journal   = {76th EAGE Conference},
  publisher = {earthdoc.org},
  year      =  2014,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=76370}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Yousefi2014-nn,
  title     = {Application of staged factor analysis and logistic function to
               create a fuzzy stream sediment geochemical evidence layer for
               mineral prospectivity mapping},
  author    = {Yousefi, M and Kamkar-Rouhani, A and {others}},
  abstract  = {Stream sediment geochemical data are usually subjected to
               methods of multivariate analysis (eg factor analysis) in order
               to extract an anomalous geochemical signature (factor) of the
               mineral deposit-type sought. A map of anomalous geochemical
               signature can be used as evidence, in combination with other
               layers of evidence, for mineral prospectivity mapping (MPM).
               Because factor analysis may yield more than one factor in a
               stream sediment dataset, it raises the challenge of how to
               recognize the factor that best indicates presence of …},
  journal   = {Geochem. Explor. Environ. Analy.},
  publisher = {geea.lyellcollection.org},
  year      =  2014,
  url       = {http://geea.lyellcollection.org/content/14/1/45.short},
  issn      = {1467-7873}
}

@inproceedings{ronneberger2015unet,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@ARTICLE{Zadhesh2014-vt,
  title     = {Estimation of joint trace length probability distribution
               function in igneous, sedimentary, and metamorphic rocks},
  author    = {Zadhesh, Jamal and Jalali, Seyed-Mohammad Esmaeil and
               Ramezanzadeh, Ahmad},
  abstract  = {To predict the behavior of structures in and on jointed rock
               masses, it is necessary to characterize the geomechanical
               properties of joints and intact rock. Among geometry properties
               of joints, trace length has a vital importance, because it
               affects rock mass strength and controls the stability of the
               rock structures in jointed rock masses. Since joint length has a
               range of values, it is useful to have an understanding of the
               distribution of these values in order to predict how the extreme
               values may be compared to the values obtained from a small
               sample. For this purpose, three datasets of joint systems from
               nine exposures of igneous, metamorphic, and sedimentary rocks
               are studied. Joint trace length is one of the most difficult
               properties to measure accurately, but it may be possible to
               record other geometrical properties of exposed joints
               accurately; thereby, support vector machine (SVM) model is used
               to predict the joint trace length. SVM is a novel machine
               learning method, which is a powerful tool used to solve the
               problem characterized by small sample and non-linearity with a
               good generalization performance. Consequently, goodness-of-fit
               (GOF) tests were applied on these data. According to these GOF
               tests, the lognormal distribution was found to be the best
               probability distribution function for representing a joint trace
               length distribution.},
  journal   = {Arabian Journal of Geosciences},
  publisher = {Springer},
  volume    =  7,
  number    =  6,
  pages     = {2353--2361},
  month     =  jun,
  year      =  2014,
  url       = {https://doi.org/10.1007/s12517-013-0861-1},
  issn      = {1866-7538},
  doi       = {10.1007/s12517-013-0861-1}
}

@INPROCEEDINGS{Youn2002-rn,
  title      = {Automatic {GPR} target detection and clutter reduction using
                neural network},
  booktitle  = {Ninth International Conference on Ground Penetrating Radar},
  author     = {Youn, Hyoung-Sun and Chen, Chi-Chih},
  abstract   = {Ground penetrating radar (GPR) has been widely used for the
                detection and location of buried objects. However, the
                detection method is often subjected to operator's
                interpretation due to large quantities of data and undesired
                clutter and noise. Such a detection method is neither reliable
                nor efficient.},
  publisher  = {International Society for Optics and Photonics},
  volume     =  4758,
  pages      = {579--583},
  month      =  apr,
  year       =  2002,
  url        = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/4758/0000/Automatic-GPR-target-detection-and-clutter-reduction-using-neural-network/10.1117/12.462229.short},
  conference = {Ninth International Conference on Ground Penetrating Radar},
  doi        = {10.1117/12.462229}
}

@ARTICLE{Soner_Yorgun2016-mt,
  title     = {A decision tree algorithm for investigation of model biases
               related to dynamical cores and physical parameterizations},
  author    = {Soner Yorgun, M and Rood, Richard B},
  abstract  = {An object-based evaluation method using a pattern recognition
               algorithm (i.e., classification trees) is applied to the
               simulated orographic precipitation for idealized experimental
               setups using the National Center of Atmospheric Research (NCAR)
               Community Atmosphere Model (CAM) with the finite volume (FV) and
               the Eulerian spectral transform dynamical cores with varying
               resolutions. Daily simulations were analyzed and three different
               types of precipitation features were identified by the
               classification tree algorithm. The statistical characteristics
               of these features (i.e., maximum value, mean value, and
               variance) were calculated to quantify the difference between the
               dynamical cores and changing resolutions. Even with the simple
               and smooth topography in the idealized setups, complexity in the
               precipitation fields simulated by the models develops quickly.
               The classification tree algorithm using objective thresholding
               successfully detected different types of precipitation features
               even as the complexity of the precipitation field increased. The
               results show that the complexity and the bias introduced in
               small-scale phenomena due to the spectral transform method of
               CAM Eulerian spectral dynamical core is prominent, and is an
               important reason for its dissimilarity from the FV dynamical
               core. The resolvable scales, both in horizontal and vertical
               dimensions, have significant effect on the simulation of
               precipitation. The results of this study also suggest that an
               efficient and informative study about the biases produced by
               GCMs should involve daily (or even hourly) output (rather than
               monthly mean) analysis over local scales.},
  journal   = {J Adv Model Earth Syst},
  publisher = {Wiley Online Library},
  volume    =  8,
  number    =  4,
  pages     = {1769--1785},
  month     =  dec,
  year      =  2016,
  url       = {http://dx.doi.org/10.1002/2016MS000657},
  keywords  = {decision trees; global circulation models; machine learning;
               model evaluation; orographic precipitation},
  language  = {en},
  issn      = {1942-2466},
  pmid      = {28239437},
  doi       = {10.1002/2016MS000657},
  pmc       = {PMC5298012}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Xiating1995-gb,
  title     = {{NEURAL} {NETWORK} {ESTIMATION} {OF} {SLOPE} {STABILITY} [J]},
  author    = {Xiating, F and Yongjia, W and Shizong, L},
  abstract  = {With application of neural network theory, a new method has been
               proposed for direct estimation of the safety factor for circular
               and wedge failure of slopes. Furthermore, a new algorithm called
               generalized learning algorithm is designed to learn better
               knowledge of estimation of the safety factors of slopes from
               cases. The learned knowledge is then used for extrapolating
               prediction of the safety factor of new slope, Compared with the
               safety factors predicted by the limit equilibrium and maximum
               likelihood method, the neural network …},
  journal   = {Journal of Engineering Geology},
  publisher = {en.cnki.com.cn},
  year      =  1995,
  url       = {http://en.cnki.com.cn/Article_en/CJFDTOTAL-GCDZ504.007.htm}
}

@ARTICLE{Xie2013-fh,
  title     = {An automatic recognition algorithm for {GPR} images of {RC}
               structure voids},
  author    = {Xie, Xiongyao and Qin, Hui and Yu, Chao and Liu, Lanbo},
  abstract  = {Ground penetrating radar (GPR) is a powerful tool for detecting
               defects in and behind reinforced concrete (RC) structures.
               However, the traditional way of interpreting GPR data involves
               considerable manpower and is time-consuming. The aim of this
               study is to illustrate a new approach to recognize GPR images of
               RC structure voids automatically. Firstly, synthetic GPR images
               are created by FDTD method. As multiple waves caused by steel
               bars seriously interfere with the target echo signals, it is
               difficult to identify targets from the forward modeling images.
               According to the periodicity of multiple waves from steel bars,
               the predictive deconvolution method is used to suppress those
               waves and the outcome is preferable. Then, the support vector
               machine (SVM) algorithm is proposed to automatically recognize
               voids in GPR images. The automatic identification procedure
               includes four steps: 1) collecting training data, 2) extracting
               features from GPR images, 3) building the SVM model and 4)
               identifying the voids automatically. The results show that the
               proposed method provides a suitable tool to locate the cover
               depths and lateral ranges of the voids, and the trained SVM
               model gives a favorable outcome when noise (no more than 5\%) is
               added to a synthetic GPR image.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  99,
  pages     = {125--134},
  month     =  dec,
  year      =  2013,
  url       = {http://www.sciencedirect.com/science/article/pii/S0926985113000487},
  keywords  = {Ground penetrating radar (GPR); Reinforced concrete (RC)
               structure; Void; Forward simulation; Support vector machine
               (SVM); Automatic recognition},
  issn      = {0926-9851},
  doi       = {10.1016/j.jappgeo.2013.02.016}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Wei2018-nm,
  title     = {Unsupervised Machine Learning: K-means Clustering Velocity
               Semblance {Auto-Picking}},
  author    = {Wei, S and Yonglin, O and Qingcai, Z and Jiaqiang, H and
               {others}},
  abstract  = {Machine learning is becoming an attractive tool in various
               fields of earth sciences. During seismic data processing,
               velocity auto-picking can reduce time consumed on processing
               large volumes of seismic data and increase the number of
               velocity semblances which will be picked in a 3D seismic survey.
               In this paper, a new velocity auto-picking method on the base of
               unsupervised machine learning was proposed, a guide velocity as
               a constraint to pre- processing the velocity semblance was
               introduced and K-means clustering had been used …},
  journal   = {80th EAGE Conference},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=92299}
}

@ARTICLE{Wu2018-hg,
  title         = {A deep convolutional encoder-decoder neural network in
                   assisting seismic horizon tracking},
  author        = {Wu, Hao and Zhang, Bo},
  abstract      = {Seismic horizons are geologically significant surfaces that
                   can be used for building geology structure and stratigraphy
                   models. However, horizon tracking in 3D seismic data is a
                   time-consuming and challenging problem. Relief human from
                   the tedious seismic interpretation is one of the hot
                   research topics. We proposed a novel automatically seismic
                   horizon tracking method by using a deep convolutional neural
                   network. We employ a state-of-art end-to-end semantic
                   segmentation method to track the seismic horizons
                   automatically. Experiment result shows that our proposed
                   neural network can automatically track multiple horizons
                   simultaneously. We validate the effectiveness and robustness
                   of our proposed method by comparing automatically tracked
                   horizons with manually picked horizons.},
  month         =  apr,
  year          =  2018,
  url           = {http://arxiv.org/abs/1804.06814},
  archivePrefix = {arXiv},
  eprint        = {1804.06814},
  primaryClass  = {physics.geo-ph},
  arxivid       = {1804.06814}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Wang1992-mq,
  title     = {Adaptive minimum prediction-error deconvolution and source
               wavelet estimation using Hopfield neural networks},
  author    = {Wang, L X and Mendel, J M},
  abstract  = {The massively parallel processing advantage of artificial neural
               networks makes them suitable for hardware implementations;
               therefore, using artificial neural networks for seismic signal
               processing problems has the potential of greatly speeding up
               seismic signal processing. A commonly used artificial neural
               network---Hopfield neural network---is used to implement a new
               adaptive minimum prediction-error deconvolution (AMPED)
               procedure which decomposes deconvolution and wavelet estimation
               into three subprocesses …},
  journal   = {Geophysics},
  publisher = {library.seg.org},
  year      =  1992,
  url       = {https://library.seg.org/doi/abs/10.1190/1.1443281},
  issn      = {0016-8033}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Di2018-ox,
  title     = {Seismic Fault Detection from {Post-Stack} Amplitude by
               Convolutional Neural Networks},
  author    = {Di, H and Wang, Z and AlRegib, G},
  abstract  = {Fault detection is one of the major tasks of subsurface
               interpretation and reservoir characterization from 3D seismic
               surveying. However, with the growing of seismic data in both its
               size and resolution, the efficiency of interpreting seismic
               faults increasingly relies on the development of powerful
               computational interpretation tools that are capable of mimicking
               an experienced interpreter's intelligence. In recent years, the
               convolutional neural network (CNN) has been successful for
               image/video processing in various disciplines and is …},
  journal   = {80th EAGE Conference and Exhibition 2018},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=92119}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Wang1997-is,
  title     = {Identification and picking of {S} phase using an artificial
               neural network},
  author    = {Wang, Jin and Teng, Ta-Liang},
  abstract  = {An artificial neural network (ann) algorithm has been applied to
               the automatic picking of local and regional S phase. For a set
               of local three-component seismic data, a variety of features for
               signal detection and phase identification were analyzed in terms
               of sensitivity and efficiency. Comparing the performance of each
               feature in discriminating the local S phases, four features were
               selected as input attributes of the ann S-phase picker:(1) the
               ratio between short-term average and long-term average,(2) the
               ratio between horizontal power …},
  journal   = {Bull. Seismol. Soc. Am.},
  publisher = {GeoScienceWorld},
  volume    =  87,
  number    =  5,
  pages     = {1140--1149},
  month     =  oct,
  year      =  1997,
  url       = {https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/87/5/1140/120211},
  issn      = {0037-1106}
}

@article{hale2013methods,
  title={Methods to compute fault images, extract fault surfaces, and estimate fault throws from 3D seismic images},
  author={Hale, Dave},
  journal={Geophysics},
  volume={78},
  number={2},
  pages={O33--O43},
  year={2013},
  publisher={Society of Exploration Geophysicists}
}

@ARTICLE{Wang2017-lw,
  title     = {Automatic, geologic layer-constrained well-seismic tie through
               blocked dynamic warping},
  author    = {Wang, K and Lomask, J and Segovia, F},
  abstract  = {Abstract Well-log-to-seismic tying is a key step in many
               interpretation workflows for oil and gas exploration. Synthetic
               seismic traces from the wells are often manually tied to seismic
               data; this process can be very time consuming and, in some
               cases, inaccurate. Automatic methods, such as dynamic time
               warping (DTW), can match synthetic traces to seismic data.
               Although these methods are extremely fast, they tend to create
               interval velocities that are not geologically realistic. We have
               described the modification of DTW to create a blocked dynamic
               warping (BDW) method. BDW generates an automatic, optimal well
               tie that honors geologically consistent velocity constraints.
               Consequently, it results in updated velocities that are more
               realistic than other methods. BDW constrains the updated
               velocity to be constant or linearly variable inside each
               geologic layer. With an optimal correlation between synthetic
               seismograms and surface seismic data, this algorithm returns an
               automatically updated time-depth curve and an updated interval
               velocity model that still retains the original geologic velocity
               boundaries. In other words, the algorithm finds the optimal
               solution for tying the synthetic to the seismic data while
               restricting the interval velocity changes to coincide with the
               initial input blocking. We have determined the application of
               the BDW technique on a synthetic data example and field data
               set.},
  journal   = {Interpretation},
  publisher = {Society of Exploration Geophysicists},
  volume    =  5,
  number    =  3,
  pages     = {SJ81--SJ90},
  month     =  aug,
  year      =  2017,
  url       = {https://doi.org/10.1190/INT-2016-0160.1},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2016-0160.1}
}

@ARTICLE{Wang2017-gi,
  title     = {A Segmentation Approach for Stochastic Geological Modeling Using
               Hidden Markov Random Fields},
  author    = {Wang, Hui and Wellmann, J Florian and Li, Zhao and Wang,
               Xiangrong and Liang, Robert Y},
  abstract  = {Stochastic modeling methods and uncertainty quantification are
               important tools for gaining insight into the geological
               variability of subsurface structures. Previous attempts at
               geologic inversion and interpretation can be broadly categorized
               into geostatistics and process-based modeling. The choice of a
               suitable modeling technique directly depends on the modeling
               applications and the available input data. Modern geophysical
               techniques provide us with regional data sets in two- or
               three-dimensional spaces with high resolution either directly
               from sensors or indirectly from geophysical inversion. Existing
               methods suffer certain drawbacks in producing accurate and
               precise (with quantified uncertainty) geological models using
               these data sets. In this work, a stochastic modeling framework
               is proposed to extract the subsurface heterogeneity from
               multiple and complementary types of data. Subsurface
               heterogeneity is considered as the ``hidden link'' between
               multiple spatial data sets. Hidden Markov random field models
               are employed to perform three-dimensional segmentation, which is
               the representation of the ``hidden link''. Finite Gaussian
               mixture models are adopted to characterize the statistical
               parameters of multiple data sets. The uncertainties are
               simulated via a Gibbs sampling process within a Bayesian
               inference framework. The proposed modeling method is validated
               and is demonstrated using numerical examples. It is shown that
               the proposed stochastic modeling framework is a promising tool
               for three-dimensional segmentation in the field of geological
               modeling and geophysics.},
  journal   = {Math. Geosci.},
  publisher = {Springer},
  volume    =  49,
  number    =  2,
  pages     = {145--177},
  month     =  feb,
  year      =  2017,
  url       = {https://doi.org/10.1007/s11004-016-9663-9},
  issn      = {1874-8961, 1874-8953},
  doi       = {10.1007/s11004-016-9663-9}
}

@ARTICLE{Waldeland2018-hj,
  title     = {Convolutional neural networks for automated seismic
               interpretation},
  author    = {Waldeland, A and Jensen, A and Gelius, L and Solberg, A},
  abstract  = {Abstract Deep-learning methods have proved successful recently
               for solving problems in image analysis and natural language
               processing. One of these methods, convolutional neural networks
               (CNNs), is revolutionizing the field of image analysis and
               pushing the state of the art. CNNs consist of layers of
               convolutions with trainable filters. The input to the network is
               the raw image or seismic amplitudes, removing the need for
               feature/attribute engineering. During the training phase, the
               filter coefficients are found by iterative optimization. The
               network thereby learns how to compute good attributes to solve
               the given classification task. However, CNNs require large
               amounts of training data and must be carefully designed and
               trained to perform well. We look into the intuition behind this
               method and discuss considerations that must be made in order to
               make the method reliable. In particular, we discuss how deep
               learning can be used for automated seismic interpretation. As an
               example, we show how a CNN can be used for automatic
               interpretation of salt bodies.},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  37,
  number    =  7,
  pages     = {529--537},
  month     =  jul,
  year      =  2018,
  url       = {https://doi.org/10.1190/tle37070529.1},
  issn      = {1070-485X},
  doi       = {10.1190/tle37070529.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Waldeland2017-tx,
  title     = {Salt classification using deep learning},
  author    = {Waldeland, A U and Solberg, A},
  abstract  = {Traditional methods for salt classification consist of choosing
               a set of attributes that are sensitive to the characteristics of
               salt bodies and training a classification algorithm to
               discriminate between salt and other geological structures.
               Convolutional neural networks have the advantage of combining
               attribute extraction and classification in one network. This
               allows both the attributes and classification to be trainable
               for the given application. In this work we show how this
               technique can be applied to salt classification in seismic
               datasets …},
  journal   = {79th EAGE Conference and Exhibition},
  publisher = {earthdoc.org},
  year      =  2017,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=88635}
}

@incollection{di2017seismic,
  title={Seismic-fault detection based on multiattribute support vector machine analysis},
  author={Di, Haibin and Shafiq, Muhammad Amir and AlRegib, Ghassan},
  booktitle={SEG Technical Program Expanded Abstracts 2017},
  pages={2039--2044},
  year={2017},
  publisher={Society of Exploration Geophysicists}
}

@ARTICLE{Viswanathan2016-ju,
  title     = {Determination of rock depth using artificial intelligence
               techniques},
  author    = {Viswanathan, R and Samui, Pijush},
  abstract  = {This article adopts three artificial intelligence techniques,
               Gaussian Process Regression (GPR), Least Square Support Vector
               Machine (LSSVM) and Extreme Learning Machine (ELM), for
               prediction of rock depth (d) at any point in Chennai. GPR, ELM
               and LSSVM have been used as regression techniques. Latitude and
               longitude are also adopted as inputs of the GPR, ELM and LSSVM
               models. The performance of the ELM, GPR and LSSVM models has
               been compared. The developed ELM, GPR and LSSVM models produce
               spatial variability of rock depth and offer robust models for
               the prediction of rock depth.},
  journal   = {Geoscience Frontiers},
  publisher = {Elsevier},
  volume    =  7,
  number    =  1,
  pages     = {61--66},
  month     =  jan,
  year      =  2016,
  url       = {http://www.sciencedirect.com/science/article/pii/S1674987115000456},
  keywords  = {Rock depth; Spatial variability; Least square support vector
               machine; Gaussian process regression; Extreme learning machine},
  issn      = {1674-9871},
  doi       = {10.1016/j.gsf.2015.04.002}
}

@ARTICLE{Viswanathan2016-cx,
  title     = {Determination of rock depth using artificial intelligence
               techniques},
  author    = {Viswanathan, R and Samui, Pijush},
  abstract  = {This article adopts three artificial intelligence techniques,
               Gaussian Process Regression (GPR), Least Square Support Vector
               Machine (LSSVM) and Extreme Learning Machine (ELM), for
               prediction of rock depth (d) at any point in Chennai. GPR, ELM
               and LSSVM have been used as regression techniques. Latitude and
               longitude are also adopted as inputs of the GPR, ELM and LSSVM
               models. The performance of the ELM, GPR and LSSVM models has
               been compared. The developed ELM, GPR and LSSVM models produce
               spatial variability of rock depth and offer robust models for
               the prediction of rock depth.},
  journal   = {Geoscience Frontiers},
  publisher = {Elsevier},
  volume    =  7,
  number    =  1,
  pages     = {61--66},
  month     =  jan,
  year      =  2016,
  url       = {http://www.sciencedirect.com/science/article/pii/S1674987115000456},
  keywords  = {Rock depth; Spatial variability; Least square support vector
               machine; Gaussian process regression; Extreme learning machine},
  issn      = {1674-9871},
  doi       = {10.1016/j.gsf.2015.04.002}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Verma2016-eo,
  title     = {Estimation of total organic carbon and brittleness volume},
  author    = {Verma, Sumit and Zhao, Tao and Marfurt, Kurt J and Devegowda,
               Deepak},
  abstract  = {Abstract The Barnett Shale in the Fort Worth Basin is one of the
               most important resource plays in the USA. The total organic
               carbon (TOC) and brittleness can help to characterize a resource
               play to assist in the search for sweet spots. Higher TOC or
               organic content are generally associated with hydrocarbon
               storage and with rocks that are ductile in nature. However,
               brittle rocks are more amenable to fracturing with the fractures
               faces more resistant to proppant embedment. Productive intervals
               within a resource play should …},
  journal   = {Interpretation},
  publisher = {GeoScienceWorld},
  volume    =  4,
  number    =  3,
  pages     = {T373--T385},
  month     =  aug,
  year      =  2016,
  url       = {https://pubs.geoscienceworld.org/segweb/interpretation/article/4/3/T373/309416},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2015-0166.1}
}

@ARTICLE{Verma2014-jx,
  title     = {Quantification of sand fraction from seismic attributes using
               {Neuro-Fuzzy} approach},
  author    = {Verma, Akhilesh K and Chaki, Soumi and Routray, Aurobinda and
               Mohanty, William K and Jenamani, Mamata},
  abstract  = {In this paper, we illustrate the modeling of a reservoir
               property (sand fraction) from seismic attributes namely seismic
               impedance, seismic amplitude, and instantaneous frequency using
               Neuro-Fuzzy (NF) approach. Input dataset includes 3D
               post-stacked seismic attributes and six well logs acquired from
               a hydrocarbon field located in the western coast of India.
               Presence of thin sand and shale layers in the basin area makes
               the modeling of reservoir characteristic a challenging task.
               Though seismic data is helpful in extrapolation of reservoir
               properties away from boreholes; yet, it could be challenging to
               delineate thin sand and shale reservoirs using seismic data due
               to its limited resolvability. Therefore, it is important to
               develop state-of-art intelligent methods for calibrating a
               nonlinear mapping between seismic data and target reservoir
               variables. Neural networks have shown its potential to model
               such nonlinear mappings; however, uncertainties associated with
               the model and datasets are still a concern. Hence, introduction
               of Fuzzy Logic (FL) is beneficial for handling these
               uncertainties. More specifically, hybrid variants of Artificial
               Neural Network (ANN) and fuzzy logic, i.e., NF methods, are
               capable for the modeling reservoir characteristics by
               integrating the explicit knowledge representation power of FL
               with the learning ability of neural networks. In this paper, we
               opt for ANN and three different categories of Adaptive
               Neuro-Fuzzy Inference System (ANFIS) based on clustering of the
               available datasets. A comparative analysis of these three
               different NF models (i.e., Sugeno-type fuzzy inference systems
               using a grid partition on the data (Model 1), using subtractive
               clustering (Model 2), and using Fuzzy c-means (FCM) clustering
               (Model 3)) and ANN suggests that Model 3 has outperformed its
               counterparts in terms of performance evaluators on the present
               dataset. Performance of the selected algorithms is evaluated in
               terms of correlation coefficients (CC), root mean square error
               (RMSE), absolute error mean (AEM) and scatter index (SI) between
               target and predicted sand fraction values. The achieved
               estimation accuracy may diverge minutely depending on geological
               characteristics of a particular study area. The documented
               results in this study demonstrate acceptable resemblance between
               target and predicted variables, and hence, encourage the
               application of integrated machine learning approaches such as
               Neuro-Fuzzy in reservoir characterization domain. Furthermore,
               visualization of the variation of sand probability in the study
               area would assist in identifying placement of potential wells
               for future drilling operations.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  111,
  pages     = {141--155},
  month     =  dec,
  year      =  2014,
  url       = {http://www.sciencedirect.com/science/article/pii/S0926985114002912},
  keywords  = {Reservoir characterization; Well logs; Seismic attributes;
               Artificial neural network; Fuzzy logic; Neuro-Fuzzy},
  issn      = {0926-9851},
  doi       = {10.1016/j.jappgeo.2014.10.005}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Veillard2018-sg,
  title     = {Fast {3D} Seismic Interpretation with Unsupervised Deep
               Learning: Application to a Potash Network in the North Sea},
  author    = {Veillard, A and Mor{\`e}re, O and Grout, M and {others}},
  abstract  = {We present a new Artificial Intelligence (AI) tool enabling fast
               and accurate interpretation of 3D geological objects from
               seismic data. The tool is powered by deep learning, a set of
               techniques representing the latest breakthroughs in machine
               learning. The original method proposed in this work is built
               around generative models (unsupervised deep learning) which
               leads to several key advantages compared with other
               state-of-the-art AI approaches. Powerful interpretation models
               can be trained from the seismic data alone, without requiring …},
  journal   = {80th EAGE Conference},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=92124}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{De_la_Varga2016-da,
  title     = {Structural geologic modeling as an inference problem: A Bayesian
               perspective},
  author    = {de la Varga, Miguel and Florian Wellmann, J},
  abstract  = {Structural geologic models are widely used to represent the
               spatial distribution of relevant geologic features. Several
               techniques exist to construct these models on the basis of
               different assumptions and different types of geologic
               observations. However, two problems are prevalent when
               constructing models:(1) observations and assumptions, and
               therefore also the constructed model, are subject to
               uncertainties and (2) additional information is often available,
               but it cannot be considered directly in the geologic modeling
               step---although …},
  journal   = {Interpretation},
  publisher = {GeoScienceWorld},
  volume    =  4,
  number    =  3,
  pages     = {SM1--SM16},
  month     =  aug,
  year      =  2016,
  url       = {https://pubs.geoscienceworld.org/interpretation/article-abstract/4/3/SM1/309479},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2015-0188.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Valentine2013-fo,
  title     = {Discovery and analysis of topographic features using learning
               algorithms: A seamount case study},
  author    = {Valentine, A P and Kalnins, L M and {others}},
  abstract  = {Identifying and cataloging occurrences of particular topographic
               features are important but time‐consuming tasks. Typically,
               automation is challenging, as simple models do not fully
               describe the complexities of natural features. We propose a new
               approach, where a particular class of neural network (the
               ``autoencoder'') is used to assimilate the characteristics of
               the feature to be cataloged, and then applied to a systematic
               search for new examples. To demonstrate the feasibility of this
               method, we construct a network that …},
  journal   = {Geophys. Res. Lett.},
  publisher = {Wiley Online Library},
  year      =  2013,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/grl.50615},
  issn      = {0094-8276}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ueki2018-at,
  title     = {Geochemical Discrimination and Characteristics of Magmatic
               Tectonic Settings: A {Machine‐Learning‐Based} Approach},
  author    = {Ueki, K and Hino, H and Kuwatani, T},
  abstract  = {Geochemically discriminating between magmatism in different
               tectonic settings remains a fundamental part of understanding
               the processes of magma generation within the Earth's mantle.
               Here we present an approach where machine learning (ML) methods
               are used for quantitative tectonic discrimination and feature
               selection using global geochemical data sets containing data for
               volcanic rocks generated in eight different tectonic settings.
               This study uses support vector machine, random forest, and
               sparse multinomial regression (SMR) …},
  journal   = {Geochem. Geophys. Geosyst.},
  publisher = {Wiley Online Library},
  year      =  2018,
  url       = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2017GC007401}
}

@ARTICLE{Valera2018-fp,
  title     = {Machine learning for graph-based representations of
               three-dimensional discrete fracture networks},
  author    = {Valera, Manuel and Guo, Zhengyang and Kelly, Priscilla and Matz,
               Sean and Cantu, Vito Adrian and Percus, Allon G and Hyman,
               Jeffrey D and Srinivasan, Gowri and Viswanathan, Hari S},
  abstract  = {Structural and topological information play a key role in
               modeling flow and transport through fractured rock in the
               subsurface. Discrete fracture network (DFN) computational suites
               such as dfnWorks (Hyman et al. Comput. Geosci. 84, 10--19 2015)
               are designed to simulate flow and transport in such porous
               media. Flow and transport calculations reveal that a small
               backbone of fractures exists, where most flow and transport
               occurs. Restricting the flowing fracture network to this
               backbone provides a significant reduction in the network's
               effective size. However, the particle-tracking simulations
               needed to determine this reduction are computationally
               intensive. Such methods may be impractical for large systems or
               for robust uncertainty quantification of fracture networks,
               where thousands of forward simulations are needed to bound
               system behavior. In this paper, we develop an alternative
               network reduction approach to characterizing transport in DFNs,
               by combining graph theoretical and machine learning methods. We
               consider a graph representation where nodes signify fractures
               and edges denote their intersections. Using random forest and
               support vector machines, we rapidly identify a subnetwork that
               captures the flow patterns of the full DFN, based primarily on
               node centrality features in the graph. Our supervised learning
               techniques train on particle-tracking backbone paths found by
               dfnWorks, but run in negligible time compared to those
               simulations. We find that our predictions can reduce the network
               to approximately 20\% of its original size, while still
               generating breakthrough curves consistent with those of the
               original network.},
  journal   = {Computational Geosciences},
  publisher = {Springer},
  volume    =  22,
  number    =  3,
  pages     = {695--710},
  month     =  jun,
  year      =  2018,
  url       = {https://doi.org/10.1007/s10596-018-9720-1},
  issn      = {1573-1499},
  doi       = {10.1007/s10596-018-9720-1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ueki2018-ox,
  title     = {Geochemical Discrimination and Characteristics of Magmatic
               Tectonic Settings: A {Machine‐Learning‐Based} Approach},
  author    = {Ueki, K and Hino, H and Kuwatani, T},
  abstract  = {Geochemically discriminating between magmatism in different
               tectonic settings remains a fundamental part of understanding
               the processes of magma generation within the Earth's mantle.
               Here we present an approach where machine learning (ML) methods
               are used for quantitative tectonic discrimination and feature
               selection using global geochemical data sets containing data for
               volcanic rocks generated in eight different tectonic settings.
               This study uses support vector machine, random forest, and
               sparse multinomial regression (SMR) …},
  journal   = {Geochem. Geophys. Geosyst.},
  publisher = {Wiley Online Library},
  year      =  2018,
  url       = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2017GC007401}
}

@ARTICLE{Tartakovsky2004-ml,
  title     = {Delineation of geologic facies with statistical learning theory},
  author    = {Tartakovsky, Daniel M},
  abstract  = {Insufficient site parameterization remains a major stumbling
               block for efficient and reliable prediction of flow and
               transport in a subsurface environment. The lack of sufficient
               parameter data is usually dealt with by treating relevant
               parameters as random fields, which enables one to employ various
               geostatistical and stochastic tools. The major conceptual
               difficulty with these techniques is that they rely on the
               ergodicity hypothesis to interchange spatial and ensemble
               statistics. Instead of treating deterministic material
               properties as random, we introduce tools from machine learning
               to deal with the sparsity of data. To demonstrate the relevance
               and advantages of this approach, we apply one of these tools,
               the Support Vector Machine, to delineate geologic facies from
               hydraulic conductivity data.},
  journal   = {Geophys. Res. Lett.},
  publisher = {Wiley Online Library},
  volume    =  31,
  number    =  18,
  pages     = {121},
  year      =  2004,
  url       = {http://doi.wiley.com/10.1029/2004GL020864},
  issn      = {0094-8276},
  doi       = {10.1029/2004GL020864}
}

@INCOLLECTION{Tang2017-ve,
  title     = {Segmentation of shale {SEM} images using machine learning},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2017},
  author    = {Tang, D and Spikes, K},
  abstract  = {The segmentation procedure in a digital rock physics workflow is
               often very challenging and time consuming. Here, we present an
               alternative method for quickly segmenting digital rock physics
               images that utilizes machine learning. Elemental SEM images of a
               core sample serve as inputs into a neural network. The network
               then outputs the probability of a pixel belonging to a certain
               class. Segmentation is implemented by choosing the class with
               the highest probability. This process allows for the uncertainty
               to be quantified in mineral phase identification. After training
               the algorithm, the rest of the image and subsequent images can
               be quickly segmented. We demonstrate the segmentation process on
               a shale sample with six different phases. Presentation Date:
               Wednesday, September 27, 2017 Start Time: 3:05 PM Location:
               Exhibit Hall C, E-P Station 4 Presentation Type: EPOSTER},
  publisher = {Society of Exploration Geophysicists},
  pages     = {3898--3902},
  series    = {SEG Technical Program Expanded Abstracts},
  month     =  aug,
  year      =  2017,
  url       = {https://doi.org/10.1190/segam2017-17738502.1},
  doi       = {10.1190/segam2017-17738502.1}
}

@INCOLLECTION{Tang2017-xe,
  title     = {Segmentation of shale {SEM} images using machine learning},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2017},
  author    = {Tang, D and Spikes, K},
  abstract  = {The segmentation procedure in a digital rock physics workflow is
               often very challenging and time consuming. Here, we present an
               alternative method for quickly segmenting digital rock physics
               images that utilizes machine learning. Elemental SEM images of a
               core sample serve as inputs into a neural network. The network
               then outputs the probability of a pixel belonging to a certain
               class. Segmentation is implemented by choosing the class with
               the highest probability. This process allows for the uncertainty
               to be quantified in mineral phase identification. After training
               the algorithm, the rest of the image and subsequent images can
               be quickly segmented. We demonstrate the segmentation process on
               a shale sample with six different phases. Presentation Date:
               Wednesday, September 27, 2017 Start Time: 3:05 PM Location:
               Exhibit Hall C, E-P Station 4 Presentation Type: EPOSTER},
  publisher = {Society of Exploration Geophysicists},
  pages     = {3898--3902},
  series    = {SEG Technical Program Expanded Abstracts},
  month     =  aug,
  year      =  2017,
  url       = {https://doi.org/10.1190/segam2017-17738502.1},
  doi       = {10.1190/segam2017-17738502.1}
}

@ARTICLE{Sudakov2018-cj,
  title         = {Driving Digital Rock towards Machine Learning: predicting
                   permeability with Gradient Boosting and Deep Neural Networks},
  author        = {Sudakov, Oleg and Burnaev, Evgeny and Koroteev, Dmitry},
  abstract      = {We present a research study aimed at testing of
                   applicability of machine learning techniques for prediction
                   of permeability of digitized rock samples. We prepare a
                   training set containing 3D images of sandstone samples
                   imaged with X-ray microtomography and corresponding
                   permeability values simulated with Pore Network approach. We
                   also use Minkowski functionals and Deep Learning-based
                   descriptors of 3D images and 2D slices as input features for
                   predictive model training and prediction. We compare
                   predictive power of various feature sets and methods. The
                   later include Gradient Boosting and various architectures of
                   Deep Neural Networks (DNN). The results demonstrate
                   applicability of machine learning for image-based
                   permeability prediction and open a new area of Digital Rock
                   research.},
  month         =  mar,
  year          =  2018,
  url           = {http://arxiv.org/abs/1803.00758},
  archivePrefix = {arXiv},
  eprint        = {1803.00758},
  primaryClass  = {physics.geo-ph},
  arxivid       = {1803.00758}
}

@ARTICLE{Sudakov2018-vy,
  title         = {Driving Digital Rock towards Machine Learning: predicting
                   permeability with Gradient Boosting and Deep Neural Networks},
  author        = {Sudakov, Oleg and Burnaev, Evgeny and Koroteev, Dmitry},
  abstract      = {We present a research study aimed at testing of
                   applicability of machine learning techniques for prediction
                   of permeability of digitized rock samples. We prepare a
                   training set containing 3D images of sandstone samples
                   imaged with X-ray microtomography and corresponding
                   permeability values simulated with Pore Network approach. We
                   also use Minkowski functionals and Deep Learning-based
                   descriptors of 3D images and 2D slices as input features for
                   predictive model training and prediction. We compare
                   predictive power of various feature sets and methods. The
                   later include Gradient Boosting and various architectures of
                   Deep Neural Networks (DNN). The results demonstrate
                   applicability of machine learning for image-based
                   permeability prediction and open a new area of Digital Rock
                   research.},
  month         =  mar,
  year          =  2018,
  url           = {http://arxiv.org/abs/1803.00758},
  archivePrefix = {arXiv},
  eprint        = {1803.00758},
  primaryClass  = {physics.geo-ph},
  arxivid       = {1803.00758}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Shihab2002-po,
  title     = {Image processing and neural network techniques for automatic
               detection and interpretation of ground penetrating radar data},
  author    = {Shihab, S and Al-Nuaimy, W and Eriksen, A},
  abstract  = {Ground penetrating radar (GPR) has gained a distinguished place
               during recent years as a tool for investigating subsurface
               objects, yet its output is of low resolution, and in need of
               further processing in order to make its output readily
               interpretable. Furthermore, GPR data collected in a typical
               survey is usually in large quantities, and dealing with such
               quantities manually to produce final interpretations would
               result in human inaccuracy, and time- consumption problems. In
               this paper we present an automatic target-detection and …},
  journal   = {Proceedings of the 6th},
  publisher = {researchgate.net},
  year      =  2002,
  url       = {https://www.researchgate.net/profile/Asger_Eriksen/publication/255015233_Image_processing_and_neural_network_techniques_for_automatic_detection_and_interpretation_of_ground_penetrating_radar_data/links/54c664b60cf219bbe4f842ba/Image-processing-and-neural-network-techniques-for-automatic-detection-and-interpretation-of-ground-penetrating-radar-data.pdf}
}

@ARTICLE{Strecker2002-dp,
  title     = {Data mining of {3D} poststack seismic attribute volumes using
               Kohonen self-organizing maps},
  author    = {Strecker, U and Uden, R},
  abstract  = {For several decades, artificial neural networks have assisted in
               data reduction processes through classifications applied to a
               wide spectrum of aspects?from traffic solutions and medicinal
               purposes to geophysical interpretations. Here we use an
               unsupervised approach where the neural network is free to
               search, to recognize, and to classify structural patterns in an
               n-dimensional vector field spanning the entire 3D input seismic
               attribute data set (Taner et al., 2001; Walls et al., 2002).
               Within the data set, each data sample is defined by a unique
               combination of physical, geometric, and hybrid attributes and is
               treated as an n-dimensional vector (Carr et al., 2001). Data
               classification occurs when similar data are captured with a
               Euclidean distance of a neural node, thus providing data
               clusters or classes as an output data set. In this paper, an
               unsupervised artificial neural network using four different
               suites of poststack seismic attributes is employed to classify a
               3D seismic data volume from Lafourche Parish, South Louisiana.},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  21,
  number    =  10,
  pages     = {1032--1037},
  month     =  oct,
  year      =  2002,
  url       = {https://doi.org/10.1190/1.1518442},
  issn      = {1070-485X},
  doi       = {10.1190/1.1518442}
}

@INPROCEEDINGS{Shihab2002-ne,
  title      = {Neural network target identifier based on statistical features
                of {GPR} signals},
  booktitle  = {Ninth International Conference on Ground Penetrating Radar},
  author     = {Shihab, S and Al-Nuaimy, Waleed and Huang, Yi and Eriksen,
                Asger},
  abstract   = {Accurate and consistent manual interpretation of the vast
                quantities of GPR data collected during a typical survey
                constitute an implementation bottleneck that often limits the
                practicality and cost-effectiveness of this tool for rapid site
                investigation. Automatic unsupervised interpretation of GPR
                data is achieved by training a neural network to discriminate
                between signals originating from different types of targets and
                other spurious sources of reflections such as clutter. This is
                achieved by computing a number of statistical data descriptors
                for feature extraction. The neural classifier is capable of
                returning 3-dimensional image outlining regions of extended
                targets (such as reinforced concrete, disturbed soil or storage
                tanks) and pinpointing the location of localised targets such
                as mines and pipes. These reports are accompanied by a written
                log detailing the depths and geometry of these targets. This
                classifier was applied to a variety of GPR data sets gathered
                from a number of sites. The obtained results were in close
                agreement with those obtained by a trained operator manually,
                but in a fraction of the time. Different targets have been
                successfully discriminated, with a consistency greater than
                that of the operator. Although the system is implemented in
                software, the rate at which classifications are rendered lends
                the system Authors would like to thank the Engineering and
                Physical Sciences Research Council (EPSRC) for funding this
                work as a part of a larger project regarding automatic
                data-processing of ground penetrating radar. Authors would like
                also to express their gratitude to Zetica (UK) Ltd. for
                supporting this work financially, and providing sites data and
                related software. favourably to near real-time on-site
                processing and interpretation.},
  publisher  = {International Society for Optics and Photonics},
  volume     =  4758,
  pages      = {135--139},
  month      =  apr,
  year       =  2002,
  url        = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/4758/0000/Neural-network-target-identifier-based-on-statistical-features-of-GPR/10.1117/12.462228.short},
  conference = {Ninth International Conference on Ground Penetrating Radar},
  doi        = {10.1117/12.462228}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Shafiq2018-qt,
  title     = {Leveraging Sparse Features Learned from Natural Images for
               Seismic Understanding},
  author    = {Shafiq, M A and Prabhushankar, M and AlRegib, G},
  abstract  = {This paper aims at adapting and utilizing the broad domain
               knowledge from natural images and evaluate its applicability in
               automation, improving attributes, and seismic processing. We
               propose an unsupervised learning network for seismic data
               analysis based on features learned from natural images. First,
               we learn the variances of edge and non-edge features in natural
               images characterized by different shapes, orientation, edges,
               and background. Then, we use the sparse model of learned
               features to study and recognize salient geological …},
  journal   = {80th EAGE Conference and},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=92123}
}

@ARTICLE{Silva2015-go,
  title     = {Artificial neural networks to support petrographic
               classification of carbonate-siliciclastic rocks using well logs
               and textural information},
  author    = {Silva, Adrielle A and Lima Neto, Irineu A and Miss{\'a}gia,
               Roseane M and Ceia, Marco A and Carrasquilla, Abel G and
               Archilha, Nathaly L},
  abstract  = {Petrographic class identification is of great importance to
               petroleum reservoir characterization and wellbore economic
               viability analysis, and is usually performed using core or
               geophysical log analysis. The coring process is costly, and well
               log analysis requires highly specific knowledge. Thus, great
               interest has arisen in new methods for predicting the
               lithological and textural properties of a wide area from a small
               number of samples. The artificial neural network (ANN) is a
               computational method based on human brain function and is
               efficient in recognizing previously trained patterns. This paper
               demonstrates petrographic classification of
               carbonate-siliciclastic rocks using a back-propagation neural
               network algorithm supported by elastic, mineralogical, and
               textural information from a well data set located in the South
               Provence Basin, in the southwest of France. The accuracy of the
               testing suggests that an ANN application offers an auxiliary
               tool for petrographic classification based on well data,
               specifically for prediction intervals in wells that have not
               been sampled or wells adjacent to sampled wells.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  117,
  pages     = {118--125},
  month     =  jun,
  year      =  2015,
  url       = {http://www.sciencedirect.com/science/article/pii/S092698511500124X},
  keywords  = {Artificial neural network; Back-propagation algorithm;
               Recognizing patterns; Petrographic classification;
               Carbonate-siliciclastic rocks},
  issn      = {0926-9851},
  doi       = {10.1016/j.jappgeo.2015.03.027}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Shafiq2018-ed,
  title     = {Leveraging Sparse Features Learned from Natural Images for
               Seismic Understanding},
  author    = {Shafiq, M A and Prabhushankar, M and AlRegib, G},
  abstract  = {This paper aims at adapting and utilizing the broad domain
               knowledge from natural images and evaluate its applicability in
               automation, improving attributes, and seismic processing. We
               propose an unsupervised learning network for seismic data
               analysis based on features learned from natural images. First,
               we learn the variances of edge and non-edge features in natural
               images characterized by different shapes, orientation, edges,
               and background. Then, we use the sparse model of learned
               features to study and recognize salient geological …},
  journal   = {80th EAGE Conference and},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=92123}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Schuster2018-sj,
  title     = {Machine learning and wave equation inversion of skeletonized
               data},
  author    = {Schuster, G T S},
  abstract  = {We compare the full waveform inversion (FWI), skeletonized wave
               equation inversion (SWI), and supervised Machine Learning (ML)
               algorithms with one another. For velocity inversion the
               advantage of SWI over FWI is it is more robust and has less of a
               tendency in getting stuck at local minima. This is because SWI
               only needs to explain the kinematic information in the
               seismograms, which is less demanding than FWI's difficult task
               of explaining all of the wiggles in every arrival. The
               disadvantage of SWI is that it provides a tomogram with …},
  journal   = {80th EAGE Conference \& Exhibition 2018 Workshop},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=93370}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Shafiq2018-rp,
  title     = {Attention models based on sparse autoencoders for seismic
               interpretation},
  author    = {Shafiq, M A and Prabhushankar, M and {others}},
  abstract  = {One of the fundamental steps in the exploration of oil, gas, and
               hydrocarbons is to detect various subsurface structures such as
               faults, salt domes, gas chimneys and channels within seismic
               volumes. In recent years, with the dramatic increase in the size
               of acquired seismic data, manual interpretation is becoming
               extremely time consuming and labor-intensive. Attention models
               based on human visual system (HVS) can be utilized to mimic and
               predict the behaviour of interpreters inspecting seismic
               sections. Leveraging these models, we can …},
  journal   = {ACE 2018 Annual},
  publisher = {searchanddiscovery.com},
  year      =  2018,
  url       = {http://www.searchanddiscovery.com/abstracts/html/2018/ace2018/abstracts/2856356.html}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Schlanser2016-xs,
  title     = {Lithofacies classification in the Marcellus Shale by applying a
               statistical clustering algorithm to petrophysical and elastic
               well logs},
  author    = {Schlanser, Kristen and Grana, Dario and Campbell-Stone, Erin},
  abstract  = {Interpreting shale lithofacies is an important step in
               identifying productive zones in the Marcellus Shale gas play;
               the target reservoir can be less than 3 m (10 ft) thick with
               overlying shales that appear similar on certain petrophysical
               well logs and in the core. However, these nonreservoir-quality
               shales contain widely varying organic and mechanical properties.
               To distinguish between reservoir-and nonreservoir-quality shale
               facies, this classification method applies a pattern-recognition
               algorithm, expectation maximization, to a set of …},
  journal   = {Interpretation},
  publisher = {GeoScienceWorld},
  volume    =  4,
  number    =  2,
  pages     = {SE31--SE49},
  month     =  may,
  year      =  2016,
  url       = {https://pubs.geoscienceworld.org/interpretation/article-abstract/4/2/SE31/75919},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2015-0128.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Scarpetta2005-xf,
  title     = {Automatic Classification of Seismic Signals at Mt. Vesuvius
               Volcano, Italy, Using Neural Networks},
  author    = {Scarpetta, S and Giudicepietro, F and Ezin, E C and Petrosino, S
               and Del Pezzo, E and Martini, M and Marinaro, M},
  abstract  = {We present a new strategy for reliable automatic classification
               of local seismic signals and volcano-tectonic earthquakes (vt).
               The method is based on a supervised neural network in which a
               new approach for feature extraction from short period seismic
               signals is applied. To reduce the number of records required for
               the analysis we set up a specialized neural classifier, able to
               distinguish two classes of signals, for each of the selected
               stations. The neural network architecture is a multilayer
               perceptron (mlp) with a single hidden layer …},
  journal   = {Bull. Seismol. Soc. Am.},
  publisher = {GeoScienceWorld},
  volume    =  95,
  number    =  1,
  pages     = {185--196},
  month     =  feb,
  year      =  2005,
  url       = {https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/95/1/185/146889},
  issn      = {0037-1106},
  doi       = {10.1785/0120030075}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.

@ARTICLE{Saporetti2018-sq,
  title     = {Machine learning approaches for petrographic classification of
               carbonate-siliciclastic rocks using well logs and textural
               information},
  author    = {Saporetti, Camila Martins and da Fonseca, Leonardo Goliatt and
               Pereira, Egberto and de Oliveira, Leonardo Costa},
  abstract  = {The definition of lithology in oil wells by means of multiple
               geophysical analysis profiles an important role in the reservoir
               characterization process. From this one can generate lithologic
               models which in turn will be filled in with the petrophysical
               properties and can then be used in flow simulators to understand
               and study the behavior of an oil field. The identification of
               lithology can be accomplished by direct and indirect methods,
               but these procedures are not always feasible because of the cost
               or imprecision of the results generated. Consequently, there is
               a need to automate the process of reservoir characterization
               and, in this context, computational intelligence techniques
               appear as an alternative to lithology identification. In this
               paper balancing strategies are implemented in order to tackle
               the lack of data due to the characteristics of the distinct
               diagenetic processes. Six machine learning methods combined with
               data balancing techniques and a model selection approach to
               classify geologic data from the South Provence Basin. The
               results show the balancing strategies improve the overall
               performance of all classifiers and the model selection allows or
               obtaining the best parameters from a user-defined set. The
               computational tool developed in this paper arises as an
               alternative to assist geologists ans specialists in the task of
               reservoir heterogeneities identification.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  155,
  pages     = {217--225},
  month     =  aug,
  year      =  2018,
  url       = {http://www.sciencedirect.com/science/article/pii/S092698511630667X},
  keywords  = {Machine learning; Petrographic classification; Well logs;
               Textural information},
  issn      = {0926-9851},
  doi       = {10.1016/j.jappgeo.2018.06.012}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Salati2014-jm,
  title     = {Spectral and geochemical characterization of onshore hydrocarbon
               seep-induced alteration in the Dezful embayment, southwest
               {IranSpectral} and Geochemical …},
  author    = {Salati, S and van Ruitenbeek, F J A and de Smeth, J B and
               {others}},
  abstract  = {The presence of hydrocarbon seeps at the surface is indirect
               evidence of the presence of mature source rocks within a
               geological system at depth. Chemical changes in the environment
               of surface rocks caused by hydrocarbon seeps cause mineralogical
               alterations. To determine the nature of the alterations and the
               influences of lithology and type of seep, rock samples were
               collected from altered and unaltered evaporite and marly
               limestone formations in the Dezful embayment, southwest Iran.
               Reflectance spectroscopy, bulk …},
  journal   = {AAPG},
  publisher = {pubs.geoscienceworld.org},
  year      =  2014,
  url       = {https://pubs.geoscienceworld.org/segweb/aapgbull/article/98/9/1837/133439}
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Sahoo2017-xt,
  title     = {Machine learning algorithms for modeling groundwater level
               changes in agricultural regions of the {US}},
  author    = {Sahoo, S and Russo, T A and Elliott, J and {others}},
  abstract  = {Climate, groundwater extraction, and surface water flows have
               complex nonlinear relationships with groundwater level in
               agricultural regions. To better understand the relative
               importance of each driver and predict groundwater level change,
               we develop a new ensemble modeling framework based on spectral
               analysis, machine learning, and uncertainty analysis, as an
               alternative to complex and computationally expensive physical
               models. We apply and evaluate this new approach in the context
               of two aquifer systems …},
  journal   = {Water Resour.},
  publisher = {Wiley Online Library},
  year      =  2017,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/2016WR019933}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Samui2011-zc,
  title     = {Support vector machine for evaluating seismic-liquefaction
               potential using shear wave velocity},
  author    = {Samui, Pijush and Kim, Dookie and Sitharam, T G},
  abstract  = {The use of the shear wave velocity data as a field index for
               evaluating the liquefaction potential of sands is receiving
               increased attention because both shear wave velocity and
               liquefaction resistance are similarly influenced by many of the
               same factors such as void ratio, state of stress, stress history
               and geologic age. In this paper, the potential of support vector
               machine (SVM) based classification approach has been used to
               assess the liquefaction potential from actual shear wave
               velocity data. In this approach, an approximate implementation
               of a structural risk minimization (SRM) induction principle is
               done, which aims at minimizing a bound on the generalization
               error of a model rather than minimizing only the mean square
               error over the data set. Here SVM has been used as a
               classification tool to predict liquefaction potential of a soil
               based on shear wave velocity. The dataset consists the
               information of soil characteristics such as effective vertical
               stress ($\sigma$′v0), soil type, shear wave velocity (Vs) and
               earthquake parameters such as peak horizontal acceleration
               (amax) and earthquake magnitude (M). Out of the available 186
               datasets, 130 are considered for training and remaining 56 are
               used for testing the model. The study indicated that SVM can
               successfully model the complex relationship between seismic
               parameters, soil parameters and the liquefaction potential. In
               the model based on soil characteristics, the input parameters
               used are $\sigma$′v0, soil type, Vs, amax and M. In the other
               model based on shear wave velocity alone uses Vs, amax and M as
               input parameters. In this paper, it has been demonstrated that
               Vs alone can be used to predict the liquefaction potential of a
               soil using a support vector machine model.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  73,
  number    =  1,
  pages     = {8--15},
  month     =  jan,
  year      =  2011,
  url       = {http://www.sciencedirect.com/science/article/pii/S092698511000131X},
  keywords  = {Liquefaction; Shear wave velocity; Support vector machine},
  issn      = {0926-9851},
  doi       = {10.1016/j.jappgeo.2010.10.005}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Sacrey2018-pk,
  title     = {Solving exploration problems with machine learning},
  author    = {Sacrey, D and Roden, R},
  abstract  = {Over the past eight years the evolution of machine learning in
               the form of unsupervised neural networks has been applied to
               improve and gain more insights in the seismic interpretation
               process (Smith and Taner, 2010; Roden et al., 2015; Santogrossi,
               2016: Roden and Chen, 2017; Roden et al., 2017). Today's
               interpretation environment involves an enormous amount of
               seismic data including regional 3D surveys with numerous
               processing versions and dozens if not hundreds of seismic
               attributes. This 'Big Data'issue poses …},
  journal   = {First Break},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=92017},
  issn      = {0263-5046}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{RouetLeduc2017-li,
  title     = {Machine learning predicts laboratory earthquakes},
  author    = {Rouet‐Leduc, B and Hulbert, C and Lubbers, N and {others}},
  abstract  = {We apply machine learning to data sets from shear laboratory
               experiments, with the goal of identifying hidden signals that
               precede earthquakes. Here we show that by listening to the
               acoustic signal emitted by a laboratory fault, machine learning
               can predict the time remaining before it fails with great
               accuracy. These predictions are based solely on the
               instantaneous physical characteristics of the acoustical signal
               and do not make use of its history. Surprisingly, machine
               learning identifies a signal emitted from the fault zone …},
  journal   = {Geophysical},
  publisher = {Wiley Online Library},
  year      =  2017,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/2017GL074677}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{RouetLeduc2018-vd,
  title     = {Estimating fault friction from seismic signals in the laboratory},
  author    = {Rouet‐Leduc, B and Hulbert, C and Bolton, D C and {others}},
  abstract  = {Nearly all aspects of earthquake rupture are controlled by the
               friction along the fault that progressively increases with
               tectonic forcing but in general cannot be directly measured. We
               show that fault friction can be determined at any time, from the
               continuous seismic signal. In a classic laboratory experiment of
               repeating earthquakes, we find that the seismic signal follows a
               specific pattern with respect to fault friction, allowing us to
               determine the fault's position within its failure cycle. Using
               machine learning, we show that instantaneous …},
  journal   = {Geophysical},
  publisher = {Wiley Online Library},
  year      =  2018,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/2017GL076708}
}

@ARTICLE{Roth1994-na,
  title     = {Neural networks and inversion of seismic data},
  author    = {R{\"o}th, Gunter and Tarantola, Albert},
  abstract  = {Neural networks can be viewed as applications that map one
               space, the input space, into some output space. In order to
               simulate the desired mapping the network has to go through a
               learning process consisting of an iterative change of the
               internal parameters, through the presentation of many input
               patterns and their corresponding output patterns. The training
               process is accomplished if the error between the computed output
               and the desired output pattern is minimal for all examples in
               the training set. The network will then simulate the desired
               mapping on the restricted domain of the training examples. We
               describe an experiment where a neural network is designed to
               accept a synthetic common shot gather (i.e., a set of
               seismograms obtained from a single source), as its input pattern
               and to compute the corresponding one-dimensional large-scale
               velocity model as its output. The subsurface models are built up
               of eight layers with constant layer thickness over a homogeneous
               half-space, 450 examples are used to train the network. After
               the training process the network never computes a subsurface
               model which perfectly fits the desired one, but the
               approximation of the network is sufficient to take this model as
               starting model for further seismic imaging algorithms. The
               trained network computes satisfactory velocity profiles for 80\%
               of the new seismic gathers not included in the training set.
               Although the network gives results that are stable when the
               input is contaminated with white noise, the network is not
               robust against strong, i.e., correlated, noise. This application
               proves that neural networks are able to solve nontrivial inverse
               problems.},
  journal   = {J. Geophys. Res.},
  publisher = {Wiley Online Library},
  volume    =  99,
  number    = {B4},
  pages     = {6753},
  year      =  1994,
  url       = {http://doi.wiley.com/10.1029/93JB01563},
  issn      = {0148-0227},
  doi       = {10.1029/93JB01563}
}

@ARTICLE{Ross2018-rx,
  title         = {Generalized Seismic Phase Detection with Deep Learning},
  author        = {Ross, Zachary E and Meier, Men-Andrin and Hauksson, Egill
                   and Heaton, Thomas H},
  abstract      = {To optimally monitor earthquake-generating processes,
                   seismologists have sought to lower detection sensitivities
                   ever since instrumental seismic networks were started about
                   a century ago. Recently, it has become possible to search
                   continuous waveform archives for replicas of previously
                   recorded events (template matching), which has led to at
                   least an order of magnitude increase in the number of
                   detected earthquakes and greatly sharpened our view of
                   geological structures. Earthquake catalogs produced in this
                   fashion, however, are heavily biased in that they are
                   completely blind to events for which no templates are
                   available, such as in previously quiet regions or for very
                   large magnitude events. Here we show that with deep learning
                   we can overcome such biases without sacrificing detection
                   sensitivity. We trained a convolutional neural network
                   (ConvNet) on the vast hand-labeled data archives of the
                   Southern California Seismic Network to detect seismic body
                   wave phases. We show that the ConvNet is extremely sensitive
                   and robust in detecting phases, even when masked by high
                   background noise, and when the ConvNet is applied to new
                   data that is not represented in the training set (in
                   particular, very large magnitude events). This generalized
                   phase detection (GPD) framework will significantly improve
                   earthquake monitoring and catalogs, which form the
                   underlying basis for a wide range of basic and applied
                   seismological research.},
  month         =  may,
  year          =  2018,
  url           = {http://arxiv.org/abs/1805.01075},
  archivePrefix = {arXiv},
  eprint        = {1805.01075},
  primaryClass  = {physics.geo-ph},
  arxivid       = {1805.01075}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ross2018-kt,
  title     = {P‐wave arrival picking and first‐motion polarity determination
               with deep learning},
  author    = {Ross, Z E and Meier, M A and Hauksson, E},
  abstract  = {Determining earthquake hypocenters and focal mechanisms requires
               precisely measured P‐ wave arrival times and first‐motion
               polarities. Automated algorithms for estimating these quantities
               have been less accurate than estimates by human experts, which
               is problematic for processing large data volumes. Here, we train
               convolutional neural networks to measure both quantities, which
               learn directly from seismograms without the need for feature
               extraction. The networks are trained on 18.2 million manually
               picked seismograms for the …},
  journal   = {J. Geophys. Res.},
  publisher = {Wiley Online Library},
  year      =  2018,
  url       = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2017JB015251},
  issn      = {0148-0227}
}

@ARTICLE{Romeo1994-ih,
  title     = {Seismic signals detection and classification using artiricial
               neural networks},
  author    = {Romeo, G},
  abstract  = {Pattern recognition belongs to a class of Problems which are
               easily solved by humans, but difficult for computers. It is
               sometimes difficult to formalize a problem which a human
               operator can casily understand by using examples. Neural
               networks are useful in solving this kind of problem. A neural
               network may, under certain conditions, simulate a well trained
               human operator in recognizing different types of earthquakes or
               in detecting the presence of a seismic event. It is then shown
               how a fully connected multi layer perceptron may perform a
               recognition task. It is shown how a self training auto
               associative neural network may detect an earthquake occurrence
               analysing the change in signal characteristics.},
  journal   = {Annals of Geophysics},
  publisher = {annalsofgeophysics.eu},
  volume    =  37,
  number    =  3,
  month     =  nov,
  year      =  1994,
  url       = {http://www.annalsofgeophysics.eu/index.php/annals/article/view/4211},
  keywords  = {seismology;detection;neural network;auto-associative neural
               network;classification},
  issn      = {2037-416X, 2037-416X},
  doi       = {10.4401/ag-4211}
}

@ARTICLE{Rodriguez-Galiano2014-bj,
  title     = {Predictive modelling of gold potential with the integration of
               multisource information based on random forest: a case study on
               the Rodalquilar area, Southern Spain},
  author    = {Rodriguez-Galiano, V F and Chica-Olmo, M and Chica-Rivas, M},
  abstract  = {Mineral exploration activities require robust predictive models
               that result in accurate mapping of the probability that mineral
               deposits can be found at a certain location. Random forest (RF)
               is a powerful machine data-driven predictive method that is
               unknown in mineral potential mapping. In this paper, performance
               of RF regression for the likelihood of gold deposits in the
               Rodalquilar mining district is explored. The RF model was
               developed using a comprehensive exploration GIS database
               composed of: gravimetric and magnetic survey, a lithogeochemical
               survey of 59 elements, lithology and fracture maps, a Landsat 5
               Thematic Mapper image and gold occurrence locations. The results
               of this study indicate that the use of RF for the integration of
               large multisource data sets used in mineral exploration and for
               prediction of mineral deposit occurrences offers several
               advantages over existing methods. Key advantages of RF include:
               (1) the simplicity of parameter setting; (2) an internal
               unbiased estimate of the prediction error; (3) the ability to
               handle complex data of different statistical distributions,
               responding to nonlinear relationships between variables; (4) the
               capability to use categorical predictors; and (5) the capability
               to determine variable importance. Additionally, variables that
               RF identified as most important coincide with well-known
               geologic expectations. To validate and assess the effectiveness
               of the RF method, gold prospectivity maps are also prepared
               using the logistic regression (LR) method. Statistical measures
               of map quality indicate that the RF method performs better than
               LR, with mean square errors equal to 0.12 and 0.19,
               respectively. The efficiency of RF is also better, achieving an
               optimum success rate when half of the area predicted by LR is
               considered.},
  journal   = {Int. J. Geogr. Inf. Sci.},
  publisher = {Taylor \& Francis},
  volume    =  28,
  number    =  7,
  pages     = {1336--1354},
  month     =  jul,
  year      =  2014,
  url       = {https://doi.org/10.1080/13658816.2014.885527},
  issn      = {1365-8816},
  doi       = {10.1080/13658816.2014.885527}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Roden2015-ek,
  title     = {Geologic pattern recognition from seismic attributes: Principal
               component analysis and self-organizing maps},
  author    = {Roden, Rocky and Smith, Thomas and Sacrey, Deborah},
  abstract  = {Abstract Interpretation of seismic reflection data routinely
               involves powerful multiple-central- processing-unit computers,
               advanced visualization techniques, and generation of numerous
               seismic data types and attributes. Even with these technologies
               at the disposal of interpreters, there are additional techniques
               to derive even more useful information from our data. Over the
               last few years, there have been efforts to distill numerous
               seismic attributes into volumes that are easily evaluated for
               their geologic significance and improved seismic …},
  journal   = {Interpretation},
  publisher = {GeoScienceWorld},
  volume    =  3,
  number    =  4,
  pages     = {SAE59--SAE83},
  month     =  nov,
  year      =  2015,
  url       = {https://pubs.geoscienceworld.org/interpretation/article-abstract/3/4/SAE59/75892},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2015-0037.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Roden2017-pv,
  title     = {Interpretation of {DHI} characteristics with machine learning},
  author    = {Roden, R and Chen, C W},
  abstract  = {In conventional geological settings, oil companies routinely
               evaluate prospects for their drilling portfolio where the
               process of interpreting seismic amplitude anomalies as Direct
               Hydrocarbon Indicators (DHIs) plays an important role. DHIs are
               an acoustic response owing to the presence of hydrocarbons and
               can have a significant impact on prospect risking and
               determining well locations (Roden et al., 2005; Fahmy 2006;
               Forrest et al., 2010; Roden et al., 2012; Rudolph and Goulding,
               2017). DHI anomalies are caused by changes in …},
  journal   = {First Break},
  publisher = {earthdoc.org},
  year      =  2017,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=88069},
  issn      = {0263-5046}
}

@ARTICLE{Ristic2017-wl,
  title     = {Point coordinates extraction from localized hyperbolic
               reflections in {GPR} data},
  author    = {Risti{\'c}, Aleksandar and Bugarinovi{\'c}, {\v Z}eljko and
               Vrtunski, Milan and Govedarica, Miro},
  abstract  = {In this paper, we propose an automated detection algorithm for
               the localization of apexes and points on the prongs of
               hyperbolic reflection incurred as a result of GPR scanning
               technology. The objects of interest encompass cylindrical
               underground utilities that have a distinctive form of hyperbolic
               reflection in radargram. Algorithm involves application of
               trained neural network to analyze radargram in the form of
               raster image, resulting with extracted segments of interest that
               contain hyperbolic reflections. This significantly reduces the
               amount of data for further analysis. Extracted segments
               represent the zone for localization of apices. This is followed
               by extraction of points on prongs of hyperbolic reflections
               which is carried out until stopping criterion is satisfied,
               regardless the borders of segment of interest. In final step a
               classification of false hyperbolic reflections caused by the
               constructive interference and their removal is done. The
               algorithm is implemented in MATLAB environment. There are
               several advantages of the proposed algorithm. It can
               successfully recognize true hyperbolic reflections in radargram
               images and extracts coordinates, with very low rate of false
               detections and without prior knowledge about the number of
               hyperbolic reflections or buried utilities. It can be applied to
               radargrams containing single and multiple hyperbolic
               reflections, intersected, distorted, as well as incomplete
               (asymmetric) hyperbolic reflections, all in the presence of
               higher level of noise. Special feature of algorithm is developed
               procedure for analysis and removal of false hyperbolic
               reflections generated by the constructive interference from
               reflectors associated with the utilities. Algorithm was tested
               on a number of synthetic and radargram acquired in the field
               survey. To illustrate the performances of the proposed
               algorithm, we present the characteristics of the algorithm
               through five representative radargrams obtained in real
               conditions. In these examples we present different acquisition
               scenarios by varying the number of buried objects, their
               disposition, size, and level of noise. Example with highest
               complexity was tested also as a synthetic radargram generated by
               gprMax. Processing time in examples with one or two hyperbolic
               reflections is from 0.1 to 0.3s, while for the most complex
               examples it is from 2.2 to 4.9s. In general, the obtained
               experimental results show that the proposed algorithm exhibits
               promising performances both in terms of utility detection and
               processing speed of the algorithm.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  144,
  pages     = {1--17},
  month     =  sep,
  year      =  2017,
  url       = {http://www.sciencedirect.com/science/article/pii/S0926985117305670},
  keywords  = {GPR; Hyperbolic reflection; Automated extraction; Neural
               networks; MATLAB},
  issn      = {0926-9851},
  doi       = {10.1016/j.jappgeo.2017.06.003}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Riedel2014-kb,
  title     = {Macroscale Vulnerability Assessment of Cities Using Association
               Rule Learning},
  author    = {Riedel, I and Gu{\'e}guen, P and Dunand, F and Cottaz, S},
  abstract  = {After most moderate-to-strong earthquakes causing considerable
               damage (eg, recent earthquakes such as those of Boumerdes in
               2003, Bam in 2003, L'Aquila in 2009, Ha{\"\i}ti in 2010, etc.),
               the observed losses remind local authorities and decision makers
               that reducing seismic risk is essential for the well-being and
               safety of local populations, as well as for economic and social
               stability. The anticipation and simulation of the consequences
               of an earthquake scenario require knowledge of the probabilistic
               seismic hazard, as well as a …},
  journal   = {Seismol. Res. Lett.},
  publisher = {GeoScienceWorld},
  volume    =  85,
  number    =  2,
  pages     = {295--305},
  month     =  mar,
  year      =  2014,
  url       = {https://pubs.geoscienceworld.org/ssa/srl/article-abstract/85/2/295/315364},
  issn      = {0895-0695},
  doi       = {10.1785/0220130148}
}

@ARTICLE{Richardson2018-py,
  title         = {Seismic {Full-Waveform} Inversion Using Deep Learning Tools
                   and Techniques},
  author        = {Richardson, Alan},
  abstract      = {I demonstrate that the conventional seismic full-waveform
                   inversion algorithm can be constructed as a recurrent neural
                   network and so implemented using deep learning software such
                   as TensorFlow. Applying another deep learning concept, the
                   Adam optimizer with minibatches of data, produces quicker
                   convergence toward the true wave speed model on a 2D dataset
                   than Stochastic Gradient Descent and than the L-BFGS-B
                   optimizer with the cost function and gradient computed using
                   the entire training dataset. I also show that the cost
                   function gradient calculation using reverse-mode automatic
                   differentiation is the same as that used in the adjoint
                   state method.},
  month         =  jan,
  year          =  2018,
  url           = {http://arxiv.org/abs/1801.07232},
  archivePrefix = {arXiv},
  eprint        = {1801.07232},
  primaryClass  = {physics.geo-ph},
  arxivid       = {1801.07232}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Rezvanbehbahani2017-ac,
  title     = {Predicting the Geothermal Heat Flux in Greenland: A Machine
               Learning Approach},
  author    = {Rezvanbehbahani, S and Stearns, L A and {others}},
  abstract  = {Geothermal heat flux (GHF) is a crucial boundary condition for
               making accurate predictions of ice sheet mass loss, yet it is
               poorly known in Greenland due to inaccessibility of the bedrock.
               Here we use a machine learning algorithm on a large collection
               of relevant geologic features and global GHF measurements and
               produce a GHF map of Greenland that we argue is within∼ 15\%
               accuracy. The main features of our predicted GHF map include a
               large region with high GHF in central-north Greenland
               surrounding the NorthGRIP …},
  journal   = {Geophysical},
  publisher = {Wiley Online Library},
  year      =  2017,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/2017GL075661}
}

@ARTICLE{Qi2016-qy,
  title     = {Semisupervised multiattribute seismic facies analysis},
  author    = {Qi, J and Lin, T and Zhao, T and Li, F and Marfurt, K},
  abstract  = {AbstractOne of the key components of traditional seismic
               interpretation is to associate or ?label? a specific seismic
               amplitude package of reflectors with an appropriate seismic or
               geologic facies. The object of seismic clustering algorithms is
               to use a computer to accelerate this process, allowing one to
               generate interpreted facies for large 3D volumes. Determining
               which attributes best quantify a specific amplitude or
               morphology component seen by the human interpreter is critical
               to successful clustering. Unfortunately, many patterns, such as
               coherence images of salt domes, result in a salt-and-pepper
               classification. Application of 3D Kuwahara median filters
               smooths the interior attribute response and sharpens the
               contrast between neighboring facies, thereby preconditioning the
               attribute volumes for subsequent clustering. In our workflow,
               the interpreter manually painted n target facies using
               traditional interpretation techniques, resulting in attribute
               training data for each facies. Candidate attributes were
               evaluated by crosscorrelating their histogram for each facies
               with low correlation implying good facies discrimination, and
               Kuwahara filtering significantly increased this discrimination.
               Multiattribute voxels for the n interpreter-painted facies were
               projected against a generative topographical mapping manifold,
               resulting in n probability density functions (PDFs). The
               Bhattacharyya distance between the PDF of each unlabeled voxel
               to each of n facies PDFs resulted in a probability volume of
               each user-defined facies. We have determined the effectiveness
               of this workflow to a large 3D seismic volume acquired offshore
               Louisiana, USA.},
  journal   = {Interpretation},
  publisher = {Society of Exploration Geophysicists},
  volume    =  4,
  number    =  1,
  pages     = {SB91--SB106},
  month     =  feb,
  year      =  2016,
  url       = {https://doi.org/10.1190/INT-2015-0098.1},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2015-0098.1}
}

@ARTICLE{Purves2018-dy,
  title     = {Bootstrapping {Machine-Learning} Based Seismic Fault
               Interpretation},
  author    = {Purves, S and Alaei, B and Larsen, E},
  abstract  = {Seismic Interpretation represents quite a unique problem, we
               have a great density of data within seismic datasets; 2D, 3D,
               prestack, multicomponent, broadband. A wealth of measurements.
               However, we have very little in the terms of interpretation on
               which to train machine-learning models. This`` labelled'' data,
               as the term goes, is scant and insufficient for training a
               general-purpose seismic interpretation model, and this is
               unlikely to change.},
  journal   = {ACE 2018 Annual Convention \&},
  publisher = {searchanddiscovery.com},
  year      =  2018,
  url       = {http://www.searchanddiscovery.com/abstracts/html/2018/ace2018/abstracts/2856016.html}
}

@ARTICLE{Poulton1992-ft,
  title     = {Location of subsurface targets in geophysical data using neural
               networks},
  author    = {Poulton, M and Sternberg, B and Glass, C},
  abstract  = {Neural networks were used to estimate the offset, depth, and
               conductivity?area product of a conductive target given an
               electromagnetic ellipticity image of the target. Five different
               neural network paradigms and five different representations of
               the ellipticity image were compared. The networks were trained
               with synthetic images of the target and tested on field data and
               more synthetic data. The extrapolation capabilities of the
               networks were also tested with synthetic data lying outside the
               spatial limits of the training set. The data representations
               consisted of the whole image, the subsampled image, the peak and
               adjacent troughs, the peak, and components from a
               two?dimensional (2-D) fast Fourier transform. The paradigms
               tested were standard back propagation, directed random search,
               functional link, extended delta bar delta, and the hybrid
               combination of self?organizing map and back propagation. For
               input patterns with less than 100 elements, the directed random
               search and functional link networks gave the best results. For
               patterns with more than 100 elements, self?organizing map to
               back propagation was most accurate. Using the whole ellipticity
               image gave the most accurate results for all the network
               paradigms. The fast Fourier transform data representation also
               yielded good results with a much faster computation time.
               Average accuracies of offset, depth, and conductivity?area
               product as high as 97 percent could be achieved for test and
               field data and 88 percent for extrapolation data.},
  journal   = {Geophysics},
  publisher = {Society of Exploration Geophysicists},
  volume    =  57,
  number    =  12,
  pages     = {1534--1544},
  month     =  dec,
  year      =  1992,
  url       = {https://doi.org/10.1190/1.1443221},
  issn      = {0016-8033},
  doi       = {10.1190/1.1443221}
}

@ARTICLE{Porwal2003-pm,
  title     = {Artificial Neural Networks for {Mineral-Potential} Mapping: A
               Case Study from Aravalli Province, Western India},
  author    = {Porwal, Alok and Carranza, E J M and Hale, M},
  abstract  = {This paper describes a GIS-based application of a radial basis
               functional link net (RBFLN) to map the potential of SEDEX-type
               base metal deposits in a study area in the Aravalli metallogenic
               province (western India). Available public domain geodata of the
               study area were processed to generate evidential maps, which
               subsequently were encoded and combined to derive a set of input
               feature vectors. A subset of feature vectors with known targets
               (i.e., either known mineralized or known barren locations) was
               extracted and divided into (a) a training data set and (b) a
               validation data set. A series of RBFLNs were trained to
               determine the network architecture and estimate parameters that
               mapped the maximum number of validation vectors correctly to
               their respective targets. The trained RBFLN that gave the best
               performance for the validation data set was used for processing
               all feature vectors. The output for each feature vector is a
               predictive value between 1 and 0, indicating the extent to which
               a feature vector belongs to either the mineralized or the barren
               class. These values were mapped to generate a predictive
               classification map, which was reclassified into a favorability
               map showing zones with high, moderate and low favorability for
               SEDEX-type base metal deposits in the study area. The method
               demarcates successfully high favorability zones, which occupy
               6\% of the study area and contain 94\% of the known base metal
               deposits.},
  journal   = {Nat. Resour. Res.},
  publisher = {Springer},
  volume    =  12,
  number    =  3,
  pages     = {155--171},
  month     =  sep,
  year      =  2003,
  url       = {https://doi.org/10.1023/A:1025171803637},
  issn      = {1520-7439, 1573-8981},
  doi       = {10.1023/A:1025171803637}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Plotkin2014-gk,
  title     = {Distinguishing meanders of the {K} uroshio using machine
               learning},
  author    = {Plotkin, D A and Weare, J and Abbot, D S},
  abstract  = {Abstract The Kuroshio south of Japan is often described as being
               bimodal, with abrupt transitions between a straight path state
               that stays near the coast (small meander) and a meandering state
               that deviates from the coast (large meander). Despite evidence
               of the existence of two or more states of the Kuroshio, previous
               data‐driven studies have shown only high variability of the
               current; they have not, however, demonstrated bimodality in the
               sense of two states of relatively high probability separated by
               a region of relatively low …},
  journal   = {J. Geophys. Res.},
  publisher = {Wiley Online Library},
  year      =  2014,
  url       = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1002/2014JC010128},
  issn      = {0148-0227}
}

@ARTICLE{Petrelli2016-yt,
  title     = {Solving petrological problems through machine learning: the
               study case of tectonic discrimination using geochemical and
               isotopic data},
  author    = {Petrelli, Maurizio and Perugini, Diego},
  abstract  = {Machine-learning methods are evaluated to study the intriguing
               and debated topic of discrimination among different tectonic
               environments using geochemical and isotopic data. Volcanic rocks
               characterized by a whole geochemical signature of major elements
               (SiO2, TiO2, Al2O3, Fe2O3T, CaO, MgO, Na2O, K2O), selected trace
               elements (Sr, Ba, Rb, Zr, Nb, La, Ce, Nd, Hf, Sm, Gd, Y, Yb, Lu,
               Ta, Th) and isotopes (206Pb/204Pb, 207Pb/204Pb, 208Pb/204Pb,
               87Sr/86Sr and 143Nd/144Nd) have been extracted from open-access
               and comprehensive petrological databases (i.e., PetDB and
               GEOROC). The obtained dataset has been analyzed using support
               vector machines, a set of supervised machine-learning methods,
               which are considered particularly powerful in classification
               problems. Results from the application of the machine-learning
               methods show that the combined use of major, trace elements and
               isotopes allows associating the geochemical composition of rocks
               to the relative tectonic setting with high classification scores
               (93 \%, on average). The lowest scores are recorded from
               volcanic rocks deriving from back-arc basins (65 \%). All the
               other tectonic settings display higher classification scores,
               with oceanic islands reaching values up to 99 \%. Results of
               this study could have a significant impact in other petrological
               studies potentially opening new perspectives for petrologists
               and geochemists. Other examples of applications include the
               development of more robust geothermometers and geobarometers and
               the recognition of volcanic sources for tephra layers in
               tephro-chronological studies.},
  journal   = {Contrib. Mineral. Petrol.},
  publisher = {Springer},
  volume    =  171,
  number    =  10,
  pages     = {81},
  month     =  sep,
  year      =  2016,
  url       = {https://doi.org/10.1007/s00410-016-1292-2},
  issn      = {0010-7999, 1432-0967},
  doi       = {10.1007/s00410-016-1292-2}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Pedersen2002-de,
  title     = {Automatic fault extraction using artificial ants},
  author    = {Pedersen, S I and Randen, T and Sonneland, L and {others}},
  abstract  = {A novel fault extraction procedure for 3D seismic is presented.
               The procedure consists of three steps. The first step enhances
               the spatial discontinuities in the seismic data (fault attribute
               generation). The second step significantly improves the fault
               attributes by suppressing noise and remains of non-faulting
               events. This is achieved by the cooperative behavior of
               thousands of ``artificial ants''. The advantages with this
               method will be demonstrated. In particular, the faults can be
               split into different nonintersecting sub-systems …},
  journal   = {SEG Technical Program},
  publisher = {library.seg.org},
  year      =  2002,
  url       = {https://library.seg.org/doi/pdf/10.1190/1.1817297}
}

@ARTICLE{Patel2016-vp,
  title     = {Computer vision-based limestone rock-type classification using
               probabilistic neural network},
  author    = {Patel, Ashok Kumar and Chatterjee, Snehamoy},
  abstract  = {Proper quality planning of limestone raw materials is an
               essential job of maintaining desired feed in cement plant.
               Rock-type identification is an integrated part of quality
               planning for limestone mine. In this paper, a computer
               vision-based rock-type classification algorithm is proposed for
               fast and reliable identification without human intervention. A
               laboratory scale vision-based model was developed using
               probabilistic neural network (PNN) where color histogram
               features are used as input. The color image histogram-based
               features that include weighted mean, skewness and kurtosis
               features are extracted for all three color space red, green, and
               blue. A total nine features are used as input for the PNN
               classification model. The smoothing parameter for PNN model is
               selected judicially to develop an optimal or close to the
               optimum classification model. The developed PPN is validated
               using the test data set and results reveal that the proposed
               vision-based model can perform satisfactorily for classifying
               limestone rock-types. Overall the error of mis-classification is
               below 6\%. When compared with other three classification
               algorithms, it is observed that the proposed method performs
               substantially better than all three classification algorithms.},
  journal   = {Geoscience Frontiers},
  publisher = {Elsevier},
  volume    =  7,
  number    =  1,
  pages     = {53--60},
  month     =  jan,
  year      =  2016,
  url       = {http://www.sciencedirect.com/science/article/pii/S1674987114001388},
  keywords  = {Supervised classification; Probabilistic neural network;
               Histogram based features; Smoothing parameter; Limestone},
  issn      = {1674-9871},
  doi       = {10.1016/j.gsf.2014.10.005}
}

@ARTICLE{Pasolli2009-dy,
  title     = {Automatic Analysis of {GPR} Images: A {Pattern-Recognition}
               Approach},
  author    = {Pasolli, E and Melgani, F and Donelli, M},
  abstract  = {In this paper, we propose a novel pattern-recognition system to
               identify and classify buried objects from ground-penetrating
               radar (GPR) imagery. The entire process is subdivided into four
               steps. After a preprocessing step, the GPR image is thresholded
               to put under light the regions containing potential objects. The
               third step of the system consists of automatically detecting the
               objects in the obtained binary image by means of a search of
               linear/hyperbolic patterns formulated within a genetic
               optimization framework. In the genetic optimizer, each
               chromosome models the apex position and the curvature associated
               with the candidate pattern, while the fitness function expresses
               the Hamming distance between that pattern and the binary image
               content. Finally, in the fourth step, the problem of the
               recognition of the material type of the identified objects is
               approached as a classification issue, which is solved by means
               of an opportune feature-extraction strategy and a support vector
               machine classifier. To illustrate the performances of the
               proposed system, we conducted a thorough experimental study
               based on GPR images generated by a GPR simulator based on the
               finite-difference time-domain method so as to construct
               different acquisition scenarios by varying the number of buried
               objects, their position, their size, their shape, and their
               material type. In general, the obtained experimental results
               show that the proposed system exhibits promising performances
               both in terms of object detection and material recognition.},
  journal   = {IEEE Trans. Geosci. Remote Sens.},
  publisher = {ieeexplore.ieee.org},
  volume    =  47,
  number    =  7,
  pages     = {2206--2217},
  month     =  jul,
  year      =  2009,
  url       = {http://dx.doi.org/10.1109/TGRS.2009.2012701},
  keywords  = {buried object detection;feature extraction;finite difference
               time-domain analysis;geophysical techniques;geophysics
               computing;ground penetrating radar;image classification;support
               vector machines;ground-penetrating radar;GPR image
               analysis;pattern-recognition system;buried objects
               classification;objects detection;binary image;linear/hyperbolic
               patterns;genetic optimization framework;chromosome
               models;feature-extraction strategy;support vector machine
               classifier;finite-difference time-domain method;material
               recognition method;Image analysis;Pattern analysis;Ground
               penetrating radar;Buried object detection;Object
               detection;Genetics;Conducting materials;Radar
               detection;Biological cells;Hamming distance;Buried
               objects;feature extraction;genetic algorithms
               (GAs);ground-penetrating radar (GPR);pattern recognition;support
               vector machine (SVM)},
  issn      = {0196-2892},
  doi       = {10.1109/TGRS.2009.2012701}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Parra2015-rh,
  title     = {Attenuation and velocity estimation using rock physics and
               neural network methods for calibrating reflection seismograms},
  author    = {Parra, Jorge O and Iturrar{\'a}n-Viveros, Ursula and Parra,
               Jonathan S and Xu, Pei-Cheng},
  abstract  = {Velocity logs are the most important data used to evaluate rock,
               fluid, and geotechnical properties of hydrocarbon reservoirs. As
               a complementary physical property, P-wave attenuation (Q− 1) can
               be used as an indicator of lithology and fluid saturation in oil
               and gas reservoir characterization. We implemented an inversion
               self-consistent rock physical model to predict P-and S-wave
               velocities in two old wells near a new well containing a
               complete suite of logs at the Waggoner Ranch oil reservoir in
               northeast Texas. We selected a training …},
  journal   = {Interpretation},
  publisher = {GeoScienceWorld},
  volume    =  3,
  number    =  1,
  pages     = {SA121--SA133},
  month     =  feb,
  year      =  2015,
  url       = {https://pubs.geoscienceworld.org/sepm/interpretation/article/3/1/SA121/75811},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2014-0175.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Papacharalampous2018-xn,
  title     = {One-step ahead forecasting of geophysical processes within a
               purely statistical framework},
  author    = {Papacharalampous, Georgia and Tyralis, Hristos and
               Koutsoyiannis, Demetris},
  abstract  = {The simplest way to forecast geophysical processes, an
               engineering problem with a widely recognized challenging
               character, is the so-called ``univariate time series
               forecasting'' that can be implemented using stochastic or
               machine learning regression models within a purely statistical
               framework. Regression models are in general fast-implemented, in
               contrast to the computationally intensive Global Circulation
               Models, which constitute the most frequently used alternative
               for precipitation and temperature forecasting. For their
               simplicity and easy applicability, the former have been proposed
               as benchmarks for the latter by forecasting scientists. Herein,
               we assess the one-step ahead forecasting performance of 20
               univariate time series forecasting methods, when applied to a
               large number of geophysical and simulated time series of 91
               values. We use two real-world annual datasets, a dataset
               composed by 112 time series of precipitation and another
               composed by 185 time series of temperature, as well as their
               respective standardized datasets, to conduct several real-world
               experiments. We further conduct large-scale experiments using 12
               simulated datasets. These datasets contain 24,000 time series in
               total, which are simulated using stochastic models from the
               families of AutoRegressive Moving Average and AutoRegressive
               Fractionally Integrated Moving Average. We use the first 50, 60,
               70, 80 and 90 data points for model-fitting and
               model-validation, and make predictions corresponding to the
               51st, 61st, 71st, 81st and 91st respectively. The total number
               of forecasts produced herein is 2,177,520, among which 47,520
               are obtained using the real-world datasets. The assessment is
               based on eight error metrics and accuracy statistics. The
               simulation experiments reveal the most and least accurate
               methods for long-term forecasting applications, also suggesting
               that the simple methods may be competitive in specific cases.
               Regarding the results of the real-world experiments using the
               original (standardized) time series, the minimum and maximum
               medians of the absolute errors are found to be 68 mm (0.55) and
               189 mm (1.42) respectively for precipitation, and 0.23 °C (0.33)
               and 1.10 °C (1.46) respectively for temperature. Since there is
               an absence of relevant information in the literature, the
               numerical results obtained using the standardized real-world
               datasets could be used as rough benchmarks for the one-step
               ahead predictability of annual precipitation and temperature.},
  journal   = {Geoscience Letters},
  publisher = {Nature Publishing Group},
  volume    =  5,
  number    =  1,
  pages     = {12},
  month     =  apr,
  year      =  2018,
  url       = {https://geoscienceletters.springeropen.com/articles/10.1186/s40562-018-0111-1},
  language  = {en},
  issn      = {2196-4092, 2196-4092},
  doi       = {10.1186/s40562-018-0111-1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Olivier2018-di,
  title     = {Using Supervised Machine Learning to Improve Active Source
               Signal Retrieval},
  author    = {Olivier, Gerrit and Chaput, Julien and Borchers, Brian},
  abstract  = {Nondestructive active seismic sources have been successfully
               used to image and monitor the earth on many different scales.
               Although the raw signals generated by these sources can be weak,
               the signals can be retrieved over great distances using seismic
               interferometry and stacking. When using these methods, a major
               limiting factor on range and signal‐to‐noise ratio of the
               retrieved signal is the presence of persistent noise sources in
               the same frequency range as the signal from the active source.
               In this article, we will introduce a …},
  journal   = {Seismol. Res. Lett.},
  publisher = {GeoScienceWorld},
  volume    =  89,
  number    =  3,
  pages     = {1023--1029},
  month     =  may,
  year      =  2018,
  url       = {https://pubs.geoscienceworld.org/ssa/srl/article-abstract/89/3/1023/530133},
  issn      = {0895-0695},
  doi       = {10.1785/0220170239}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Ohrnberger2001-cq,
  title        = {[No title]},
  author       = {Ohrnberger, M},
  abstract     = {Merapi volcano, located in the central part of Java island,
                  Indonesia, is considered to be one of the most active and
                  dangerous volcanoes of the world. The danger of Merapi
                  evolves from its eruptive behavior, which is mainly
                  characterized by the frequent occurrence of pyroclastic flows
                  and occasional vulcanian eruptions. Due to its location in
                  the magmatic arc of the subduction zone formed by the
                  Indo-Australian and Eurasian Plate boundary (see Fig. 2.1),
                  Merapi's magmatism is basaltic-andesitic, with SiO2 contents
                  ranging from 50 …},
  publisher    = {researchgate.net},
  year         =  2001,
  url          = {https://www.researchgate.net/profile/Matthias_Ohrnberger/publication/252958874_Continuous_Automatic_Classification_of_Seismic_Signals_of_Volcanic_Origin_at_Mt_Merapi_Java_Indonesia/links/573ffe3e08aea45ee84504a4/Continuous-Automatic-Classification-of-Seismic-Signals-of-Volcanic-Origin-at-Mt-Merapi-Java-Indonesia.pdf},
  howpublished = {\url{https://www.researchgate.net/profile/Matthias_Ohrnberger/publication/252958874_Continuous_Automatic_Classification_of_Seismic_Signals_of_Volcanic_Origin_at_Mt_Merapi_Java_Indonesia/links/573ffe3e08aea45ee84504a4/Continuous-Automatic-Classification-of-Seismic-Signals-of-Volcanic-Origin-at-Mt-Merapi-Java-Indonesia.pdf}},
  note         = {Accessed: 2018-12-17}
}

@ARTICLE{Oh2010-wm,
  title     = {Application of Artificial Neural Network for {Gold--Silver}
               Deposits Potential Mapping: A Case Study of Korea},
  author    = {Oh, Hyun-Joo and Lee, Saro},
  abstract  = {The aim of this study is to analyze hydrothermal gold--silver
               mineral deposits potential in the Taebaeksan mineralized
               district, Korea, using an artificial neural network (ANN) and a
               geographic information system (GIS) environment. A spatial
               database considering 46 Au and Ag deposits, geophysical,
               geological, and geochemical data was constructed for the study
               area using the GIS. The geospatial factors were used with the
               ANN to analyze mineral potential. The Au and Ag mineral deposits
               were randomly divided into a training set (70\%) to analyze
               mineral potential using ANN and a test set (30\%) to validate
               predicted potential map. Four different training datasets
               determined from likelihood ratio and weight of evidence models
               were applied to analyze and validate the effect of training.
               Then, the mineral potential index (MPI) was calculated using the
               trained back-propagation weights, and mineral potential maps
               (MPMs) were constructed from GIS data for the four training
               cases. The MPMs were then validated by comparison with the test
               mineral occurrences. The validation results gave respective
               accuracies of 73.06, 73.52, 70.11, and 73.10\% for the training
               cases. The comparison results of some training cases showed less
               sensitive to training data from likelihood ratio than weight of
               evidence. Overall, the training cases selected from 10\% area
               with low and high index value of MPML and MPMW gave higher
               accuracy (73.52 and 73.10\%) for MPMs than those (73.06 and
               70.11\%, respectively) from known deposits and 10\% area with
               low index value of MPIL and MPIW.},
  journal   = {Nat. Resour. Res.},
  publisher = {Springer},
  volume    =  19,
  number    =  2,
  pages     = {103--124},
  month     =  jun,
  year      =  2010,
  url       = {https://doi.org/10.1007/s11053-010-9112-2},
  issn      = {1520-7439, 1573-8981},
  doi       = {10.1007/s11053-010-9112-2}
}

@ARTICLE{Ochoa2018-wp,
  title     = {Fast magnitude determination using a single seismological
               station record implementing machine learning techniques},
  author    = {Ochoa, Luis H and Ni{\~n}o, Luis F and Vargas, Carlos A},
  abstract  = {In this work a Support Vector Machine Regression (SVMR)
               algorithm is used to calculate local magnitude (Ml) using only
               five seconds of signal after the P wave onset of one three
               component seismic station. This algorithm was trained with 863
               records of historical earthquakes, where the input regression
               parameters were an exponential function of the waveform envelope
               estimated by least squares and the maximum value of the observed
               waveform for each component in a single station. Ten-fold cross
               validation was applied for a normalized polynomial kernel
               obtaining the mean absolute error for different exponents and
               complexity parameters. The local magnitude (Ml) could be
               estimated with 0.19 units of mean absolute error. The proposed
               algorithm is easy to implement in hardware and may be used
               directly after the field seismological sensor to generate fast
               decisions at seismological control centers, increasing the
               possibility of having an effective reaction.},
  journal   = {Geodesy and Geodynamics},
  publisher = {Elsevier},
  volume    =  9,
  number    =  1,
  pages     = {34--41},
  month     =  jan,
  year      =  2018,
  url       = {http://www.sciencedirect.com/science/article/pii/S1674984717300058},
  keywords  = {Earthquake early warning; Support Vector Machine Regression;
               Earthquake; Rapid response; Local magnitude; Seismic event;
               Seismology; Bogota; Colombia},
  issn      = {1674-9847},
  doi       = {10.1016/j.geog.2017.03.010}
}

@ARTICLE{OBrien2015-vs,
  title     = {Using Random Forests to distinguish gahnite compositions as an
               exploration guide to Broken Hill-type {Pb--Zn--Ag} deposits in
               the Broken Hill domain, Australia},
  author    = {O'Brien, Joshua J and Spry, Paul G and Nettleton, Dan and Xu,
               Ruo and Teale, Graham S},
  abstract  = {Various studies have focused on evaluating variability in the
               major-trace element chemistry of minerals as exploration guides
               to metallic mineral deposits or diamond-bearing kimberlites. The
               chemistry of gahnite has previously been proposed as an
               exploration guide to Broken Hill-type Pb--Zn--Ag mineralization
               in the Broken Hill domain, Australia, with the development of a
               series of discrimination plots to compare the composition of
               gahnite from the supergiant Broken Hill deposit with those in
               occurrences of minor Broken Hill-type mineralization. Here, the
               performance of Random Forests, a relatively new statistical
               technique, is used to classify mineral chemistry using a
               database (n=533) of gahnite compositions (i.e., Mg, Al, V, Cr,
               Mn, Fe, Co, Ni, Zn, Ga, and Cd) from the Broken Hill deposit and
               11 minor Broken Hill-type deposits in the Broken Hill domain.
               This statistical method has yet to be applied to geological
               problems involving mineral chemistry. Random Forests provide a
               framework for classification and decision making through a
               series of classification trees, which individually, resemble
               classification keys. Gahnite from the Broken Hill domain is
               classified here on the basis of the following schemes: 1. Random
               Forest 1 (RF1): gahnite in the Broken Hill deposit versus
               compositions of gahnite from other minor Broken Hill-type
               occurrences in the Broken Hill domain; 2. Random Forest 2 (RF2):
               gahnite in the Broken Hill deposit versus gahnite in minor
               Broken Hill-type deposits containing>0.25milliontonnes (Mt) of
               Pb--Zn--Ag mineralization versus gahnite in sulfide-free and
               sulfide-poor prospects containing<0.25Mt; and 3. Random Forest 3
               (RF3): gahnite in sulfide-bearing quartz--gahnite lode rocks
               versus gahnite in sulfide-free samples. Misclassification rates,
               according to a ten-fold cross validation, of RF1, RF2, and RF3
               are 1.6, 3.3, and 4.7\% respectively. Results of this study
               suggest that Random Forests work well in classification problems
               involving mineral chemistry, and may prove useful in the
               exploration for Broken Hill-type and other types of metallic
               mineral deposits.},
  journal   = {J. Geochem. Explor.},
  publisher = {Elsevier},
  volume    =  149,
  pages     = {74--86},
  month     =  feb,
  year      =  2015,
  url       = {http://www.sciencedirect.com/science/article/pii/S0375674214003793},
  keywords  = {Random Forests; Gahnite; Broken Hill; Statistics; Exploration},
  issn      = {0375-6742},
  doi       = {10.1016/j.gexplo.2014.11.010}
}

@ARTICLE{Nunez-Nieto2014-il,
  title     = {{GPR} Signal Characterization for Automated Landmine and {UXO}
               Detection Based on Machine Learning Techniques},
  author    = {N{\'u}{\~n}ez-Nieto, Xavier and Solla, Mercedes and
               G{\'o}mez-P{\'e}rez, Paula and Lorenzo, Henrique},
  abstract  = {Landmine clearance is an ongoing problem that currently affects
               millions of people around the world. This study evaluates the
               effectiveness of ground penetrating radar (GPR) in demining and
               unexploded ordnance detection using 2.3-GHz and 1-GHz
               high-frequency antennas. An automated detection tool based on
               machine learning techniques is also presented with the aim of
               automatically detecting underground explosive artifacts. A GPR
               survey was conducted on a designed scenario that included the
               most commonly buried items in historic battle fields, such as
               mines, projectiles and mortar grenades. The buried targets were
               identified using both frequencies, although the higher vertical
               resolution provided by the 2.3-GHz antenna allowed for better
               recognition of the reflection patterns. The targets were also
               detected automatically using machine learning techniques. Neural
               networks and logistic regression algorithms were shown to be
               able to discriminate between potential targets and clutter. The
               neural network had the most success, with accuracies ranging
               from 89\% to 92\% for the 1-GHz and 2.3-GHz antennas,
               respectively.},
  journal   = {Remote Sensing},
  publisher = {Multidisciplinary Digital Publishing Institute},
  volume    =  6,
  number    =  10,
  pages     = {9729--9748},
  month     =  oct,
  year      =  2014,
  url       = {https://www.mdpi.com/2072-4292/6/10/9729/htm},
  language  = {en},
  doi       = {10.3390/rs6109729}
}

@ARTICLE{Namekar2009-di,
  title     = {Neural network for tsunami and runup forecast},
  author    = {Namekar, Shailesh and Yamazaki, Yoshiki and Cheung, Kwok Fai},
  abstract  = {This paper examines the use of neural network to model nonlinear
               tsunami processes for forecasting of coastal waveforms and
               runup. The three-layer network utilizes a radial basis function
               in the hidden, middle layer for nonlinear transformation of
               input waveforms near the tsunami source. Events based on the
               2006 Kuril Islands tsunami demonstrate the implementation and
               capability of the network. Division of the Kamchatka-Kuril
               subduction zone into a number of subfaults facilitates
               development of a representative tsunami dataset using a
               nonlinear long-wave model. The computed waveforms near the
               tsunami source serve as the input and the far-field waveforms
               and runup provide the target output for training of the network
               through a back-propagation algorithm. The trained network
               reproduces the resonance of tsunami waves and the
               topography-dominated runup patterns at Hawaii's coastlines from
               input water-level data off the Aleutian Islands.},
  journal   = {Geophys. Res. Lett.},
  publisher = {Wiley Online Library},
  volume    =  36,
  number    =  8,
  pages     = {203},
  month     =  apr,
  year      =  2009,
  url       = {http://doi.wiley.com/10.1029/2009GL037184},
  issn      = {0094-8276},
  doi       = {10.1029/2009GL037184}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Nikolov2015-dg,
  title     = {Application of Machine Learning Method in Classification of Rock
               Types in Open Pit Mines},
  author    = {Nikolov, H S},
  abstract  = {Support vector (SV) method for classification originates from
               supervised machine learning methods. Although theoretically
               developed in the 70-ties of the 20-th century it was
               significantly improved in theory and practically implemented in
               the late 90-ties. Originally intended and elaborated as two
               class separation procedure it was latter transformed in robust
               multiclass classification technique. In this research the SV
               based technique for classification has been used for
               discrimination of rock types found in and around the open …},
  journal   = {8th Congress of the Balkan Geophysical Society},
  publisher = {earthdoc.org},
  year      =  2015,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=82844}
}

@ARTICLE{Naimi2014-kr,
  title     = {Estimation of Reservoir Porosity and Water Saturation Based on
               Seismic Attributes Using Support Vector Regression Approach},
  author    = {Na'imi, S R and Shadizadeh, S R and Riahi, M A and Mirzakhanian,
               M},
  abstract  = {Porosity and fluid saturation distributions are crucial
               properties of hydrocarbon reservoirs and are involved in almost
               all calculations related to reservoir and production. True
               measurements of these parameters derived from laboratory
               measurements, are only available at the isolated localities of a
               reservoir and also are expensive and time-consuming. Therefore,
               employing other methodologies which have stiffness, simplicity,
               and cheapness is needful. Support Vector Regression approach is
               a moderately novel method for doing functional estimation in
               regression problems. Contrary to conventional neural networks
               which minimize the error on the training data by the use of
               usual Empirical Risk Minimization principle, Support Vector
               Regression minimizes an upper bound on the anticipated risk by
               means of the Structural Risk Minimization principle. This
               difference which is the destination in statistical learning
               causes greater ability of this approach for generalization
               tasks. In this study, first, appropriate seismic attributes
               which have an underlying dependency with reservoir porosity and
               water saturation are extracted. Subsequently, a non-linear
               support vector regression algorithm is utilized to obtain
               quantitative formulation between porosity and water saturation
               parameters and selected seismic attributes. For an undrilled
               reservoir, in which there are no sufficient core and log data,
               it is moderately possible to characterize hydrocarbon bearing
               formation by means of this method.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  107,
  pages     = {93--101},
  month     =  aug,
  year      =  2014,
  url       = {http://www.sciencedirect.com/science/article/pii/S0926985114001451},
  keywords  = {Porosity; Water saturation; Seismic Attributes; Support Vector
               Regression (SVR)},
  issn      = {0926-9851},
  doi       = {10.1016/j.jappgeo.2014.05.011}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Musil1996-xj,
  title     = {Discrimination between local microearthquakes and quarry blasts
               by multi-layer perceptrons and Kohonen maps},
  author    = {Musil, Miloslav and Ple{\v s}inger, Axel},
  abstract  = {The results of the application of artificial neural nets (ANNs)
               to discriminating microearthquakes from quarry and mining blasts
               in the West Bohemia earthquake swarm region are presented and
               discussed. Input vectors consisting of seven spectral and seven
               amplitude parameters, automatically extracted from local
               three-component digital broadband (0.6 to 60 Hz) velocigrams,
               have been employed for training of different ANN configurations.
               Multi-layer perceptrons (MLP) trained in supervised mode by
               different …},
  journal   = {Bull. Seismol. Soc. Am.},
  publisher = {GeoScienceWorld},
  volume    =  86,
  number    =  4,
  pages     = {1077--1090},
  month     =  aug,
  year      =  1996,
  url       = {https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/86/4/1077/120135},
  issn      = {0037-1106}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Musil1996-ch,
  title     = {Discrimination between local microearthquakes and quarry blasts
               by multi-layer perceptrons and Kohonen maps},
  author    = {Musil, Miloslav and Ple{\v s}inger, Axel},
  abstract  = {The results of the application of artificial neural nets (ANNs)
               to discriminating microearthquakes from quarry and mining blasts
               in the West Bohemia earthquake swarm region are presented and
               discussed. Input vectors consisting of seven spectral and seven
               amplitude parameters, automatically extracted from local
               three-component digital broadband (0.6 to 60 Hz) velocigrams,
               have been employed for training of different ANN configurations.
               Multi-layer perceptrons (MLP) trained in supervised mode by
               different …},
  journal   = {Bull. Seismol. Soc. Am.},
  publisher = {GeoScienceWorld},
  volume    =  86,
  number    =  4,
  pages     = {1077--1090},
  month     =  aug,
  year      =  1996,
  url       = {https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/86/4/1077/120135},
  issn      = {0037-1106}
}

@ARTICLE{Murat1992-qs,
  title     = {{AUTOMATED} {FIRST} {ARRIVAL} {PICKING}: A {NEURAL} {NETWORK}
               {APPROACH1}},
  author    = {Murat, Michael E and Rudman, Albert J},
  abstract  = {Abstract A back-propagation neural network is successfully
               applied to pick first arrivals (first breaks) in a background of
               noise. Network output is a decision whether each half-cycle on
               the trace is a first or not. 3D plots of the input attributes
               allow evaluation of the attributes for use in a neural network.
               Clustering and separation of first break from non-break data on
               the plots indicate that a neural network solution is possible,
               and therefore the attributes are suitable as network input.
               Application of the trained network to actual seismic data
               (Vibroseis and Poulter sources) demonstrates successful
               automated first-break selection for the following four
               attributes used as neural network input: (1) peak amplitude of a
               half-cycle; (2) amplitude difference between the peak value of
               the half-cycle and the previous (or following) half-cycle; (3)
               rms amplitude ratio for a data window (0.3 s) before and after
               the half-cycle; (4) rms amplitude ratio for a data window (0.06
               s) on adjacent traces. The contribution of the attributes based
               on adjacent traces (4) was considered significant and future
               work will emphasize this aspect.},
  journal   = {Geophys. Prospect.},
  publisher = {Wiley Online Library},
  volume    =  40,
  number    =  6,
  pages     = {587--604},
  month     =  aug,
  year      =  1992,
  url       = {http://doi.wiley.com/10.1111/j.1365-2478.1992.tb00543.x},
  issn      = {0016-8025, 1365-2478},
  doi       = {10.1111/j.1365-2478.1992.tb00543.x}
}

@ARTICLE{Mosser2018-cr,
  title         = {Conditioning of three-dimensional generative adversarial
                   networks for pore and reservoir-scale models},
  author        = {Mosser, Lukas and Dubrule, Olivier and Blunt, Martin J},
  abstract      = {Geostatistical modeling of petrophysical properties is a key
                   step in modern integrated oil and gas reservoir studies.
                   Recently, generative adversarial networks (GAN) have been
                   shown to be a successful method for generating unconditional
                   simulations of pore- and reservoir-scale models. This
                   contribution leverages the differentiable nature of neural
                   networks to extend GANs to the conditional simulation of
                   three-dimensional pore- and reservoir-scale models. Based on
                   the previous work of Yeh et al. (2016), we use a content
                   loss to constrain to the conditioning data and a perceptual
                   loss obtained from the evaluation of the GAN discriminator
                   network. The technique is tested on the generation of
                   three-dimensional micro-CT images of a Ketton limestone
                   constrained by two-dimensional cross-sections, and on the
                   simulation of the Maules Creek alluvial aquifer constrained
                   by one-dimensional sections. Our results show that GANs
                   represent a powerful method for sampling conditioned pore
                   and reservoir samples for stochastic reservoir evaluation
                   workflows.},
  month         =  feb,
  year          =  2018,
  url           = {http://arxiv.org/abs/1802.05622},
  archivePrefix = {arXiv},
  eprint        = {1802.05622},
  primaryClass  = {stat.ML},
  arxivid       = {1802.05622}
}

@ARTICLE{Mosser2018-hm,
  title         = {Stochastic seismic waveform inversion using generative
                   adversarial networks as a geological prior},
  author        = {Mosser, Lukas and Dubrule, Olivier and Blunt, Martin J},
  abstract      = {We present an application of deep generative models in the
                   context of partial-differential equation (PDE) constrained
                   inverse problems. We combine a generative adversarial
                   network (GAN) representing an a priori model that creates
                   subsurface geological structures and their petrophysical
                   properties, with the numerical solution of the PDE governing
                   the propagation of acoustic waves within the earth's
                   interior. We perform Bayesian inversion using an approximate
                   Metropolis-adjusted Langevin algorithm (MALA) to sample from
                   the posterior given seismic observations. Gradients with
                   respect to the model parameters governing the forward
                   problem are obtained by solving the adjoint of the acoustic
                   wave equation. Gradients of the mismatch with respect to the
                   latent variables are obtained by leveraging the
                   differentiable nature of the deep neural network used to
                   represent the generative model. We show that approximate
                   MALA sampling allows efficient Bayesian inversion of model
                   parameters obtained from a prior represented by a deep
                   generative model, obtaining a diverse set of realizations
                   that reflect the observed seismic response.},
  month         =  jun,
  year          =  2018,
  url           = {http://arxiv.org/abs/1806.03720},
  archivePrefix = {arXiv},
  eprint        = {1806.03720},
  primaryClass  = {physics.geo-ph},
  arxivid       = {1806.03720}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Mosser2018-nf,
  title     = {Rapid seismic domain transfer: Seismic velocity inversion and
               modeling using deep generative neural networks},
  author    = {Mosser, L and Kimman, W and Dramsch, J and Purves, S and
               {others}},
  abstract  = {Traditional physics-based approaches to infer sub-surface
               properties such as full-waveform inversion or reflectivity
               inversion are time-consuming and computationally expensive. We
               present a deep-learning technique that eliminates the need for
               these computationally complex methods by posing the problem as
               one of domain transfer. Our solution is based on a deep
               convolutional generative adversarial network and dramatically
               reduces computation time. Training based on two different types
               of synthetic data produced a neural net that …},
  journal   = {EAGE Conference and …},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=92120}
}

@ARTICLE{Mosser2018-gl,
  title     = {Stochastic Reconstruction of an Oolitic Limestone by Generative
               Adversarial Networks},
  author    = {Mosser, Lukas and Dubrule, Olivier and Blunt, Martin J},
  abstract  = {Stochastic image reconstruction is a key part of modern digital
               rock physics and material analysis that aims to create
               representative samples of microstructures for upsampling,
               upscaling and uncertainty quantification. We present new results
               of a method of three-dimensional stochastic image reconstruction
               based on generative adversarial neural networks (GANs). GANs are
               a family of unsupervised learning methods that require no a
               priori inference of the probability distribution associated with
               the training data. Thanks to the use of two convolutional neural
               networks, the discriminator and the generator, in the training
               phase, and only the generator in the simulation phase, GANs
               allow the sampling of large and realistic volumetric images. We
               apply a GAN-based workflow of training and image generation to
               an oolitic Ketton limestone micro-CT unsegmented gray-level
               dataset. Minkowski functionals calculated as a function of the
               segmentation threshold are compared between simulated and
               acquired images. Flow simulations are run on the segmented
               images, and effective permeability and velocity distributions of
               simulated flow are also compared. Results show that GANs allow a
               fast and accurate reconstruction of the evaluated image dataset.
               We discuss the performance of GANs in relation to other
               simulation techniques and stress the benefits resulting from the
               use of convolutional neural networks . We address a number of
               challenges involved in GANs, in particular the representation of
               the probability distribution associated with the training data.},
  journal   = {Transp. Porous Media},
  publisher = {Springer},
  volume    =  125,
  number    =  1,
  pages     = {81--103},
  month     =  oct,
  year      =  2018,
  url       = {https://doi.org/10.1007/s11242-018-1039-9},
  issn      = {1573-1634},
  doi       = {10.1007/s11242-018-1039-9}
}

@ARTICLE{Mosser2017-ml,
  title     = {Reconstruction of three-dimensional porous media using
               generative adversarial neural networks},
  author    = {Mosser, Lukas and Dubrule, Olivier and Blunt, Martin J},
  abstract  = {To evaluate the variability of multiphase flow properties of
               porous media at the pore scale, it is necessary to acquire a
               number of representative samples of the void-solid structure.
               While modern x-ray computer tomography has made it possible to
               extract three-dimensional images of the pore space, assessment
               of the variability in the inherent material properties is often
               experimentally not feasible. We present a method to reconstruct
               the solid-void structure of porous media by applying a
               generative neural network that allows an implicit description of
               the probability distribution represented by three-dimensional
               image data sets. We show, by using an adversarial learning
               approach for neural networks, that this method of unsupervised
               learning is able to generate representative samples of porous
               media that honor their statistics. We successfully compare
               measures of pore morphology, such as the Euler characteristic,
               two-point statistics, and directional single-phase permeability
               of synthetic realizations with the calculated properties of a
               bead pack, Berea sandstone, and Ketton limestone. Results show
               that generative adversarial networks can be used to reconstruct
               high-resolution three-dimensional images of porous media at
               different scales that are representative of the morphology of
               the images used to train the neural network. The fully
               convolutional nature of the trained neural network allows the
               generation of large samples while maintaining computational
               efficiency. Compared to classical stochastic methods of image
               reconstruction, the implicit representation of the learned data
               distribution can be stored and reused to generate multiple
               realizations of the pore structure very rapidly.},
  journal   = {Phys Rev E},
  publisher = {APS},
  volume    =  96,
  number    = {4-1},
  pages     = {043309},
  month     =  oct,
  year      =  2017,
  url       = {http://dx.doi.org/10.1103/PhysRevE.96.043309},
  language  = {en},
  issn      = {2470-0053, 2470-0045},
  pmid      = {29347591},
  doi       = {10.1103/PhysRevE.96.043309}
}

@ARTICLE{Morales-Esteban2013-nj,
  title     = {Earthquake prediction in seismogenic areas of the Iberian
               Peninsula based on computational intelligence},
  author    = {Morales-Esteban, A and Mart{\'\i}nez-{\'A}lvarez, F and Reyes, J},
  abstract  = {A method to predict earthquakes in two of the seismogenic areas
               of the Iberian Peninsula, based on Artificial Neural Networks
               (ANNs), is presented in this paper. ANNs have been widely used
               in many fields but only very few and very recent studies have
               been conducted on earthquake prediction. Two kinds of
               predictions are provided in this study: a) the probability of an
               earthquake, of magnitude equal or larger than a preset threshold
               magnitude, within the next 7days, to happen; b) the probability
               of an earthquake of a limited magnitude interval to happen,
               during the next 7days. First, the physical fundamentals related
               to earthquake occurrence are explained. Second, the mathematical
               model underlying ANNs is explained and the configuration chosen
               is justified. Then, the ANNs have been trained in both areas:
               The Albor{\'a}n Sea and the Western Azores--Gibraltar fault.
               Later, the ANNs have been tested in both areas for a period of
               time immediately subsequent to the training period. Statistical
               tests are provided showing meaningful results. Finally, ANNs
               were compared to other well known classifiers showing
               quantitatively and qualitatively better results. The authors
               expect that the results obtained will encourage researchers to
               conduct further research on this topic.},
  journal   = {Tectonophysics},
  publisher = {Elsevier},
  volume    =  593,
  pages     = {121--134},
  month     =  may,
  year      =  2013,
  url       = {http://www.sciencedirect.com/science/article/pii/S0040195113001467},
  keywords  = {Earthquake prediction; Artificial neural networks; Iberian
               Peninsula; Seismic risk; Time series},
  issn      = {0040-1951},
  doi       = {10.1016/j.tecto.2013.02.036}
}

@ARTICLE{Masotti2008-tu,
  title     = {{TREMOrEC}: A software utility for automatic classification of
               volcanic tremor},
  author    = {Masotti, M and Campanini, R and Mazzacurati, L and Falsaperla, S
               and Langer, H and Spampinato, S},
  abstract  = {We describe a stand-alone software utility named TREMOrEC, which
               carries out training and test of a Support Vector Machine (SVM)
               classifier. TREMOrEC is developed in Visual C++ and runs under
               Microsoft Windows operating systems. Ease of use and short time
               processing, along with the excellent performance of the SVM
               classifier, make this tool ideal for volcano monitoring. The
               development of TREMOrEC is motivated by the successful
               application of the SVM classifier to volcanic tremor data
               recorded at Mount Etna in 2001. In that application,
               spectrograms of volcanic tremor were divided according to their
               recording date into four classes associated with different
               states of activity, i.e., pre-eruptive, lava fountain, eruptive,
               or post-eruptive. During the training, SVM learned the a priori
               classification. The classifier's performance was then evaluated
               on test sets not considered for training. The classification
               results matched the actual class membership with an error of
               less than 6\%.},
  journal   = {Geochem. Geophys. Geosyst.},
  publisher = {Wiley Online Library},
  volume    =  9,
  number    =  4,
  month     =  apr,
  year      =  2008,
  url       = {http://doi.wiley.com/10.1029/2007GC001860},
  issn      = {1525-2027},
  doi       = {10.1029/2007GC001860}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Miller2016-ub,
  title     = {{Data-Driven} Metric Learning for History Matching},
  author    = {Miller, J and Thiagarajan, J J and Bremer, P T and Hoda, N and
               Stern, D and {others}},
  abstract  = {History matching, a highly non-unique inverse problem, is
               critical to calibrate model parameters in many scientific
               applications. A typical approach to history matching is to start
               with a uniform sampling of the high-dimensional parameter space
               and employ a surrogate modeling based black-box optimization to
               perform sequential sampling. Though this general workflow has
               been well studied, the problem of choosing an appropriate merit
               function to compare time-varying simulation outputs has been
               overlooked. Instead, convenient metrics …},
  publisher = {osti.gov},
  year      =  2016,
  url       = {https://www.osti.gov/servlets/purl/1345314}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Mihanovic2011-wx,
  title     = {Surface current patterns in the northern Adriatic extracted from
               high‐frequency radar data using self‐organizing map analysis},
  author    = {Mihanovi{\'c}, H and Cosoli, S and Vilibi{\'c}, I and {others}},
  abstract  = {A network of high-frequency (HF) radars was installed in the
               northern Adriatic in the second half of 2007, aimed to measure
               surface currents in the framework of the North Adriatic Surface
               Current Mapping (NASCUM) project. This study includes a detailed
               analysis of current measurements from February to August 2008, a
               period in which three radars were simultaneously operational.
               Current patterns and temporal evolutions of different physical
               processes were extracted by using self-organizing map (SOM)
               analysis. The analysis …},
  journal   = {Journal of},
  publisher = {Wiley Online Library},
  year      =  2011,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2011JC007104}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Mertens2016-os,
  title     = {Automated Detection of Reflection Hyperbolas in Complex {GPR}
               Images With No A Priori Knowledge on the Medium},
  author    = {Mertens, L and Persico, R and Matera, L and {others}},
  abstract  = {In this paper, we propose an automated detection algorithm for
               well-and ill-shaped ground- penetrating radar reflection
               hyperbolas for complex media, calibrated with human recognition
               principles. The algorithm detects the apex of the hyperbolas by
               fitting an analytical function of a hyperbola to the profile
               edge dots detected with a Canny filter. The existence of a
               hyperbola is determined using a set of carefully chosen criteria
               calibrated in order to fit the ambiguity zone for the human
               brain. The inherent misshapedness of field …},
  journal   = {IEEE Transactions on},
  publisher = {ieeexplore.ieee.org},
  year      =  2016,
  url       = {https://ieeexplore.ieee.org/abstract/document/7230274/}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Meier2007-tj,
  title     = {Global crustal thickness from neural network inversion of
               surface wave data},
  author    = {Meier, Ueli and Curtis, Andrew and Trampert, Jeannot},
  abstract  = {We present a neural network approach to invert surface wave data
               for a global model of crustal thickness with corresponding
               uncertainties. We model the a posteriori probability
               distribution of Moho depth as a mixture of Gaussians and let the
               various parameters of the mixture model be given by the outputs
               of a conventional neural network. We show how such a network can
               be trained on a set of random samples to give a continuous
               approximation to the inverse relation in a compact and
               computationally efficient form. The trained networks are applied
               to real data consisting of fundamental mode Love and Rayleigh
               phase and group velocity maps. For each inversion, performed on
               a 2° $\times$ 2° grid globally, we obtain the a posteriori
               probability distribution of Moho depth. From this distribution
               any desired statistic such as mean and variance can be computed.
               The obtained results are compared with current knowledge of
               crustal structure. Generally our results are in good agreement
               with other crustal models. However in certain regions such as
               central Africa and the backarc of the Rocky Mountains we observe
               a thinner crust than the other models propose. We also see
               evidence for thickening of oceanic crust with increasing age. In
               applications, characterized by repeated inversion of similar
               data, the neural network approach proves to be very efficient.
               In particular, the speed of the individual inversions and the
               possibility of modelling the whole a posteriori probability
               distribution of the model parameters make neural networks a
               promising tool in seismic tomography.},
  journal   = {Geophys. J. Int.},
  publisher = {Oxford University Press},
  volume    =  169,
  number    =  2,
  pages     = {706--722},
  month     =  may,
  year      =  2007,
  url       = {https://academic.oup.com/gji/article-abstract/169/2/706/2012014},
  issn      = {0956-540X},
  doi       = {10.1111/j.1365-246X.2007.03373.x}
}

@ARTICLE{Meldahl2001-bb,
  title     = {Identifying faults and gas chimneys using multiattributes and
               neural networks},
  author    = {Meldahl, P and Heggland, R and Bril, B and de Groot, P},
  abstract  = {Modern visualization and image processing techniques are
               revolutionizing the art of seismic interpretation. Emerging
               technologies allow us to interpret more data with higher
               accuracy in less time. The trend is shifting from horizon-based
               toward volume-based. New insights are gained by studying objects
               of various geologic origins and their spatial
               interrelationships. The standard way of highlighting objects is
               through seismic attribute analysis. Various attributes are
               tested in a trial-and-error mode, and one is selected as the
               optimal representation of the desired object. The selected
               attribute, which may be a mathematical composite of several
               attributes, is not sensitive to a particular geologic object but
               highlights any seismic position with similar attribute response.},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  20,
  number    =  5,
  pages     = {474--482},
  month     =  may,
  year      =  2001,
  url       = {https://doi.org/10.1190/1.1438976},
  issn      = {1070-485X},
  doi       = {10.1190/1.1438976}
}

@ARTICLE{Meier2007-sh,
  title     = {Fully nonlinear inversion of fundamental mode surface waves for
               a global crustal model},
  author    = {Meier, U and Curtis, A and Trampert, J},
  abstract  = {We use neural networks to find 1-dimensional marginal
               probability density functions (pdfs) of global crustal
               parameters. The information content of the full posterior and
               prior pdfs can quantify the extent to which a parameter is
               constrained by the data. We inverted fundamental mode Love and
               Rayleigh wave phase and group velocity maps for pdfs of crustal
               thickness and independently of vertically averaged crustal shear
               wave velocity. Using surface wave data with periods T > 35 s for
               phase velocities and T > 18 s for group velocities, Moho depth
               and vertically averaged shear wave velocity of continental crust
               are well constrained, but vertically averaged shear wave
               velocity of oceanic crust is not resolvable. The latter is a
               priori constrained by CRUST2.0. We show that the resulting model
               allows to compute global crustal corrections for surface wave
               tomography for periods T > 50 s for phase velocities and T > 60
               s for group velocities.},
  journal   = {Geophys. Res. Lett.},
  publisher = {Wiley Online Library},
  volume    =  34,
  number    =  16,
  pages     = {151},
  month     =  aug,
  year      =  2007,
  url       = {http://doi.wiley.com/10.1029/2007GL030989},
  issn      = {0094-8276},
  doi       = {10.1029/2007GL030989}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{McCormack1993-ul,
  title     = {First-break refraction event picking and seismic data trace
               editing using neural networks},
  author    = {McCormack, M D and Zaucha, D E and Dushek, D W},
  abstract  = {Interactive seismic processing systems for editing noisy seismic
               traces and picking first- break refraction events have been
               developed using a neural network learning algorithm. We employ a
               backpropagation neural network (BNN) paradigm modified to
               improve the convergence rate of the BNN. The BNN is
               interactively ``trained'' to edit seismic data or pick first
               breaks by a human processor who judiciously selects and presents
               to the network examples of trace edits or refraction picks. The
               network then iteratively adjusts a set of …},
  journal   = {Geophysics},
  publisher = {library.seg.org},
  year      =  1993,
  url       = {https://library.seg.org/doi/abs/10.1190/1.1443352},
  issn      = {0016-8033}
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{McClinton2013-ci,
  title     = {Reconstructing lava flow emplacement processes at the hot
               spot‐affected Gal{\'a}pagos Spreading Center, 95 {W} and 92 {W}},
  author    = {McClinton, T and White, S M and Colman, A and {others}},
  abstract  = {Volcanic eruptions at mid‐ocean ridges (MORs) control the
               permeability, internal structure, and architecture of oceanic
               crust, thus establishing the foundation for the evolution of the
               ocean basins. To better understand the emplacement of submarine
               lava flows at MORs, we have integrated submersible‐based
               geologic mapping with remote sensing techniques to characterize
               the lava flow morphology within previously mapped lava flow
               fields produced during single eruptive episodes at the
               Gal{\'a}pagos Spreading Center (GSC). Detailed …},
  journal   = {Geochem. Explor. Environ. Analy.},
  publisher = {Wiley Online Library},
  year      =  2013,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ggge.20157},
  issn      = {1467-7873}
}

@ARTICLE{Masotti2006-fi,
  title     = {Application of Support Vector Machine to the classification of
               volcanic tremor at Etna, Italy},
  author    = {Masotti, M and Falsaperla, S and Langer, H and Spampinato, S and
               Campanini, R},
  abstract  = {We applied an automatic pattern recognition technique, known as
               Support Vector Machine (SVM), to classify volcanic tremor data
               recorded during different states of activity at Etna volcano,
               Italy. The seismic signal was recorded at a station deployed 6
               km southeast of the summit craters from 1 July to 15 August,
               2001, a time span encompassing episodes of lava fountains and a
               23 day-long effusive activity. Trained by a supervised learning
               algorithm, the classifier learned to recognize patterns
               belonging to four classes, i.e., pre-eruptive, lava fountains,
               eruptive, and post-eruptive. Training and test of the classifier
               were carried out using 425 spectrogram-based feature vectors.
               Following cross-validation with a random subsampling strategy,
               SVM correctly classified 94.7 $\pm$ 2.4\% of the data. The
               performance was confirmed by a leave-one-out strategy, with 401
               matches out of 425 patterns. Misclassifications highlighted
               intrinsic fuzziness of class memberships of the signals,
               particularly during transitional phases.},
  journal   = {Geophys. Res. Lett.},
  publisher = {Wiley Online Library},
  volume    =  33,
  number    =  20,
  pages     = {113},
  month     =  oct,
  year      =  2006,
  url       = {http://doi.wiley.com/10.1029/2006GL027441},
  issn      = {0094-8276},
  doi       = {10.1029/2006GL027441}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Martinelli2013-ch,
  title     = {Building Bayesian networks from basin-modelling scenarios for
               improved geological decision making},
  author    = {Martinelli, G and Eidsvik, J and Sinding-Larsen, R and {others}},
  abstract  = {Basin models are used to gain insights about a petroleum system,
               and to simulate geological processes required to form oil and
               gas accumulations. The focus of such simulations is usually on
               charge and timing-related issues, although uncertainty analysis
               about a wider range of parameters is becoming more common.
               Bayesian networks (BNs) are useful for decision making in
               geological prospect analysis and exploration. In this paper we
               propose a framework for merging these two methodologies: by
               doing so, we explicitly …},
  journal   = {Petroleum},
  publisher = {pg.lyellcollection.org},
  year      =  2013,
  url       = {http://pg.lyellcollection.org/content/early/2013/06/24/petgeo2012-057.abstract}
}

@ARTICLE{Martin2015-gp,
  title     = {A global prediction of seafloor sediment porosity using machine
               learning},
  author    = {Martin, Kylara M and Wood, Warren T and Becker, Joseph J},
  abstract  = {Abstract Porosity (void ratio) is a critical parameter in models
               of acoustic propagation, bearing strength, and many other
               seafloor phenomena. However, like many seafloor phenomena,
               direct measurements are expensive and sparse. We show here how
               porosity everywhere at the seafloor can be estimated using a
               machine learning technique (specifically, Random Forests). Such
               techniques use sparsely acquired direct samples and dense grids
               of other parameters to produce a statistically optimal estimate
               where direct measurements are lacking. Our porosity estimate is
               both qualitatively more consistent with geologic principles than
               the results produced by interpolation and quantitatively more
               accurate than results produced by interpolation or regression
               methods. We present here a seafloor porosity estimate on a 5 arc
               min, pixel registered grid, produced using widely available,
               densely sampled grids of other seafloor properties. These
               techniques represent the only practical means of estimating
               seafloor properties in inaccessible regions of the seafloor
               (e.g., the Arctic).},
  journal   = {Geophys. Res. Lett.},
  publisher = {Wiley Online Library},
  volume    =  42,
  number    =  24,
  pages     = {10,640--10,646},
  month     =  dec,
  year      =  2015,
  url       = {http://doi.wiley.com/10.1002/2015GL065279},
  issn      = {0094-8276},
  doi       = {10.1002/2015GL065279}
}

@INCOLLECTION{Marroquin2013-lt,
  title     = {A knowledge-integration framework for interpreting seismic
               facies classifications},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2013},
  author    = {Marroqu{\'\i}n, I},
  abstract  = {Automated seismic facies classification is an interpretation
               workflow that provides an efficient means to integrate and
               analyze large amount of seismic data. The resulting output from
               the classification process is a single map (or volume) capturing
               the spatial distribution of seismic facies. Interpreters use the
               resulting seismic facies to predict changes in lithology, rock
               properties, and/or fluid content of the strata being imaged.
               However, interpreters are confronted with the selection of the
               clustering technique and the number of seismic facies that best
               reveal geologic trends in the input data set. To overcome the
               challenge presented by the selection of the clustering technique
               and number of seismic facies, I propose a new interpretation
               framework, in which clustering techniques and data visualization
               are combined. One of the main advantages of the use of this
               framework is that interpreters are directly involved in the
               seismic facies classification process. I discuss the use of this
               framework with a case study to demonstrate that visual
               examination of seismic facies classification results is a
               valuable approach.},
  publisher = {Society of Exploration Geophysicists},
  pages     = {2464--2469},
  series    = {SEG Technical Program Expanded Abstracts},
  month     =  aug,
  year      =  2013,
  url       = {https://doi.org/10.1190/segam2013-0188.1},
  doi       = {10.1190/segam2013-0188.1}
}

@ARTICLE{Marroquin2014-gg,
  title     = {A knowledge-integration framework for interpreting seismic
               facies},
  author    = {Marroqu{\'\i}n, I},
  abstract  = {AbstractIn recent years, the size of seismic data volumes and
               the number of seismic attributes available have increased. As a
               result, the task of recognizing seismic anomalies for the
               prediction of stratigraphic features or reservoir properties can
               be overwhelming. One way to evaluate a large amount of data and
               understand potential geologic trends is to automate seismic
               facies classification. However, the interpretation of seismic
               facies remains an elusive issue. Interpreters are confronted
               with the selection of the clustering technique and the optimal
               number of seismic facies that best uncover the spatial
               distribution of seismic facies. An interpretation framework
               combining data visualization with the results from various
               clustering techniques was evaluated. The framework allows
               interpreters to be directly involved in the seismic facies
               classification process. Because of the active participation,
               interpreters (1) gain insight into the detected seismic facies,
               (2) verify hypotheses with respect to the spatial distribution
               of seismic facies, (3) compare different seismic facies
               classification, and (4) gain more confidence with the seismic
               facies interpretation.},
  journal   = {Interpretation},
  publisher = {Society of Exploration Geophysicists},
  volume    =  2,
  number    =  1,
  pages     = {SA1--SA9},
  month     =  feb,
  year      =  2014,
  url       = {https://doi.org/10.1190/INT-2013-0057.1},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2013-0057.1}
}

@ARTICLE{Marjanovic2011-ot,
  title     = {Landslide susceptibility assessment using {SVM} machine learning
               algorithm},
  author    = {Marjanovi{\'c}, Milo{\v s} and Kova{\v c}evi{\'c}, Milo{\v s}
               and Bajat, Branislav and Vo{\v z}en{\'\i}lek, V{\'\i}t},
  abstract  = {This paper introduces the current machine learning approach to
               solving spatial modeling problems in the domain of landslide
               susceptibility assessment. The latter is introduced as a
               classification problem, having multiple (geological,
               morphological, environmental etc.) attributes and one referent
               landslide inventory map from which to devise the classification
               rules. Three different machine learning algorithms were
               compared: Support Vector Machines, Decision Trees and Logistic
               Regression. A specific area of the Fru{\v s}ka Gora Mountain
               (Serbia) was selected to perform the entire modeling procedure,
               from attribute and referent data preparation/processing, through
               the classifiers' implementation to the evaluation, carried out
               in terms of the model's performance and agreement with the
               referent data. The experiments showed that Support Vector
               Machines outperformed the other proposed methods, and hence this
               algorithm was selected as the model of choice to be compared
               with a common knowledge-driven method -- the Analytical
               Hierarchy Process -- to create a landslide susceptibility map of
               the relevant area. The SVM classifier outperformed the AHP
               approach in all evaluation metrics ($\kappa$ index, area under
               ROC curve and false positive rate in stable ground class).},
  journal   = {Eng. Geol.},
  publisher = {Elsevier},
  volume    =  123,
  number    =  3,
  pages     = {225--234},
  month     =  nov,
  year      =  2011,
  url       = {http://www.sciencedirect.com/science/article/pii/S0013795211002195},
  keywords  = {Landslide susceptibility; Support Vector Machines; Decision
               Tree; Logistic Regression; Analytical Hierarchy Process;
               Classification},
  issn      = {0013-7952},
  doi       = {10.1016/j.enggeo.2011.09.006}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Mardan2017-vr,
  title     = {Channel Characterization Using Support Vector Machine},
  author    = {Mardan, A and Javaherian, A and {others}},
  abstract  = {Rapid growth in the size of seismic data and the number of
               attributes cause to increase the significance of pattern
               recognition techniques in interpreting the seismic data.
               Unsupervised methods include k-means, self-organizing maps (SOM)
               and generative topographic maps (GTM) let interpreters do a
               preliminary interpretation and conclude relatively suitable
               information with no much primary data from studied area. On the
               other hand, utilizing supervised learning such as neural
               networks (NN) and support vector machines (SVM) by …},
  journal   = {79th EAGE Conference},
  publisher = {earthdoc.org},
  year      =  2017,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=89283}
}
@article{pasolli2009automatic,
  title={Automatic analysis of GPR images: A pattern-recognition approach},
  author={Pasolli, Edoardo and Melgani, Farid and Donelli, Massimo},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={47},
  number={7},
  pages={2206--2217},
  year={2009},
  publisher={IEEE}
}

@ARTICLE{Malfante2018-yl,
  title     = {Machine Learning for {Volcano-Seismic} Signals: Challenges and
               Perspectives},
  author    = {Malfante, M and Mura, M Dalla and Metaxian, J and Mars, J I and
               Macedo, O and Inza, A},
  abstract  = {Environmental monitoring is a topic of increasing interest,
               especially concerning the matter of natural hazards prediction.
               Regarding volcanic unrest, effective methodologies along with
               innovative and operational tools are needed to monitor,
               mitigate, and prevent risks related to volcanic hazards. In
               general, the current approaches for volcanoes monitoring are
               mainly based on the manual analysis of various parameters,
               including gas leaps, deformations measurements, and seismic
               signals analysis. However, due to the large amount of data
               acquired by in situ sensors for long-term monitoring, manual
               inspection is no longer a viable option. As in many big data
               situations, classic machine-learning approaches are now
               considered to automatize the analysis of years of recorded
               signals, thereby enabling monitoring on a larger scale.},
  journal   = {IEEE Signal Process. Mag.},
  publisher = {ieeexplore.ieee.org},
  volume    =  35,
  number    =  2,
  pages     = {20--30},
  month     =  mar,
  year      =  2018,
  url       = {http://dx.doi.org/10.1109/MSP.2017.2779166},
  keywords  = {Big Data;environmental monitoring (geophysics);geophysical
               signal processing;hazards;learning (artificial
               intelligence);seismology;volcanology;recorded
               signals;volcano-seismic signals;environmental
               monitoring;interest;natural hazards prediction;volcanic
               unrest;effective methodologies;innovative tools;operational
               tools;risks;volcanic hazards;current approaches;volcanoes
               monitoring;manual analysis;gas leaps;deformations
               measurements;seismic signals analysis;long-term
               monitoring;manual inspection;big data situations;classic
               machine-learning approaches;in situ sensors;Volcanoes;Feature
               extraction;Environmental factors;Transient analysis;Geospatial
               analysis;Signal processing algorithms;Task analysis;Seismic
               measurements},
  issn      = {1053-5888},
  doi       = {10.1109/MSP.2017.2779166}
}

@ARTICLE{Maiti2010-dw,
  title     = {Neural network modeling and an uncertainty analysis in Bayesian
               framework: A case study from the {KTB} borehole site},
  author    = {Maiti, Saumen and Tiwari, Ram Krishna},
  abstract  = {A new probabilistic approach based on the concept of Bayesian
               neural network (BNN) learning theory is proposed for decoding
               litho-facies boundaries from well-log data. We show that how a
               multi-layer-perceptron neural network model can be employed in
               Bayesian framework to classify changes in litho-log successions.
               The method is then applied to the German Continental Deep
               Drilling Program (KTB) well-log data for classification and
               uncertainty estimation in the litho-facies boundaries. In this
               framework, a posteriori distribution of network parameter is
               estimated via the principle of Bayesian probabilistic theory,
               and an objective function is minimized following the scaled
               conjugate gradient optimization scheme. For the model
               development, we inflict a suitable criterion, which provides
               probabilistic information by emulating different combinations of
               synthetic data. Uncertainty in the relationship between the data
               and the model space is appropriately taken care by assuming a
               Gaussian a priori distribution of networks parameters (e.g.,
               synaptic weights and biases). Prior to applying the new method
               to the real KTB data, we tested the proposed method on synthetic
               examples to examine the sensitivity of neural network
               hyperparameters in prediction. Within this framework, we examine
               stability and efficiency of this new probabilistic approach
               using different kinds of synthetic data assorted with different
               level of correlated noise. Our data analysis suggests that the
               designed network topology based on the Bayesian paradigm is
               steady up to nearly 40\% correlated noise; however, adding more
               noise (?50\% or more) degrades the results. We perform
               uncertainty analyses on training, validation, and test data sets
               with and devoid of intrinsic noise by making the Gaussian
               approximation of the a posteriori distribution about the peak
               model. We present a standard deviation error-map at the network
               output corresponding to the three types of the litho-facies
               present over the entire litho-section of the KTB. The
               comparisons of maximum a posteriori geological sections
               constructed here, based on the maximum a posteriori probability
               distribution, with the available geological information and the
               existing geophysical findings suggest that the BNN results
               reveal some additional finer details in the KTB borehole data at
               certain depths, which appears to be of some geological
               significance. We also demonstrate that the proposed BNN approach
               is superior to the conventional artificial neural network in
               terms of both avoiding ?over-fitting? and aiding uncertainty
               estimation, which are vital for meaningful interpretation of
               geophysical records. Our analyses demonstrate that the BNN-based
               approach renders a robust means for the classification of
               complex changes in the litho-facies successions and thus could
               provide a useful guide for understanding the crustal
               inhomogeneity and the structural discontinuity in many other
               tectonically complex regions.},
  journal   = {J. Geophys. Res.},
  publisher = {Wiley Online Library},
  volume    =  115,
  number    = {B10},
  pages     = {E67},
  month     =  oct,
  year      =  2010,
  url       = {http://doi.wiley.com/10.1029/2010JB000864},
  issn      = {0148-0227},
  doi       = {10.1029/2010JB000864}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Maggi2017-mr,
  title     = {Implementation of a Multistation Approach for Automated Event
               Classification at Piton de la Fournaise Volcano},
  author    = {Maggi, Alessia and Ferrazzini, Val{\'e}rie and Hibert,
               Cl{\'e}ment and Beauducel, Fran{\c c}ois and Boissier, Patrice
               and Amemoutou, Amandine},
  abstract  = {We implemented the first operational automated seismic‐event
               classification system for monitoring activity at the Piton de la
               Fournaise volcano observatory (OVPF, La R{\'e}union Island). Our
               classifier is based on the Random Forest algorithm. It
               distinguishes between eight classes of seismic signals: summit
               and deep volcano tectonic events, local, regional, and
               teleseismic earthquakes, T phases, rockfalls, and sound waves.
               It adopts a multistation approach and automatically selects the
               best features for each station and combination of …},
  journal   = {Seismol. Res. Lett.},
  publisher = {GeoScienceWorld},
  volume    =  88,
  number    =  3,
  pages     = {878--891},
  month     =  may,
  year      =  2017,
  url       = {https://pubs.geoscienceworld.org/ssa/srl/article-abstract/88/3/878/284054},
  issn      = {0895-0695},
  doi       = {10.1785/0220160189}
}

@ARTICLE{Maas2013-wb,
  title     = {Using pattern recognition to automatically localize reflection
               hyperbolas in data from ground penetrating radar},
  author    = {Maas, Christian and Schmalzl, J{\"o}rg},
  abstract  = {Ground Penetrating Radar (GPR) is used for the localization of
               supply lines, land mines, pipes and many other buried objects.
               These objects can be recognized in the recorded data as
               reflection hyperbolas with a typical shape depending on depth
               and material of the object and the surrounding material. To
               obtain the parameters, the shape of the hyperbola has to be
               fitted. In the last years several methods were developed to
               automate this task during post-processing. In this paper we show
               another approach for the automated localization of reflection
               hyperbolas in GPR data by solving a pattern recognition problem
               in grayscale images. In contrast to other methods our detection
               program is also able to immediately mark potential objects in
               real-time. For this task we use a version of the Viola--Jones
               learning algorithm, which is part of the open source library
               ``OpenCV''. This algorithm was initially developed for face
               recognition, but can be adapted to any other simple shape. In
               our program it is used to narrow down the location of reflection
               hyperbolas to certain areas in the GPR data. In order to extract
               the exact location and the velocity of the hyperbolas we apply a
               simple Hough Transform for hyperbolas. Because the Viola--Jones
               Algorithm reduces the input for the computational expensive
               Hough Transform dramatically the detection system can also be
               implemented on normal field computers, so on-site application is
               possible. The developed detection system shows promising results
               and detection rates in unprocessed radargrams. In order to
               improve the detection results and apply the program to noisy
               radar images more data of different GPR systems as input for the
               learning algorithm is necessary.},
  journal   = {Comput. Geosci.},
  publisher = {Elsevier},
  volume    =  58,
  pages     = {116--125},
  month     =  aug,
  year      =  2013,
  url       = {http://www.sciencedirect.com/science/article/pii/S009830041300112X},
  keywords  = {Reflection hyperbola; Haartraining; OpenCV; GPR; Adaboost;
               Viola--Jones},
  issn      = {0098-3004},
  doi       = {10.1016/j.cageo.2013.04.012}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ma2012-qo,
  title     = {Classification of Digital Rocks by Machine Learning},
  author    = {Ma, J and Jiang, Z and Tian, Q and Couples, G D},
  abstract  = {The availability of high-resolution 3D digital rocks in ever
               increasing quantities calls for intelligent Machine Learning
               (ML) techniques to classify them according to diverse
               characteristics of their pore structures. If stable classes
               could be identified, they would aid us to develop better models
               for rock typing, to gain sounder understanding of the links
               between the pore structures and the fluid flow behaviours and to
               develop predictive models of effective flow properties with many
               potential applications in the petroleum industry and …},
  journal   = {ECMOR XIII-13th European},
  publisher = {earthdoc.org},
  year      =  2012,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=62262}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Lu2017-ft,
  title     = {Advanced Machine Learning for Unconventional Plays},
  author    = {Lu, L and Zhang, Y and Hohl, D},
  abstract  = {Improving the capital efficiency in oil and gas exploration and
               production, particularly in the unconventional (UNC) plays,
               becomes vitally important for the industry. Since it is evident
               that the existing geological and petro-physical methodologies
               and technologies that enjoy good success in conventional plays
               become not as effective when applied to UNC plays, more
               effective approaches are in high demand. However, in oil and gas
               exploration, the most critical phase is the early land appraisal
               and initial development of the so-called green …},
  journal   = {79th EAGE Conference and Exhibition 2017},
  publisher = {earthdoc.org},
  year      =  2017,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=89284}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Lu2017-bi,
  title     = {Advanced Machine Learning for Unconventional Plays},
  author    = {Lu, L and Zhang, Y and Hohl, D},
  abstract  = {Improving the capital efficiency in oil and gas exploration and
               production, particularly in the unconventional (UNC) plays,
               becomes vitally important for the industry. Since it is evident
               that the existing geological and petro-physical methodologies
               and technologies that enjoy good success in conventional plays
               become not as effective when applied to UNC plays, more
               effective approaches are in high demand. However, in oil and gas
               exploration, the most critical phase is the early land appraisal
               and initial development of the so-called green …},
  journal   = {79th EAGE Conference and Exhibition 2017},
  publisher = {earthdoc.org},
  year      =  2017,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=89284}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Liu2015-pf,
  title     = {Quantitative seismic interpretations to detect biogenic gas
               accumulations: a case study from Qaidam Basin, China},
  author    = {Liu, Yexin and Chen, Zhuoheng and Wang, Liqun and Zhang, Yongshu
               and Liu, Zhiqiang and Shuai, Yanhua},
  abstract  = {Quantitative seismic interpretation can be used to identify
               lithology and detect petroleum accumulations by integrating rock
               properties and attributes derived from advanced seismic
               inversion methods with existing petrophysical data and
               geological knowledge. We use quantitative seismic
               interpretations for detection of shallow biogenic gas
               accumulations in the Qaidam Basin, China, employing an
               integrated workflow that incorporates petrophysical data,
               seismic attribute analysis, Constrained Simultaneous Inversion
               (C-SI) and Bayesian …},
  journal   = {Bull. Can. Petrol. Geol.},
  publisher = {GeoScienceWorld},
  volume    =  63,
  number    =  1,
  pages     = {108--121},
  month     =  mar,
  year      =  2015,
  url       = {https://pubs.geoscienceworld.org/cspg/bcpg/article-abstract/63/1/108/455952},
  issn      = {0007-4802},
  doi       = {10.2113/gscpgbull.63.1.108}
}

@ARTICLE{Liu2017-ps,
  title     = {Enhanced coherence using principal component analysis},
  author    = {Liu, Z and Song, C and Cai, H and Yao, X and Hu, G},
  abstract  = {AbstractCoherence is a measure of similarity between seismic
               waveforms. It gives a quantitative description of lateral
               reflection changes and highlights variations of the geologic
               features within a seismic image. However, subtle changes in
               waveforms are often difficult to capture using traditional
               coherence measures because of the high similarity among the
               remaining parts in the vertical analysis window. We have
               developed an attribute called enhanced coherence based on
               principal component analysis (PCA) with the goal of reducing
               redundancy within the vertical analysis window, which is often
               composed of the parts with a high similarity between neighboring
               traces, and highlighting subtle lateral changes. In computing
               such a coherence image, we first extract seismic data within a
               specified time window along a picked horizon. Then, we calculate
               the enhanced coherence from reduced data obtained using a
               dimension-reduction technique. Because seismic data typically
               consist of large volumes, PCA is chosen for dimension reduction
               due to its insensitivity to the amount of data. We also find
               that reduced data based on PCA is equivalent to applying texture
               model regression with multiple models obtained from the data. We
               have evaluated the enhanced coherence by applying it to
               poststack data and prestack data acquired over the Sichuan Basin
               in southwestern China. We determined that the enhanced coherence
               has a higher resolution for delineating subtle lateral changes.
               Additionally, enhanced coherence calculated from prestack data
               is proven to be able to capture anisotropic features.},
  journal   = {Interpretation},
  publisher = {Society of Exploration Geophysicists},
  volume    =  5,
  number    =  3,
  pages     = {T351--T359},
  month     =  aug,
  year      =  2017,
  url       = {https://doi.org/10.1190/INT-2016-0194.1},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2016-0194.1}
}

@ARTICLE{Liu2018-tu,
  title     = {A {MaxEnt} Model for Mineral Prospectivity Mapping},
  author    = {Liu, Yue and Zhou, Kefa and Xia, Qinglin},
  abstract  = {Mineral prospectivity mapping is an important preliminary step
               for mineral resource exploration. It has been widely applied to
               distinguish areas of high potential to host mineral deposits and
               to minimize the financial risks associated with decision making
               in mineral industry. In the present study, a maximum entropy
               (MaxEnt) model was applied to investigate its potential for
               mineral prospectivity analysis. A case study from the Nanling
               tungsten polymetallic metallogenic belt, South China, was used
               to evaluate its performance. In order to deal with model
               over-fitting, varying levels of $\beta$j-regularization were set
               to determine suitable $\beta$ value based on response curves and
               receiver operating characteristic (ROC) curves, as well as via
               visual inspections of prospectivity maps. The area under the ROC
               curve (AUC = 0.863) suggests good performance of the MaxEnt
               model under the condition of balancing model complexity and
               generality. The relative importance of ore-controlling factors
               and their relationships with known deposits were examined by
               jackknife analysis and response curves. Prediction--area (P--A)
               curves were used to determine threshold values for demarcating
               high probability of tungsten polymetallic deposit occurrence
               within small exploration area. The final predictive map showed
               that high favorability zones occupy 14.5\% of the study area and
               contain 85.5\% of the known tungsten polymetallic deposits. Our
               study suggests that the MaxEnt model can be efficiently used to
               integrate multisource geo-spatial information for mineral
               prospectivity analysis.},
  journal   = {Nat. Resour. Res.},
  publisher = {Springer},
  volume    =  27,
  number    =  3,
  pages     = {299--313},
  month     =  jul,
  year      =  2018,
  url       = {https://doi.org/10.1007/s11053-017-9355-2},
  issn      = {1520-7439, 1573-8981},
  doi       = {10.1007/s11053-017-9355-2}
}

@ARTICLE{Liu2018-ne,
  title     = {Maximum entropy modeling for orogenic gold prospectivity mapping
               in the {Tangbale-Hatu} belt, western Junggar, China},
  author    = {Liu, Yue and Zhou, Kefa and Zhang, Nannan and Wang, Jinlin},
  abstract  = {The Tangbale-Hatu belt (western Junggar region), located in the
               Central Asian Orogenic Belt (CAOB), has undergone complicated
               accretion and collision processes during the evolution of the
               Paleo-Asian Ocean. The geological events contributed to orogenic
               gold mineral systems in the region. In the present study,
               mineral systems approach was employed to evaluate critical
               ore-forming processes such as fluid migration pathways, the
               formation of trap zones, and deposition of metals. By means of
               translating these critical processes into mappable
               ore-controlling variables, we attempt to establish a
               process-based quantitative evaluation model. A maximum entropy
               (MaxEnt) model was proposed to predict the potential
               distribution of orogenic gold deposits based on known gold
               deposits/occurrences, and ore-controlling variables. Nine
               ore-controlling variables including fault intersection density,
               fault linear density, the first factor score map, Au singularity
               indices, Au regional anomaly, Au local anomaly, proximity to
               NE-trending faults, proximity to intrusion contacts and
               proximity to stratigraphic contacts, were selected to identify
               the most potential zones endowed with gold deposits. The spatial
               association of individual ore-controlling variable with the
               incidence of gold deposit occurrences was investigated by
               response curves, and the relative importance of each
               ore-controlling variable was determined by jackknife analysis in
               the MaxEnt model. The results indicate that Au regional anomaly
               derived from spectrum--area (S--A) fractal model is the most
               important variable, followed by the first factor score map and
               proximity to stratigraphic contacts. The model accuracy was
               evaluated by ROC curve giving a high predictive ability
               (AUC=0.915). Favorable zones for gold mineralization illustrated
               by the prospectivity map are spatially coincident with known
               gold deposits/occurrences and the main mineralized trends,
               showing that the MaxEnt model can be efficiently employed for
               spatial fusion analysis of multisource geospatial data to
               support conceptual mineral systems modeling of geologic controls
               on mineral deposit occurrences.},
  journal   = {Ore Geol. Rev.},
  publisher = {Elsevier},
  volume    =  100,
  pages     = {133--147},
  month     =  sep,
  year      =  2018,
  url       = {http://www.sciencedirect.com/science/article/pii/S016913681630350X},
  keywords  = {MaxEnt model; Orogenic gold mineral systems; Western Junggar;
               Mineral prospectivity mapping; Machine learning methods},
  issn      = {0169-1368},
  doi       = {10.1016/j.oregeorev.2017.04.029}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ling1994-cn,
  title     = {Hydrocarbon detection using self-organizing mapping [J]},
  author    = {Ling, L},
  abstract  = {Self-organizing mapping network is a fast learning neural
               network used to deal with problems of classification,
               clustcring, interpretation and so on. In the paper, the method
               is tested with an experiment for hydrocarbon detection on two
               data sets. The results show:(1) the biger the output layer of
               network, the greater the learning ability,(2) the learning
               ability still depends on the selection for samples, and (3) very
               good results could be reached while the method is in application
               to classification. This method is worth recommending in …},
  journal   = {Geophysical Prospecting For Petrole},
  publisher = {en.cnki.com.cn},
  year      =  1994,
  url       = {http://en.cnki.com.cn/Article_en/CJFDTOTAL-SYWT199404006.htm}
}

@INCOLLECTION{Lin2017-ye,
  title     = {Towards real-time geologic feature detection from seismic
               measurements using a randomized machine-learning algorithm},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2017},
  author    = {Lin, Y and Guthrie, G and Coblentz, D and Wang, S and
               Thiagarajan, J},
  abstract  = {Conventional seismic techniques for detecting the subsurface
               geologic features are challenged by limited data coverage,
               computational inefficiency, and subjective human factors. We
               propose to employ an efficient and accurate machine-learning
               detection approach to extract useful subsurface geologic
               features automatically. We employ a data reduction technique in
               combination with the conventional kernel ridge regression method
               to improve the computational efficiency and reduce the memory
               usage. Specifically, we utilize a randomized numerical linear
               algebra technique to effectively reduce the dimensionality of
               the feature space without compromising the information content
               required for accurate detection. We validate the performance of
               our new subsurface geologic feature detection method using
               synthetic surface seismic data for a 2D geophysical model. Our
               numerical examples demonstrate that our new detection method
               significantly improves the computational efficiency while
               maintaining comparable accuracy. Interestingly, we show that our
               method yields a speed-up ratio on the order of ~102 to ~103 in a
               multi-core computational environment. Presentation Date:
               Wednesday, September 27, 2017 Start Time: 3:30 PM Location: 350D
               Presentation Type: ORAL},
  publisher = {Society of Exploration Geophysicists},
  pages     = {2143--2148},
  series    = {SEG Technical Program Expanded Abstracts},
  month     =  aug,
  year      =  2017,
  url       = {https://doi.org/10.1190/segam2017-17775517.1},
  doi       = {10.1190/segam2017-17775517.1}
}

@article{reddy1991decisiontree,
author = {R.K.T. Reddy and G.F. Bonham-Carter},
title = {A Decision-Tree Approach to Mineral Potential Mapping in Snow Lake Area, Manitoba},
journal = {Canadian Journal of Remote Sensing},
volume = {17},
number = {2},
pages = {191-200},
year  = {1991},
publisher = {Taylor & Francis},
doi = {10.1080/07038992.1991.10855292},

URL = { 
        https://doi.org/10.1080/07038992.1991.10855292
},
eprint = { 
        https://doi.org/10.1080/07038992.1991.10855292
}}

@book{preston1964fourier,
  title={Fourier series characterization of cyclic sediments for stratigraphic correlation},
  author={Preston, Floyd W and Henderson, James},
  year={1964},
  publisher={Kansas Geological Survey}
}

@article{newendorp1976decision,
  title={Decision analysis for petroleum exploration},
  author={Newendorp, Paul D},
  year={1976},
  publisher={Penn Well Books, Tulsa, OK}
}

@ARTICLE{Li2004-fk,
  title     = {Support Vector Machine ({SVM}) pattern recognition to {AVO}
               classification},
  author    = {Li, Jiakang and Castagna, John},
  abstract  = {The purpose of this paper is to present a learning algorithm to
               classify data with nonlinear characteristics. The Support Vector
               Machine (SVM) is a novel type of learning machine based on
               statistical learning theory [Vapnik, 1998]. The support vector
               machine (SVM) implements the following idea: It maps the input
               vector X into a high-dimensional feature space Z through some
               nonlinear mapping, chosen a priori. In this space, an optimal
               separating hyperplane is constructed to separate data groupings.
               The support vector machine (SVM) learning method can be used to
               classify seismic data patterns for exploration and reservoir
               characterization applications. The SVM is particularly good at
               classifying data with nonlinear characteristics. As an example
               the SVM method is applied to AVO classification of gas sand and
               wet sand.},
  journal   = {Geophys. Res. Lett.},
  publisher = {Wiley Online Library},
  volume    =  31,
  number    =  2,
  pages     = {948},
  month     =  jan,
  year      =  2004,
  url       = {http://doi.wiley.com/10.1029/2003GL018299},
  issn      = {0094-8276},
  doi       = {10.1029/2003GL018299}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Li2018-bm,
  title     = {Multiscale {Pre-Stack} Seismic Attribute Enhancement Using
               Radial Basis Function Network},
  author    = {Li, L and Li, X W and Wan, Z and Liu, Y and Zhang, L},
  abstract  = {The seismic attribute analysis has been widely applied in recent
               years as one of the effective approachs of reservoir prediction.
               However, traditional seismic attribute with full-azimuth stack
               is difficult to meet the requirement of reservoir development.
               In the paper, we propose a supervised multiscale attribute
               enhancement algorithm for pre-stack seismic data, which uses
               radial basis function network and downsampling pyramid. The
               method mainly composes of three steps: partial stack,
               multi-scale decomposition and reconstruction using …},
  journal   = {80th EAGE Conference and},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=92122}
}

@INCOLLECTION{Lewis2017-ek,
  title     = {Deep learning prior models from seismic images for full-waveform
               inversion},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2017},
  author    = {Lewis, W and Vigh, D},
  abstract  = {Full-waveform inversion (FWI) is now a mature technology that is
               routinely used in exploration around the world to obtain high
               resolution earth models. In geological areas such as the Gulf of
               Mexico, however, reconstructing complex salt geobodies poses a
               huge challenge to FWI due to the absence of low frequencies in
               the data needed to resolve such features. A skilled seismic
               interpreter has to interpret these geobodies and manually insert
               them into the earth model and repeat this process several times
               in the earth model building workflow. Deep learning algorithms
               have gained a lot of interest in recent years by obtaining
               state-of-the art results in various problems arising in the
               fields of computer vision, automatic speech recognition and
               natural language processing. We investigate the use of these
               algorithms to generate useful prior models for full-waveform
               inversion by learning features relevant to earth model building
               from a seismic image. We test this methodology in full-waveform
               inversion by generating a probability map of salt bodies in the
               migrated image along with a prior model and incorporating it in
               the FWI objective function. This approach is shown to be
               promising in enabling an automated salt body reconstruction
               using FWI. Presentation Date: Thursday, September 28, 2017 Start
               Time: 10:10 AM Location: 361F Presentation Type: ORAL},
  publisher = {Society of Exploration Geophysicists},
  pages     = {1512--1517},
  series    = {SEG Technical Program Expanded Abstracts},
  month     =  aug,
  year      =  2017,
  url       = {https://doi.org/10.1190/segam2017-17627643.1},
  doi       = {10.1190/segam2017-17627643.1}
}

@INCOLLECTION{Leggett2003-vq,
  title     = {Automated {3-D} Horizon Tracking and Seismic Classification
               Using Artificial Neural Networks},
  booktitle = {Geophysical Applications of Artificial Neural Networks and Fuzzy
               Logic},
  author    = {Leggett, Miles and Sandham, William A and Durrani, Tariq S},
  editor    = {Sandham, William A and Leggett, Miles},
  abstract  = {Seismic surveys are routinely carried out in three dimensions,
               resulting in large volumes of high-resolution seismic data and a
               corresponding increase in the workload of an interpreter. An
               automatic tracker is described in this chapter, based on
               artificial neural networks (ANNs), which enables horizons to be
               tracked in three dimensions with less input from an interpreter
               compared to most commercial automatic trackers. More time can
               therefore be spent by the interpreter investigating geologically
               complex areas. A hybrid ANN is employed which combines both
               unsupervised (self-organising feature map) and supervised
               (multilayer perceptron) network paradigms. The tracker is
               demonstrated on a real three-dimensional (3-D) seismic data set,
               and is shown to be a viable technique for use as a standard tool
               and for enhancing efficiency in 3-D seismic interpretation.
               1.5-D and 2-D methods have also been demonstrated successfully,
               which account for the seismic character above, below, behind and
               ahead of the current tracking position.},
  publisher = {Springer Netherlands},
  pages     = {31--44},
  year      =  2003,
  url       = {https://doi.org/10.1007/978-94-017-0271-3_3},
  address   = {Dordrecht},
  isbn      = {9789401702713},
  doi       = {10.1007/978-94-017-0271-3\_3}
}

@ARTICLE{Legget1996-nk,
  title     = {{3D} horizon tracking using artificial neural networks},
  author    = {Legget, M and Sandham, W A and Durrani, T S},
  abstract  = {Seismic surveys are now routinely carried out in three
               dimensions, resulting in large volumes of high-resolution
               seismic data, increasing the workload of an interpreter. An
               automatic tracker that uses the pattem recognition capabilities
               of artificial neural networks has been developed which enables
               horizons to be tracked in three dimensions with little input
               from an interpreter, thus allowing more time to be spent on
               geologically complex areas.},
  journal   = {First Break},
  publisher = {earthdoc.org},
  year      =  1996,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=28049},
  issn      = {0263-5046}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Langer2003-lh,
  title     = {Application of artificial neural networks for the classification
               of the seismic transients at Soufriere Hills volcano, Montserrat},
  author    = {Langer, H and Falsaperla, S and {others}},
  abstract  = {Seismic activity at Soufri{\`e}re Hills volcano is characterized
               by a variety of transients, such as tectonic earthquakes,
               long-period events, hybrid events, and rockfalls. The huge
               quantity of seismic data daily recorded on the volcano makes the
               application of automatic processing highly recommendable. We
               propose a method of supervised classification of the transients
               based on Artificial Neural Networks (ANN), which may be useful
               for processing the large data sets piled up in the past.
               Particularly, data sets recorded before the climactic eruptions
               …},
  journal   = {Geophys. Res. Lett.},
  publisher = {Wiley Online Library},
  year      =  2003,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2003GL018082},
  issn      = {0094-8276}
}

@ARTICLE{Langer1996-fv,
  title     = {Estimation of seismic waveform governing parameters with neural
               networks},
  author    = {Langer, Horst and Nunnari, Giuseppe and Occhipinti, Luigi},
  abstract  = {We investigate the application of multilayer perceptron neural
               networks on the inversion of waveform governing parameters
               related to the seismic source and the propagation medium. These
               parameters are given by the size of the source, thicknesses and
               velocities of the layers, and a parameter ? describing the whole
               path attenuation of the wave due to absorption. Synthetic SH
               waves radiated from a circular source model are used for this
               study. The neural network returns a mapping function which can
               be used for an entire class of signals, provided that the
               parameters are within the limits of the model space explored
               during the training. The application of the mapping function to
               a set of signals is mathematically simple and fast. This can be
               a considerable advantage over systematic search techniques, such
               as simulated annealing or genetic algorithms, since the
               stability of the results that are found with the neural network
               can be tested easily with examples not used for the estimation
               of the mapping function. The use of an appropriate transform of
               the signal (i.e., spectra or autocorrelation function) gives
               slightly better results than the crude waveforms. The seismic
               waveform-governing parameters can be identified with a
               reasonable accuracy if an appropriate network topology is chosen
               and if the number of examples used for the training phase is
               sufficiently large. Even in the case where 16 parameters of the
               models are searched and the global error remained somewhat
               unsatisfying, important parameters, such as the source radius or
               the velocity of the uppermost layers, are still recognized with
               a fair accuracy. The error is, at least to some degree, an
               effect of the nonuniqueness of the inversion problem. Performing
               a search with simulated annealing 31 times for an example
               seismogram, we obtain 31 solutions with a scatter for the
               different parameters which is of the same order as the errors
               obtained with the network.},
  journal   = {J. Geophys. Res.},
  publisher = {Wiley Online Library},
  volume    =  101,
  number    = {B9},
  pages     = {20109--20118},
  month     =  sep,
  year      =  1996,
  url       = {http://doi.wiley.com/10.1029/96JB00948},
  issn      = {0148-0227},
  doi       = {10.1029/96JB00948}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Landwehr2016-ws,
  title     = {A nonergodic ground‐motion model for California with spatially
               varying coefficients},
  author    = {Landwehr, N and Kuehn, N M and Scheffer, T and {others}},
  abstract  = {Traditional probabilistic seismic‐hazard analysis as well as the
               estimation of ground‐motion models (GMM s) is based on the
               ergodic assumption, which means that the distribution of ground
               motions over time at a given site is the same as their spatial
               distribution over all sites for the same magnitude, distance,
               and site condition. With a large increase in the number of
               recorded ground‐motion data, there are now repeated observations
               at given sites and from multiple earthquakes in small regions,
               so that assumption can be relaxed. We use a novel …},
  journal   = {Bulletin of the},
  publisher = {pubs.geoscienceworld.org},
  year      =  2016,
  url       = {https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/106/6/2574/324828}
}

@ARTICLE{Laloy2017-lp,
  title         = {Efficient training-image based geostatistical simulation and
                   inversion using a spatial generative adversarial neural
                   network},
  author        = {Laloy, Eric and H{\'e}rault, Romain and Jacques, Diederik
                   and Linde, Niklas},
  abstract      = {Probabilistic inversion within a multiple-point statistics
                   framework is still computationally prohibitive for
                   large-scale problems. To partly address this, we introduce
                   and evaluate a new training-image based simulation and
                   inversion approach for complex geologic media. Our approach
                   relies on a deep neural network of the spatial generative
                   adversarial network (SGAN) type. After training using a
                   training image (TI), our proposed SGAN can quickly generate
                   2D and 3D unconditional realizations. A key feature of our
                   SGAN is that it defines a (very) low-dimensional
                   parameterization, thereby allowing for efficient
                   probabilistic (or deterministic) inversion using
                   state-of-the-art Markov chain Monte Carlo (MCMC) methods. A
                   series of 2D and 3D categorical TIs is first used to analyze
                   the performance of our SGAN for unconditional simulation.
                   The speed at which realizations are generated makes it
                   especially useful for simulating over large grids and/or
                   from a complex multi-categorical TI. Subsequently, synthetic
                   inversion case studies involving 2D steady-state flow and 3D
                   transient hydraulic tomography are used to illustrate the
                   effectiveness of our proposed SGAN-based probabilistic
                   inversion. For the 2D case, the inversion rapidly explores
                   the posterior model distribution. For the 3D case, the
                   inversion recovers model realizations that fit the data
                   close to the target level and visually resemble the true
                   model well. Future work will focus on the inclusion of
                   direct conditioning data and application to continuous TIs.},
  month         =  aug,
  year          =  2017,
  url           = {http://arxiv.org/abs/1708.04975},
  archivePrefix = {arXiv},
  eprint        = {1708.04975},
  primaryClass  = {stat.ML},
  arxivid       = {1708.04975}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Kuroda2016-sm,
  title     = {Analysis of porosity, stratigraphy, and structural delineation
               of a Brazilian carbonate field by machine learning techniques: A
               case study},
  author    = {Kuroda, Michelle Chaves and Vidal, Alexandre Campane and Papa,
               Jo{\~a}o Paulo},
  abstract  = {The upscaling of well logs has many challenges, especially for
               carbonate rocks. Primary among them is the suitable choice of
               seismic attributes to be integrated with well information, whose
               random combination can produce artifacts of rock properties. To
               solve this problem, we have developed an alternative hybrid
               method to estimate well-log data from seismic attributes,
               associating the seismic attributes choices with the genetic
               algorithm and artificial neural network multilayer perceptron
               ability to predict neutron porosity. Thirty-seven seismic …},
  journal   = {Interpretation},
  publisher = {GeoScienceWorld},
  volume    =  4,
  number    =  3,
  pages     = {T347--T358},
  month     =  aug,
  year      =  2016,
  url       = {https://pubs.geoscienceworld.org/interpretation/article-abstract/4/3/T347/309595},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2016-0024.1}
}

@ARTICLE{Kuhn2018-mn,
  title     = {The Utility of Machine Learning in Identification of Key
               Geophysical and Geochemical Datasets: A Case Study in
               Lithological Mapping in the Central African Copper Belt},
  author    = {Kuhn, Stephen and Cracknell, Matthew and Reading, Anya},
  abstract  = {Random Forests, a supervised machine learning algorithm,
               provides a robust, data driven means of predicting lithology
               from geophysical, geochemical and remote sensing data. As an
               essential part of input selection, datasets are ranked in order
               of importance to the classification outcome. Those ranked most
               important provide, on average, the most decisive split between
               lithological classes. These rankings provide explorers with an
               additional line of reasoning to complement conventional,
               geophysical and geochemical interpretation workflows. The
               approach shows potential to aid in identifying important
               criteria for distinguishing geological map units during early
               stage exploration. This can assist in directing subsequent
               expenditure towards the acquisition and further development of
               datasets which will be the most productive for mapping. In this
               case study, we use Random Forests to classify the lithology of a
               project in the Central African Copper-Belt, Zambia. The project
               area boasts extensive magnetic, radiometric, electromagnetic and
               multi-element geochemical coverage but only sparse geological
               observations. Under various training data paradigms, Random
               Forests produced a series of varying but closely related
               lithological maps. In this study, training data were restricted
               to outcrop, simulating the data available at the early stages of
               the project. Variable ranking highlighted those datasets which
               were of greatest importance to the result. Both geophysical and
               geochemical datasets were well represented in the highest
               ranking variables, reinforcing the importance of access to both
               data types. Further analysis showed that in many cases, the
               importance of high ranking datasets had a plausible geological
               explanation, often consistent with conventional interpretation.
               In other cases the method provides new insights, identifying
               datasets which may not have been considered from the outset of a
               new project.},
  journal   = {ASEG Extended Abstracts},
  publisher = {CSIRO PUBLISHING},
  volume    =  2018,
  number    =  1,
  pages     = {1--4},
  year      =  2018,
  url       = {http://www.publish.csiro.au/EX/ASEG2018abT7_3G},
  language  = {en},
  issn      = {2202-0586},
  doi       = {10.1071/aseg2018abt7\_3g}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Kuehn2011-tv,
  title     = {Modeling the joint probability of earthquake, site, and
               ground-motion parameters using Bayesian networks},
  author    = {Kuehn, N M and Riggelsen, C and {others}},
  abstract  = {Abstract Bayesian networks are a powerful and increasingly
               popular tool for reasoning under uncertainty, offering intuitive
               insight into (probabilistic) data- generating processes. They
               have been successfully applied to many different fields,
               including bioinformatics. In this paper, Bayesian networks are
               used to model the joint- probability distribution of selected
               earthquake, site, and ground-motion parameters. This provides a
               probabilistic representation of the independencies and
               dependencies between …},
  journal   = {Bulletin of the},
  publisher = {pubs.geoscienceworld.org},
  year      =  2011,
  url       = {https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/101/1/235/349494}
}

@ARTICLE{Kuehn2010-nn,
  title     = {A Naive Bayes Classifier for Intensities Using Peak Ground
               Velocity and Acceleration},
  author    = {Kuehn, N M and Scherbaum, F},
  abstract  = {A naive Bayes classifier is determined to predict intensities
               from peak ground velocity and acceleration. It is trained on the
               same dataset that was used in the study of. The naive Bayes
               classifier directly estimates a discrete probability
               distribution for the ordinal intensities. Comparisons based on
               generalization error, estimated by cross-validation, show that
               the naive Bayes classifier performs better than traditionally
               employed regression models.},
  journal   = {Bull. Seismol. Soc. Am.},
  publisher = {pubs.geoscienceworld.org},
  year      =  2010,
  url       = {https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/100/6/3278/325392}
}

@ARTICLE{Klose2006-xh,
  title     = {Self-organizing maps for geoscientific data analysis: geological
               interpretation of multidimensional geophysical data},
  author    = {Klose, Christian D},
  abstract  = {Data interpretation is a common task in geoscientific
               disciplines. Interpretation difficulties occur especially if the
               data that have to be interpreted are of arbitrary dimension.
               This paper describes the application of a statistical method,
               called self-organizing mapping (SOM), to interpret
               multidimensional, non-linear, and highly noised geophysical data
               for purposes of geological prediction. The underlying theory is
               explained, and the method is applied to a six-dimensional
               seismic data set. Results of SOM classifications can be
               represented as two-dimensional images, called feature maps.
               Feature maps illustrate the complexity and demonstrate
               interrelations between single features or clusters of the
               complete feature space. SOM images can be visually described and
               easily interpreted. The advantage is that the SOM method
               considers interdependencies between all geophysical features at
               each instance. An application example of an automated geological
               interpretation based on the geophysical data is shown.},
  journal   = {Computational Geosciences},
  publisher = {Springer},
  volume    =  10,
  number    =  3,
  pages     = {265--277},
  month     =  sep,
  year      =  2006,
  url       = {https://doi.org/10.1007/s10596-006-9022-x},
  issn      = {1573-1499},
  doi       = {10.1007/s10596-006-9022-x}
}

@ARTICLE{Kilic2018-to,
  title     = {Neural network based inspection of voids and karst conduits in
               hydro--electric power station tunnels using {GPR}},
  author    = {Kilic, Gokhan and Eren, Levent},
  abstract  = {This paper reports on the fundamental role played by Ground
               Penetrating Radar (GPR), alongside advanced processing and
               presentation methods, during the tunnel boring project at a Dam
               and Hydro--Electric Power Station. It identifies from collected
               GPR data such issues as incomplete grouting and the presence of
               karst conduits and voids and provides full details of the
               procedures adopted. In particular, the application of collected
               GPR data to the Neural Network (NN) method is discussed.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  151,
  pages     = {194--204},
  month     =  apr,
  year      =  2018,
  url       = {http://www.sciencedirect.com/science/article/pii/S0926985118301484},
  keywords  = {GPR; TBM; NDT; Karst conduits; Neural network},
  issn      = {0926-9851},
  doi       = {10.1016/j.jappgeo.2018.02.026}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Khoshnevis2018-wq,
  title     = {Prioritizing ground‐motion validation metrics using
               semisupervised and supervised learning},
  author    = {Khoshnevis, N and Taborda, R},
  abstract  = {It has become common practice to validate ground‐motion
               simulations based on a variety of time and frequency metrics
               scaled to quantify the level of agreement between synthetics and
               data or other reference solutions. There is, however, no
               agreement about the importance or weight that it ought to be
               given to each metric. This leads to their selection often being
               subjective, either based on intended applications or personal
               preferences. As a consequence, it is difficult for simulators to
               identify what modeling improvements are …},
  journal   = {Bull. Seismol. Soc. Am.},
  publisher = {pubs.geoscienceworld.org},
  year      =  2018,
  url       = {https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/108/4/2248/536309}
}


@ARTICLE{Kern2017-vd,
  title     = {Machine Learning Based Predictive Modeling of Debris Flow
               Probability Following Wildfire in the Intermountain Western
               United States},
  author    = {Kern, Ashley N and Addison, Priscilla and Oommen, Thomas and
               Salazar, Sean E and Coffman, Richard A},
  abstract  = {It has been recognized that wildfire, followed by large
               precipitation events, triggers both flooding and debris flows in
               mountainous regions. The ability to predict and mitigate these
               hazards is crucial in protecting public safety and
               infrastructure. A need for advanced modeling techniques was
               highlighted by re-evaluating existing prediction models from the
               literature. Data from 15 individual burn basins in the
               intermountain western United States, which contained 388
               instances and 26 variables, were obtained from the United States
               Geological Survey (USGS). After randomly selecting a subset of
               the data to serve as a validation set, advanced predictive
               modeling techniques, using machine learning, were implemented
               using the remaining training data. Tenfold cross-validation was
               applied to the training data to ensure nearly unbiased error
               estimation and also to avoid model over-fitting. Linear,
               nonlinear, and rule-based predictive models including na{\"\i}ve
               Bayes, mixture discriminant analysis, classification trees, and
               logistic regression models were developed and tested on the
               validation dataset. Results for the new non-linear approaches
               were nearly twice as successful as those for the linear models,
               previously published in debris flow prediction literature. The
               new prediction models advance the current state-of-the-art of
               debris flow prediction and improve the ability to accurately
               predict debris flow events in wildfire-prone intermountain
               western United States.},
  journal   = {Math. Geosci.},
  publisher = {Springer},
  volume    =  49,
  number    =  6,
  pages     = {717--735},
  month     =  aug,
  year      =  2017,
  url       = {https://doi.org/10.1007/s11004-017-9681-2},
  issn      = {1874-8961, 1874-8953},
  doi       = {10.1007/s11004-017-9681-2}
}

@ARTICLE{Karra2018-of,
  title     = {Modeling flow and transport in fracture networks using graphs},
  author    = {Karra, S and O'Malley, D and Hyman, J D and Viswanathan, H S and
               Srinivasan, G},
  journal   = {Phys Rev E},
  publisher = {APS},
  volume    =  97,
  number    = {3-1},
  pages     = {033304},
  month     =  mar,
  year      =  2018,
  url       = {http://dx.doi.org/10.1103/PhysRevE.97.033304},
  language  = {en},
  issn      = {2470-0053, 2470-0045},
  pmid      = {29776097},
  doi       = {10.1103/PhysRevE.97.033304}
}

@ARTICLE{Jia2017-fb,
  title     = {What can machine learning do for seismic data processing? An
               interpolation application},
  author    = {Jia, Y and Ma, J},
  abstract  = {ABSTRACTMachine learning (ML) systems can automatically mine
               data sets for hidden features or relationships. Recently, ML
               methods have become increasingly used within many scientific
               fields. We have evaluated common applications of ML, and then we
               developed a novel method based on the classic ML method of
               support vector regression (SVR) for reconstructing seismic data
               from under-sampled or missing traces. First, the SVR method
               mines a continuous regression hyperplane from training data that
               indicates the hidden relationship between input data with
               missing traces and output completed data, and then it
               interpolates missing seismic traces for other input data by
               using the learned hyperplane. The key idea of our new ML method
               is significantly different from that of many previous
               interpolation methods. Our method depends on the characteristics
               of the training data, rather than the assumptions of linear
               events, sparsity, or low rank. Therefore, it can break out the
               previous assumptions or constraints and show universality to
               different data sets. In addition, our method dramatically
               reduces the manual workload; for example, it allows users to
               avoid selecting the window size parameters, as is required for
               methods based on the assumption of linear events. The ML method
               facilitates intelligent interpolation between data sets with
               similar geomorphological structures, which can significantly
               reduce costs in engineering applications. Furthermore, we
               combine a sparse transform called the data-driven tight frame
               (so-called compressed learning) with the SVR method to improve
               the training performance, in which the training is implemented
               in a sparse coefficient domain rather than in the data domain.
               Numerical experiments show the competitive performance of our
               method in comparison with the traditional f-x interpolation
               method.},
  journal   = {Geophysics},
  publisher = {Society of Exploration Geophysicists},
  volume    =  82,
  number    =  3,
  pages     = {V163--V177},
  month     =  may,
  year      =  2017,
  url       = {https://doi.org/10.1190/geo2016-0300.1},
  issn      = {0016-8033},
  doi       = {10.1190/geo2016-0300.1}
}

@ARTICLE{Jeong2014-jy,
  title     = {A novel data assimilation methodology for predicting lithology
               based on sequence labeling algorithms},
  author    = {Jeong, Jina and Park, Eungyu and Han, Weon Shik and Kim,
               Kue-Young},
  abstract  = {Abstract A hidden Markov model (HMM) and a conditional random
               fields (CRFs) model for lithological predictions based on
               multiple geophysical well-logging data are derived for dealing
               with directional nonstationarity through bidirectional training
               and conditioning. The developed models were benchmarked against
               their conventional counterparts, and hypothetical boreholes with
               the corresponding synthetic geophysical data including
               artificial errors were employed. In the three test scenarios
               devised, the average fitness and unfitness values of the
               developed CRFs model and HMM are 0.84 and 0.071 and 0.81 and
               0.084, respectively, while those of the conventional CRFs model
               and HMM are 0.78 and 0.091 and 0.77 and 0.099, respectively.
               Comparisons of their predictabilities show that the models
               designed for directional nonstationarity clearly perform better
               than the conventional models for all tested examples. Among
               them, the developed linear-chain CRFs model showed the best or
               close to the best performance with high predictability and a low
               training data requirement.},
  journal   = {J. Geophys. Res. [Solid Earth]},
  publisher = {Wiley Online Library},
  volume    =  119,
  number    =  10,
  pages     = {7503--7520},
  month     =  oct,
  year      =  2014,
  url       = {http://doi.wiley.com/10.1002/2014JB011279},
  issn      = {2169-9313},
  doi       = {10.1002/2014JB011279}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Jafrasteh2016-vj,
  title     = {Advanced Machine Learning Methods for Copper Ore Grade
               Estimation},
  author    = {Jafrasteh, B and Fathianpour, N and Su{\'a}rez, A},
  abstract  = {Ore grade estimation is one of the most important tasks in the
               design of effective strategies for the exploitation of mineral
               resources. In this work, we compare the accuracy of ordinary
               kriging with advanced machine learning techniques in the
               estimation of mineral grade as a function of the location in the
               deposit. As a case study, we analyze data from the Sarcheshmesh
               porphyry copper mine located in the Southwest of Iran. The
               learning machines considered include multilayer perceptrons
               (MLP), a type of feedforward neural …},
  journal   = {Near Surface Geoscience 2016},
  publisher = {earthdoc.org},
  year      =  2016,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=86600}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Iturraran-Viveros2014-rk,
  title     = {Artificial Neural Networks applied to estimate permeability,
               porosity and intrinsic attenuation using seismic attributes and
               well-log data},
  author    = {Iturrar{\'a}n-Viveros, Ursula and Parra, Jorge O},
  abstract  = {Permeability and porosity are two fundamental reservoir
               properties which relate to the amount of fluid contained in a
               reservoir and its ability to flow. The intrinsic attenuation is
               another important parameter since it is related to porosity,
               permeability, oil and gas saturation and these parameters
               significantly affect the seismic signature of a reservoir. We
               apply Artificial Neural Network (ANN) models to predict
               permeability (k) and porosity (ϕ) for a carbonate aquifer in
               southeastern Florida and to predict intrinsic attenuation (1/Q)
               for a sand--shale oil reservoir in northeast Texas. In this
               study, the Gamma test (a revolutionary estimator of the noise in
               a data set) has been used as a mathematically non-parametric
               nonlinear smooth modeling tool to choose the best input
               combination of seismic attributes to estimate k and ϕ, and the
               best combination of well-logs to estimate 1/Q. This saves time
               during the construction and training of ANN models and also sets
               a lower bound for the mean squared error to prevent
               over-training. The Neural Network method successfully delineates
               a highly permeable zone that corresponds to a high water
               production in the aquifer. The Gamma test found nonlinear
               relations that were not visible to linear regression allowing us
               to generalize the ANN estimations of k, ϕ and 1/Q for their
               respective sets of patterns that were not used during the
               learning phase.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  107,
  pages     = {45--54},
  month     =  aug,
  year      =  2014,
  url       = {http://www.sciencedirect.com/science/article/pii/S092698511400144X},
  keywords  = {The Gamma test; Seismic attributes; Artificial Neural Networks;
               Permeability; Porosity; Attenuation},
  issn      = {0926-9851},
  doi       = {10.1016/j.jappgeo.2014.05.010}
}

@ARTICLE{Iturraran-Viveros2012-ta,
  title     = {Smooth regression to estimate effective porosity using seismic
               attributes},
  author    = {Iturrar{\'a}n-Viveros, Ursula},
  abstract  = {Data mining is very important to characterize complex geological
               structures, where a large variety of geophysical and
               petrophysical variables are typically involved and interrelated.
               In this paper we apply smooth regression for data analysis, by
               means of the Gamma test (a revolutionary estimator of the noise
               in a data set) to aid in the construction of Artificial Neural
               Network (ANN) models to predict effective porosity ($\varphi$e)
               using seismic attributes. As a result, we obtain the best
               combination of seismic attributes to estimate $\varphi$e. We
               briefly describe the Gamma test, its benefits in model
               identification and model building. The first validation of the
               Neural Network based on leave-one-out was poor. Therefore, we
               generate a complementary set of synthetic data (from the
               original well-log data), varying the effective porosity and
               applying the Gassmann's equation for fluid substitution to
               obtain resulting velocities and densities. The complete
               procedure is repeated including the new synthetic well-logs and
               the best suited selection of seismic attributes is used to train
               a new ANN producing a better validation and more accurate
               results. The advantage of smooth regression over other
               techniques is that it tells us how well we can predict
               $\varphi$e using any model. This information saves time during
               training of the ANN and also sets a lower bound for the mean
               squared error to prevent over-training.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  76,
  pages     = {1--12},
  month     =  jan,
  year      =  2012,
  url       = {http://www.sciencedirect.com/science/article/pii/S0926985111002485},
  keywords  = {Smooth regression; The Gamma test; Noise estimation; Seismic
               attributes; Artificial Neural Networks; Effective porosity},
  issn      = {0926-9851},
  doi       = {10.1016/j.jappgeo.2011.10.012}
}

@ARTICLE{Hulbert2018-xe,
  title         = {Estimating the Physical State of a Laboratory Slow Slipping
                   Fault from Seismic Signals},
  author        = {Hulbert, Claudia and Rouet-Leduc, Bertrand and Ren,
                   Christopher X and Riviere, Jacques and Bolton, David C and
                   Marone, Chris and Johnson, Paul A},
  abstract      = {Over the last two decades, strain and GPS measurements have
                   shown that slow slip on earthquake faults is a widespread
                   phenomenon. Slow slip is also inferred from correlated small
                   amplitude seismic signals known as nonvolcanic tremor and
                   low frequency earthquakes (LFEs). Slow slip has been
                   reproduced in laboratory and simulation studies, however the
                   fundamental physics of these phenomena and their
                   relationship to dynamic earthquake rupture remains poorly
                   understood. Here we show that, in a laboratory setting,
                   continuous seismic waves are imprinted with fundamental
                   signatures of the fault's physical state. Using machine
                   learning on continuous seismic waves, we can infer several
                   bulk characteristics of the fault (friction, shear
                   displacement, gouge thickness), at any time during the slow
                   slip cycle. This analysis also allows us to infer many
                   properties of the future behavior of the fault, including
                   the time remaining before the next slow slip event. Our work
                   suggests that by applying machine learning approaches to
                   continuous seismic data, new insight into the physics of
                   slow slip could be obtained in Earth.},
  month         =  jan,
  year          =  2018,
  url           = {http://arxiv.org/abs/1801.07806},
  archivePrefix = {arXiv},
  eprint        = {1801.07806},
  primaryClass  = {physics.geo-ph},
  arxivid       = {1801.07806}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Huang1990-hj,
  title     = {Self-organizing neural network for picking seismic horizons},
  author    = {Huang, K Y and Chang, W R I and Yen, H T},
  abstract  = {The research of neural networks on computer image recognition
               has surged over the past years which studied in the hope of
               achieving human-like performance. Now, there are a lot of
               excitable results we can see, especially, in the applications of
               self-organizing models. For example, the neural phonetic
               typewriter of Kohonen can automatically type the character from
               the input of speech, the neocognitron of Fukushima can recognize
               the hand-written numbers. Using the self-organizing feature
               maps, we can solve the classical travel salesman …},
  journal   = {SEG Technical Program Expanded},
  publisher = {library.seg.org},
  year      =  1990,
  url       = {https://library.seg.org/doi/pdf/10.1190/1.1890183}
}

@ARTICLE{Huang2017-fk,
  title     = {A scalable deep learning platform for identifying geologic
               features from seismic attributes},
  author    = {Huang, L and Dong, X and Clee, T},
  abstract  = {The modern requirement for analyzing and interpreting
               ever-larger volumes of seismic data to identify prospective
               hydrocarbon prospects within stringent time deadlines represents
               an ongoing challenge in petroleum exploration. To provide a
               computer-based aid in addressing this challenge, we have
               developed a ?big data? platform to facilitate the work of
               geophysicists in interpreting and analyzing large volumes of
               seismic data with scalable performance. We have constructed this
               platform on a modern distributed-memory infrastructure,
               providing a customized seismic analytics software development
               toolkit, and a Web-based graphical workflow interface along with
               a remote 3D visualization capability. These support the
               management of seismic data volumes, attributes processing,
               seismic analytics model development, workflow execution, and 3D
               volume visualization on a scalable, distributed computing
               platform. Early experiences show that computationally demanding
               deep learning methods such as convolutional neural networks
               (CNN) provide improved results over traditional methods such as
               support vector machines (SVMs) and logistic regression for
               identifying geologic faults in 3D seismic volumes. Our
               experiments show encouraging accuracy in identifying faults by
               combining CNN and traditional machine learning models with a
               variety of seismic attributes, and the platform is able to
               deliver scalable performance.},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  36,
  number    =  3,
  pages     = {249--256},
  month     =  mar,
  year      =  2017,
  url       = {https://doi.org/10.1190/tle36030249.1},
  issn      = {1070-485X},
  doi       = {10.1190/tle36030249.1}
}

@ARTICLE{Huang1996-eg,
  title     = {Permeability prediction with artificial neural network modeling
               in the Venture gas field, offshore eastern Canada},
  author    = {Huang, Z and Shimeld, J and Williamson, M and Katsube, J},
  abstract  = {Estimating permeability from well log information in uncored
               borehole intervals is an important yet difficult task
               encountered in many earth science disciplines. Most commonly,
               permeability is estimated from various well log curves using
               either empirical relationships or some form of multiple linear
               regression (MLR). More sophisticated, multiple nonlinear
               regression (MNLR) techniques are not as common because of
               difficulties associated with choosing an appropriate
               mathematical model and with analyzing the sensitivity of the
               chosen model to the various input variables. However, the recent
               development of a class of nonlinear optimization techniques
               known as artificial neural networks (ANNs) does much to overcome
               these difficulties. We use a back?propagation ANN (BP-ANN) to
               model the interrelationships between spatial position, six
               different well logs, and permeability. Data from four wells in
               the Venture gas field (offshore eastern Canada) are organized
               into training and supervising data sets for BP-ANN modeling.
               Data from a fifth well in the same field are retained as an
               independent data set for testing. When applied to this test
               data, the trained BP-ANN produces permeability values that
               compare well with measured values in the cored intervals.
               Permeability profiles calculated with the trained BP-ANN exhibit
               numerous low permeability horizons that are correlatable between
               the wells at Venture. These horizons likely represent important,
               intra?reservoir barriers to fluid migration that are significant
               for future reservoir production plans at Venture. For
               discussion, we also derive predictive equations using
               conventional statistical methods (i.e., MLR, and MNLR) with the
               same data set used for BP-ANN modeling. These examples highlight
               the efficacy of BP-ANNs as a means of obtaining multivariate,
               nonlinear models for difficult problems such as permeability
               estimation.},
  journal   = {Geophysics},
  publisher = {Society of Exploration Geophysicists},
  volume    =  61,
  number    =  2,
  pages     = {422--436},
  month     =  mar,
  year      =  1996,
  url       = {https://doi.org/10.1190/1.1443970},
  issn      = {0016-8033},
  doi       = {10.1190/1.1443970}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Honorio2015-my,
  title     = {Integration of {PCA} with a novel machine learning method for
               reparameterization and assisted history matching geologically
               complex reservoirs},
  author    = {Honorio, J and Chen, C and Gao, G and Du, K and {others}},
  abstract  = {It is a common practice to reduce the number of parameters that
               are used to fully describe a static geological model for
               assisted-history-matching (AHM) of geologically complex
               reservoirs. However, a model reconstructed from the reduced
               parameters may often be distorted from prior geological
               information, especially when discrete facies indicator presents
               in the model; for example, a reconstructed`` channel'' does not
               look like a channel. This paper presents a novel machine
               learning (ML) method that learns prior geological …},
  journal   = {SPE Annual Technical},
  publisher = {onepetro.org},
  year      =  2015,
  url       = {https://www.onepetro.org/conference-paper/SPE-175038-MS}
}

@ARTICLE{Hibert2014-yg,
  title     = {Automated identification, location, and volume estimation of
               rockfalls at Piton de la Fournaise volcano},
  author    = {Hibert, C and Mangeney, A and Grandjean, G and Baillard, C and
               Rivet, D and Shapiro, N M and Satriano, C and Maggi, A and
               Boissier, P and Ferrazzini, V and Crawford, W},
  abstract  = {AbstractSince the collapse of the Dolomieu crater floor at Piton
               de la Fournaise Volcano (la R{\'e}union) in 2007, hundreds of
               seismic signals generated by rockfalls have been recorded daily
               at the Observatoire Volcanologique du Piton de la Fournaise
               (OVPF). To study rockfall activity over a long period of time,
               automated methods are required to process the available
               continuous seismic records. We present a set of automated
               methods designed to identify, locate, and estimate the volume of
               rockfalls from their seismic signals. The method used to
               automatically discriminate seismic signals generated by
               rockfalls from other common events recorded at OVPF is based on
               fuzzy sets and has a success rate of 92\%. A kurtosis-based
               automated picking method makes it possible to precisely pick the
               onset time and the final time of the rockfall-generated seismic
               signals. We present methods to determine rockfall locations
               based on these accurate pickings and a surface-wave propagation
               model computed for each station using a Fast Marching Method.
               These methods have successfully located directly observed
               rockfalls with an accuracy of about 100 m. They also make it
               possible to compute the seismic energy generated by rockfalls,
               which is then used to retrieve their volume. The methods
               developed were applied to a data set of 12,422 rockfalls that
               occurred over a period extending from the collapse of the
               Dolomieu crater floor in April 2007 to the end of the UnderVolc
               project in May 2011 to identify the most hazardous areas of the
               Piton de la Fournaise volcano summit.},
  journal   = {J. Geophys. Res. Earth Surf.},
  publisher = {Wiley Online Library},
  volume    =  119,
  number    =  5,
  pages     = {1082--1105},
  month     =  may,
  year      =  2014,
  url       = {http://doi.wiley.com/10.1002/2013JF002970},
  issn      = {2169-9003},
  doi       = {10.1002/2013JF002970}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Helle2002-ju,
  title     = {Fluid saturation from well logs using committee neural networks},
  author    = {Helle, H B and Bhatt, A},
  abstract  = {Neural computing has made a major step forward by the
               introduction of multi-net systems in practical applications. In
               this study we developed and tested a modular artificial neural
               network system for predicting underground fluids, water, oil and
               gas, and their partial saturations, directly from well logs,
               without explicit knowledge of the fluid and rock properties as
               required by conventional methods. Based on laboratory data on
               relative permeability for alternative fluid systems--oil--water
               or gas--oil--respectively, relative permeability logs may …},
  journal   = {Pet. Geosci.},
  publisher = {pg.lyellcollection.org},
  year      =  2002,
  url       = {http://pg.lyellcollection.org/content/8/2/109.short},
  issn      = {1354-0793}
}

@ARTICLE{Hansen2017-rq,
  title     = {Efficient Monte Carlo sampling of inverse problems using a
               neural network-based forward---applied to {GPR} crosshole
               traveltime inversion},
  author    = {Hansen, T M and Cordua, K S},
  abstract  = {Probabilistically formulated inverse problems can be solved
               using Monte Carlo-based sampling methods. In principle, both
               advanced prior information, based on for example, complex
               geostatistical models and non-linear forward models can be
               considered using such methods. However, Monte Carlo methods may
               be associated with huge computational costs that, in practice,
               limit their application. This is not least due to the
               computational requirements related to solving the forward
               problem, where the physical forward response of some earth model
               has to be evaluated. Here, it is suggested to replace a
               numerical complex evaluation of the forward problem, with a
               trained neural network that can be evaluated very fast. This
               will introduce a modeling error that is quantified
               probabilistically such that it can be accounted for during
               inversion. This allows a very fast and efficient Monte Carlo
               sampling of the solution to an inverse problem. We demonstrate
               the methodology for first arrival traveltime inversion of
               crosshole ground penetrating radar data. An accurate forward
               model, based on 2-D full-waveform modeling followed by automatic
               traveltime picking, is replaced by a fast neural network. This
               provides a sampling algorithm three orders of magnitude faster
               than using the accurate and computationally expensive forward
               model, and also considerably faster and more accurate (i.e. with
               better resolution), than commonly used approximate forward
               models. The methodology has the potential to dramatically change
               the complexity of non-linear and non-Gaussian inverse problems
               that have to be solved using Monte Carlo sampling techniques.},
  journal   = {Geophys. J. Int.},
  publisher = {Oxford University Press},
  volume    =  211,
  number    =  3,
  pages     = {1524--1533},
  month     =  dec,
  year      =  2017,
  url       = {https://academic.oup.com/gji/article-abstract/211/3/1524/4157792},
  issn      = {0956-540X},
  doi       = {10.1093/gji/ggx380}
}

@INPROCEEDINGS{Harrigan1991-ij,
  title     = {Seismic wavelet extraction using artificial neural networks},
  booktitle = {1991 Second International Conference on Artificial Neural
               Networks},
  author    = {Harrigan, E and Kroh, J R and Sandham, W A and Durrani, T S},
  abstract  = {Geophysical events are of interest to the interpreter as an
               indicator of geological boundaries and structures. In structural
               analysis, extraction of reflection events is still commonly done
               by hand, a process which is error-prone and time consuming.
               Attempts to automate the process are hindered by the absence of
               a clear, robust and universal picking algorithm. A new feature
               extraction technique for seismic data interpretation, using a
               trained Artificial Neural Network is presented. It is shown that
               this method is useful in extracting geophysical events where
               conventional pattern recognition techniques may fail.>},
  publisher = {ieeexplore.ieee.org},
  pages     = {95--99},
  month     =  nov,
  year      =  1991,
  url       = {https://ieeexplore.ieee.org/abstract/document/140293/},
  keywords  = {computerised pattern recognition;geophysical
               techniques;geophysics computing;neural nets;seismic
               waves;artificial neural networks;feature extraction;seismic data
               interpretation;geophysical events;pattern recognition;Pattern
               recognition;Geophysical measurements;Neural networks;Seismic
               waves}
}

@ARTICLE{Hamdi2017-no,
  title     = {Gaussian Processes for history-matching: application to an
               unconventional gas reservoir},
  author    = {Hamdi, Hamidreza and Couckuyt, Ivo and Sousa, Mario Costa and
               Dhaene, Tom},
  abstract  = {The process of reservoir history-matching is a costly task. Many
               available history-matching algorithms either fail to perform
               such a task or they require a large number of simulation runs.
               To overcome such struggles, we apply the Gaussian Process (GP)
               modeling technique to approximate the costly objective functions
               and to expedite finding the global optima. A GP model is a
               proxy, which is employed to model the input-output relationships
               by assuming a multi-Gaussian distribution on the output values.
               An infill criterion is used in conjunction with a GP model to
               help sequentially add the samples with potentially lower
               outputs. The IC fault model is used to compare the efficiency of
               GP-based optimization method with other typical optimization
               methods for minimizing the objective function. In this paper, we
               present the applicability of using a GP modeling approach for
               reservoir history-matching problems, which is exemplified by
               numerical analysis of production data from a horizontal
               multi-stage fractured tight gas condensate well. The results for
               the case that is studied here show a quick convergence to the
               lowest objective values in less than 100 simulations for this
               20-dimensional problem. This amounts to an almost 10 times
               faster performance compared to the Differential Evolution (DE)
               algorithm that is also known to be a powerful optimization
               technique. The sensitivities are conducted to explain the
               performance of the GP-based optimization technique with various
               correlation functions.},
  journal   = {Computational Geosciences},
  publisher = {Springer},
  volume    =  21,
  number    =  2,
  pages     = {267--287},
  month     =  apr,
  year      =  2017,
  url       = {https://doi.org/10.1007/s10596-016-9611-2},
  issn      = {1573-1499},
  doi       = {10.1007/s10596-016-9611-2}
}

@ARTICLE{Hall2016-xh,
  title     = {Facies classification using machine learning},
  author    = {Hall, B},
  abstract  = {There has been much excitement recently about big data and the
               dire need for data scientists who possess the ability to extract
               meaning from it. Geoscientists, meanwhile, have been doing
               science with voluminous data for years, without needing to brag
               about how big it is. But now that large, complex data sets are
               widely available, there has been a proliferation of tools and
               techniques for analyzing them. Many free and open-source
               packages now exist that provide powerful additions to the
               geoscientist's toolbox, much of which used to be only available
               in proprietary (and expensive) software platforms.},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  35,
  number    =  10,
  pages     = {906--909},
  month     =  oct,
  year      =  2016,
  url       = {https://doi.org/10.1190/tle35100906.1},
  issn      = {1070-485X},
  doi       = {10.1190/tle35100906.1}
}

@article{dorigo1992optimization,
  title={Optimization, learning and natural algorithms},
  author={Dorigo, Marco},
  journal={PhD Thesis, Politecnico di Milano},
  year={1992}
}

@ARTICLE{Hall2017-fk,
  title     = {Distributed collaborative prediction: Results of the machine
               learning contest},
  author    = {Hall, M and Hall, B},
  abstract  = {The Geophysical Tutorial in the October issue of The Leading
               Edge was the first we've done on the topic of machine learning.
               Brendon Hall's article (Hall, 2016) showed readers how to take a
               small data set ? wireline logs and geologic facies data from
               nine wells in the Hugoton natural gas and helium field of
               southwest Kansas (Dubois et al., 2007) ? and predict the facies
               in two wells for which the facies data were not available. The
               article demonstrated with 25 lines of code how to explore the
               data set, then create, train and test a machine learning model
               for facies classification, and finally visualize the results.
               The workflow took a deliberately naive approach using a support
               vector machine model. It achieved a sort of baseline accuracy
               rate ? a first-order prediction, if you will ? of 0.42. That
               might sound low, but it's not untypical for a naive approach to
               this kind of problem. For comparison, random draws from the
               facies distribution score 0.16, which is therefore the true
               baseline.},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  36,
  number    =  3,
  pages     = {267--269},
  month     =  mar,
  year      =  2017,
  url       = {https://doi.org/10.1190/tle36030267.1},
  issn      = {1070-485X},
  doi       = {10.1190/tle36030267.1}
}

@ARTICLE{Hale2013-fu,
  title     = {Methods to compute fault images, extract fault surfaces, and
               estimate fault throws from {3D} seismic images},
  author    = {Hale, D},
  abstract  = {ABSTRACTFault interpretation enhances our understanding of
               complex geologic structures and stratigraphy apparent in 3D
               seismic images. Common steps in this interpretation include
               image processing to highlight faults, the construction of fault
               surfaces, and estimation of fault throws. Although all three of
               these steps have been automated to some extent by others, fault
               interpretation today typically requires significant manual
               effort, suggesting that further improvements in automatic
               methods are feasible and worthwhile. I first used an efficient
               algorithm to compute images of fault likelihoods, strikes, and
               dips from a 3D seismic image. From these three fault images, I
               then automatically extracted fault surfaces as meshes of
               quadrilaterals that coincide with ridges of fault likelihood. A
               quadrilateral mesh is a simple data structure alongside which
               one can easily gather samples of the 3D seismic image. I
               automatically estimated fault throws by minimizing differences
               in values of samples gathered from opposite sides of a fault,
               while constraining the variation of throw within a fault
               surface. I tested the fidelity of estimated fault throws by
               using them to undo faulting. After unfaulting, reflectors in 3D
               seismic images were more continuous than those in the original
               3D seismic image. In one example, this unfaulting test supported
               the observation that some extracted fault surfaces have unusual
               conical shapes.},
  journal   = {Geophysics},
  publisher = {Society of Exploration Geophysicists},
  volume    =  78,
  number    =  2,
  pages     = {O33--O43},
  month     =  mar,
  year      =  2013,
  url       = {https://doi.org/10.1190/geo2012-0331.1},
  issn      = {0016-8033},
  doi       = {10.1190/geo2012-0331.1}
}

@ARTICLE{Gupta2018-ut,
  title     = {Rock typing in the Upper {Devonian-Lower} Mississippian Woodford
               Shale Formation, Oklahoma, {USA}},
  author    = {Gupta, I and Rai, C and Sondergeld, C and Devegowda, D},
  abstract  = {AbstractMost U.S. shale plays are spatially extensive with
               regions of different thermal maturity and varying production
               prospects. With increasing understanding of the heterogeneity,
               microstructure, and anisotropy of shales, efforts are now
               directed to identifying the sweet spots and optimum completion
               zones in any shale play. Rock typing is a step in this
               direction. We have developed an integrated workflow for rock
               typing using laboratory-petrophysical measurements on core
               samples and well logs. A total of seven wells with core data
               were considered for rock typing in the Woodford Shale. The
               integrated workflow has been applied in the Woodford Shale in a
               series of steps. In the first step, unsupervised clustering
               algorithms such as K-means and self-organizing maps were used to
               define the rock types. Rock type 1 is generally characterized by
               high porosity and total organic carbon (TOC). Rock type 2 had
               intermediate values of porosity and TOC and thus, moderate
               source potential and storage. Rock type 3 had the highest
               carbonate content, poor storage, and source rock potential. In
               the next step, a classification algorithm, support vector
               machines (SVM), was used to extend the rock types from the cores
               to the logs. A logging suite with gamma ray, resistivity,
               neutron porosity, and density logs was used for extending the
               rock types. These logs were used because they are commonly
               available and adequate to differentiate different rock types.
               The rock types were populated in the uncored sections of the
               seven cored wells and additionally in 12 wells (taken from
               Drilling Info) using a trained SVM model. Additional wells were
               taken to have sufficient data for production correlation. In the
               final step, a rock-type ratio (RTR) was defined based on the
               fraction of rock type 1 over the gross thickness. RTR was found
               to positively correlate with normalized oil equivalent
               production.},
  journal   = {Interpretation},
  publisher = {Society of Exploration Geophysicists},
  volume    =  6,
  number    =  1,
  pages     = {SC55--SC66},
  month     =  feb,
  year      =  2018,
  url       = {https://doi.org/10.1190/INT-2017-0015.1},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2017-0015.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Guo2017-ij,
  title     = {Sweet Spot Interpretation from Multiple Attributes: Machine
               Learning and Neural Networks Technologies},
  author    = {Guo, R and Zhang, Y S and Lin, H and Liu, W},
  abstract  = {The ``sweet spot'' interpretation of shale gas routinely
               involves advanced visualization techniques, and generation of
               numerous seismic data types and attributes. Commonly used
               seismic attributes include the total organic carbon content
               (TOC), pore pressure, stresses, rock elasticity, brittleness and
               fracture development. To derive even more useful information
               from the multiple attributes and provide a easily tool for the
               characteristic analysis of the target shale reservoir, current
               visualization techniques, machine learning and neural …},
  journal   = {First EAGE/AMGP/AMGE Latin},
  publisher = {earthdoc.org},
  year      =  2017,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=90731}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Gulbrandsen2017-oj,
  title     = {Automatic mapping of the base of aquifer---A case study from
               Morrill, Nebraska},
  author    = {Gulbrandsen, M L and Ball, L B and Minsley, B J and Hansen, T M},
  abstract  = {When a geologist sets up a geologic model, various types of
               disparate information may be available, such as exposures,
               boreholes, and (or) geophysical data. In recent years, the
               amount of geophysical data available has been increasing, a
               trend that is only expected to continue. It is nontrivial (and
               often, in practice, impossible) for the geologist to take all
               the details of the geophysical data into account when setting up
               a geologic model. We have developed an approach that allows for
               the objective quantification of information from …},
  journal   = {Interpretation},
  publisher = {library.seg.org},
  year      =  2017,
  url       = {https://library.seg.org/doi/abs/10.1190/INT-2016-0195.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Guitton2018-gd,
  title     = {{3D} Convolutional Neural Networks for Fault Interpretation},
  author    = {Guitton, A},
  abstract  = {Faults in 3D seismic volumes are identified with a machine
               learning approach. For this task, a 3D convolutional neural
               network (3DCNN) is designed to produce a heat map of fault
               locations in a given seismic volume. Then, the heat map yields
               fault picks that can be used for building fault planes and
               surfaces. Using 3D convolutional filters, as opposed to 2D,
               allows the algorithm to extract a feature set for classification
               that merges information from all dimensions available. This
               ability translates in better prediction accuracy. The 3DCNN …},
  journal   = {80th EAGE Conference and Exhibition 2018},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=92118}
}

@INCOLLECTION{Guillen2015-re,
  title     = {Supervised learning to detect salt body},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2015},
  author    = {Guillen, P and Larrazabal*, G and Gonz{\'a}lez, G and Boumber, D
               and Vilalta, R},
  abstract  = {Summary In this paper we are presenting a novel workflow to
               detect salt body base on seismic attributes and supervised
               learning. The machine learning algorithm Extremely Random Trees
               Ensemble is used to train and automatically identifying and
               classify salt regions. We have used a complex synthetic seismic
               dataset from phase I model of the SEG Advanced Modeling
               Corporation (SEAM), that represents deepwater regions of Gulf of
               Mexico. This dataset has very low frequency and there are
               sediments locations with similar amplitude value than salt body.
               After a first step of our proposal, where machine learning is
               applied directly to the seismic data, we obtained accuracy
               values of around 80\%. A second (post-processing) step brings up
               accuracy to around 95\%. We conclude that machine learning is a
               promise mechanism to identify salt bodies on seismic data when
               the selected model exhibits enough capacity to model the complex
               decision boundaries needed during class discrimination.},
  publisher = {Society of Exploration Geophysicists},
  pages     = {1826--1829},
  series    = {SEG Technical Program Expanded Abstracts},
  month     =  aug,
  year      =  2015,
  url       = {https://doi.org/10.1190/segam2015-5931401.1},
  doi       = {10.1190/segam2015-5931401.1}
}

@INCOLLECTION{Granek2015-ci,
  title     = {Data mining for real mining: A robust algorithm for
               prospectivity mapping with uncertainties},
  booktitle = {Proceedings of the 2015 {SIAM} International Conference on Data
               Mining},
  author    = {Granek, J and Haber, E},
  abstract  = {Abstract Mineral prospectivity mapping is an emerging
               application for machine learning algorithms which presents a
               series of practical difficulties. The goal is to learn the
               mapping function which can predict the existence or absence of
               economic mineralization from a compilation of geoscience
               datasets (ie: bedrock type, magnetic signature, geochemical
               response etc). The challenges include sparse, imbalanced labels
               (mineralization occurrences), varied label reliability, and a
               wide range in data quality and uncertainty. In order to address
               these issues an algorithm was developed based on total least
               squares and support vector machine regression which incorporates
               both data and label uncertainty into the objective function.
               This was done without losing sparsity in the residuals, thus
               maintaining minimal support vectors. Mineral prospectivity
               mapping is an application for machine learning which presents a
               series of practical difficulties. The goal is to learn the
               mapping function which can predict the existence of
               mineralization from a compilation of geoscience datasets.
               Challenges include sparse, imbalanced labels, varied label
               reliability, and a wide range in data uncertainty. To address
               this, an algorithm was developed based on TLS and SVM which
               incorporates both data and label uncertainty into the objective
               function.},
  publisher = {Society for Industrial and Applied Mathematics},
  pages     = {145--153},
  series    = {Proceedings},
  month     =  jun,
  year      =  2015,
  url       = {https://doi.org/10.1137/1.9781611974010.17},
  doi       = {10.1137/1.9781611974010.17}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Gramstad2018-ql,
  title     = {Automated Top Salt Interpretation Using a Deep Convolutional Net},
  author    = {Gramstad, O and Nickel, M},
  abstract  = {We present a new automated workflow based on machine learning
               which can significantly reduce the amount of manual
               interpretation of the top salt boundary. Manual interpretation
               of top salt on large seismic surveys with complex salt geometry
               is a time-consuming task. The interpreters typically need to
               scan through the seismic volume and pick control points line-by-
               line. It can take more than a month to complete a top salt
               interpretation. In this new method, a convolutional neural net
               is designed to detect the top of salt boundaries and the
               training …},
  journal   = {80th EAGE Conference and Exhibition 2018},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=92117}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Golsanami2015-ul,
  title     = {Synthesis of capillary pressure curves from post-stack seismic
               data with the use of intelligent estimators: a case study from
               the Iranian part of the South Pars …},
  author    = {Golsanami, N and Kadkhodaie-Ilkhchi, A and Erfani, A},
  abstract  = {Capillary pressure curves are important data for reservoir rock
               typing, analyzing pore throat distribution, determining height
               above free water level, and reservoir simulation. Laboratory
               experiments provide accurate data, however they are expensive,
               time-consuming and discontinuous through the reservoir
               intervals. The current study focuses on synthesizing artificial
               capillary pressure (Pc) curves from seismic attributes with the
               use of artificial intelligent systems including Artificial
               Neural Networks (ANNs), Fuzzy logic (FL) and …},
  journal   = {Journal of Applied},
  publisher = {Elsevier},
  year      =  2015,
  url       = {https://www.sciencedirect.com/science/article/pii/S0926985114003413}
}

@ARTICLE{You2018-uq,
  title     = {Reconstruction and prediction of capillary pressure curve based
               on Particle Swarm {Optimization-Back} Propagation Neural Network
               method},
  author    = {You, Lijun and Tan, Qigui and Kang, Yili and Xu, Chengyuan and
               Lin, Chong},
  abstract  = {Capillary pressure curve plays a critical role in the reservoir
               evaluation. It is essential to reconstruct and predict capillary
               pressure curve properly. Many traditional capillary pressure
               correlations have been suggested in the literature. However,
               their major limitation is mainly applicable to homogenous
               reservoir, and the larger error will be caused when
               heterogeneous reservoir is dealt by using these mathematical
               correlations. This study aims at providing an important method
               based on Particle Swarm Optimization-Back Propagation Neural
               Network (PSO-BP neural network) to represent and predict
               capillary pressure curve for homogenous and heterogeneous
               reservoir. The combination of PSO algorithm and BP neural
               network converges quickly, which improves the accuracy and
               efficiency of simulation. In this paper, core samples from three
               blocks of the same marine-sand reservoir, whose porosity is
               between 0.6\% and 20.0\% and permeability is between 0.1mD and
               6117mD, are investigated by PSO-BP neural network method and
               J-Function method respectively. The reconstruction and
               prediction results are compared with the results obtained by
               mercury intrusion method in laboratory. The results show that
               capillary pressure curves reconstructed and predicted by PSO-BP
               neural network method are in better agreement with mercury
               intrusion curves than J-Function method, with 0.1\%--5\% and
               5\%--8\% relative error respectively, which can totally meet the
               in-situ requirements. It is also demonstrated that PSO-BP neural
               network method is more suitable for homogenous and heterogeneous
               reservoir.},
  journal   = {Petroleum},
  publisher = {Elsevier},
  volume    =  4,
  number    =  3,
  pages     = {268--280},
  month     =  sep,
  year      =  2018,
  url       = {http://www.sciencedirect.com/science/article/pii/S2405656117300494},
  keywords  = {Capillary pressure curve; Homogenous reservoir; Heterogeneous
               reservoir; PSO-BP neural network; Mercury intrusion},
  issn      = {2405-6561},
  doi       = {10.1016/j.petlm.2018.03.004}
}

@ARTICLE{Dong2018-ri,
  title     = {A method to construct high-precision complex pore digital rock},
  author    = {Dong, Huaimin and Sun, Jianmeng and Golsanami, Naser and Cui,
               Likai and Jiang, Liming and Yan, Guoliang and Yan, Weichao and
               Li, Yafen},
  abstract  = {X-ray CT scanning is one of the main methods to study the pore
               structure of the rocks. However, low resolution is currently one
               of the major challenges of this method, which does not allow for
               the identification of microscopic pores. Even though adopting
               images of higher resolutions could reflect the microscopic pores
               of the rocks, due to the small size of the scanned rock sample
               in the x-ray CT scanning method, the rock parameters cannot be
               effectively obtained, especially for the rocks with strong
               heterogeneity. This would cause the loss of important pore
               information, such as fractures' information. Focusing on this
               problem, the current research tries to propose a method for
               constructing high-precision digital rocks of complexly porous
               rocks. This method is based on the simultaneous application of
               x-ray CT scanning images, nuclear magnetic resonance
               measurements, as well as mercury injection experimental data and
               fractal discrete fracture network. These methods effectively
               compensate for the shortcomings of the scanning method where it
               cannot capture pores smaller than the scanning resolution and
               for the lack of fracture information due to rock sampling. The
               research results showed that compared with the digital rock
               models constructed by single-resolution scanning, the
               high-precision complex pore digital rock constructed by this
               method can effectively improve the accuracy of the results of
               porosity and permeability calculations. These results were
               closer to the results of rock physics experiments. This approach
               provides a solid foundation for the numerical simulation of rock
               parameters in unconventional reservoirs with complex pore
               structures, such as carbonate, tight sandstone and shale
               reservoirs.},
  journal   = {J. Geophys. Eng.},
  publisher = {Oxford University Press},
  volume    =  15,
  number    =  6,
  pages     = {2695--2703},
  month     =  dec,
  year      =  2018,
  url       = {https://academic.oup.com/jge/article-abstract/15/6/2695/5209806},
  issn      = {1742-2132},
  doi       = {10.1088/1742-2140/aae04e}
}

@ARTICLE{Gentili2006-tp,
  title     = {Automatic picking of {P} and {S} phases using a neural tree},
  author    = {Gentili, S and Michelini, A},
  abstract  = {The large amount of digital data recorded by permanent and
               temporary seismic networks makes automatic analysis of
               seismograms and automatic wave onset time picking schemes of
               great importance for timely and accurate event locations. We
               propose a fast and efficient P- and S-wave onset time, automatic
               detection method based on neural networks. The neural networks
               adopted here are particular neural trees, called IUANT2,
               characterized by a high generalization capability. Comparison
               between neural network automatic onset picking and standard,
               manual methods, shows that the technique presented here is
               generally robust and that it is capable to correctly identify
               phase-types while providing estimates of their accuracies. In
               addition, the automatic post processing method applied here can
               remove the ambiguity deriving from the incorrect association of
               events occurring closely in time. We have tested the methodology
               against standard STA/LTA phase picks and found that this neural
               approach performs better especially for low signal-to-noise
               ratios. We adopt the recall, precision and accuracy estimators
               to appraise objectively the results and compare them with those
               obtained with other methodologies.},
  journal   = {J. Seismol.},
  publisher = {Springer},
  volume    =  10,
  number    =  1,
  pages     = {39--63},
  month     =  jan,
  year      =  2006,
  url       = {https://doi.org/10.1007/s10950-006-2296-6},
  issn      = {1383-4649, 1573-157X},
  doi       = {10.1007/s10950-006-2296-6}
}

@ARTICLE{Gamba2000-va,
  title     = {Neural detection of pipe signatures in ground penetrating radar
               images},
  author    = {Gamba, P and Lossani, S},
  abstract  = {A processing chain for the spatial analysis of the data recorded
               by a ground penetrating radar (GPR) is presented. In particular,
               the detection and localization of pipes is implemented by
               exploiting the a priori knowledge that a buried cylinder gives
               rise to a hyperbolic signature in GPR images. The image
               interpretation is performed by a suitably trained simple neural
               detector after some preprocessing steps aiming toward the
               enhancement of the buried objects' signatures. The algorithm has
               been tested on actual GPR images and compared with the
               information extracted by a trained human operator, and the
               agreement is extremely satisfying. Moreover, the possibilities
               and advantages to exploiting some sort of ``spatial diversity''
               by combining the analysis of data simultaneously recorded by
               different antennas are presented and discussed.},
  journal   = {IEEE Trans. Geosci. Remote Sens.},
  publisher = {ieeexplore.ieee.org},
  volume    =  38,
  number    =  2,
  pages     = {790--797},
  month     =  mar,
  year      =  2000,
  url       = {http://dx.doi.org/10.1109/36.842008},
  keywords  = {geophysical techniques;terrestrial electricity;remote sensing by
               radar;buried object detection;geophysics computing;neural
               nets;geophysical signal processing;geophysical measurement
               technique;terrain mapping;geoelectric method;terrestrial
               electricity;radar remote sensing;neural detection;neural
               net;neural network;pipe signature;ground penetrating radar;radar
               imaging;processing chain;spatial analysis;GPR;localization;a
               priori knowledge;buried cylinder;hyperbolic
               signature;preprocessing;algorithm;spatial diversity;buried
               object detection;Radar detection;Ground penetrating radar;Image
               analysis;Data analysis;Buried object detection;Neural
               networks;Soil;Geologic measurements;Electromagnetic
               analysis;Performance analysis},
  issn      = {0196-2892},
  doi       = {10.1109/36.842008}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Gaganis2012-yw,
  title     = {Machine Learning Methods to Speed up Compositional Reservoir
               Simulation ({SPE} 154505)},
  author    = {Gaganis, V and Varotsis, N},
  abstract  = {Compositional reservoir simulation is one of the most powerful
               techniques currently available to the reservoir engineer upon
               which most reservoir development decisions rely on. According to
               the number of components used to describe the fluids there is an
               increasing demand for computational power due to the complexity
               and the iterative nature of the solution process. Phase
               stability and phase split computations often consume more than
               50\% of the simulation total CPU time as both problems need to
               be solved repeatedly and …},
  journal   = {74th EAGE Conference and Exhibition},
  publisher = {earthdoc.org},
  year      =  2012,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=59137}
}

@ARTICLE{Fung1997-kw,
  title     = {Modular artificial neural network for prediction of
               petrophysical properties from well log data},
  author    = {Fung, Chun Che and Wong, Kok Wai and Eren, H},
  abstract  = {An application of Kohonen's self-organizing map (SOM),
               learning-vector quantization (LVQ) algorithms, and commonly used
               backpropagation neural network (BPNN) to predict petrophysical
               properties obtained from well-log data are presented. A modular,
               artificial neural network (ANN) comprising a complex network
               made up from a number of subnetworks is introduced. In this
               approach, the SOM algorithm is applied first to classify the
               well-log data into a predefined number of classes, This gives an
               indication of the lithology in the well. The classes obtained
               from SOM are then appended back to the training input logs for
               the training of supervised LVQ. After training, LVQ can be used
               to classify any unknown input logs. A set of BPNN that
               corresponds to different classes is then trained. Once the
               network is trained, it is then used as the classification and
               prediction model for subsequent input data. Results obtained
               from example studies using the proposed method have shown to be
               fast and accurate as compared to a single BPNN network.},
  journal   = {IEEE Trans. Instrum. Meas.},
  publisher = {ieeexplore.ieee.org},
  volume    =  46,
  number    =  6,
  pages     = {1295--1299},
  month     =  dec,
  year      =  1997,
  url       = {http://dx.doi.org/10.1109/19.668276},
  keywords  = {self-organising feature
               maps;backpropagation;modules;rocks;natural
               resources;geology;geophysical techniques;prediction
               theory;modular artificial neural network;prediction of
               petrophysical properties;well log data;Kohonen's self-organizing
               map;learning-vector quantization algorithms;backpropagation
               neural network;petrophysical properties;complex network;SOM
               algorithm;training input logs;supervised LVQ;BPNN network;self
               organising log;Artificial neural networks;Backpropagation
               algorithms;Neural networks;Complex
               networks;Reservoirs;Statistical analysis;Predictive
               models;Vector quantization;Organizing},
  issn      = {0018-9456},
  doi       = {10.1109/19.668276}
}

@ARTICLE{Chang2002-oi,
  title     = {Identification of lithofacies using Kohonen self-organizing maps},
  author    = {Chang, Hsien-Cheng and Kopaska-Merkel, David C and Chen,
               Hui-Chuan},
  abstract  = {Lithofacies identification is a primary task in reservoir
               characterization. Traditional techniques of lithofacies
               identification from core data are costly, and it is difficult to
               extrapolate to non-cored wells. We present a low-cost automated
               technique using Kohonen self-organizing maps (SOMs) to identify
               systematically and objectively lithofacies from well log data.
               SOMs are unsupervised artificial neural networks that map the
               input space into clusters in a topological form whose
               organization is related to trends in the input data. A case
               study used five wells located in Appleton Field, Escambia
               County, Alabama (Smackover Formation, limestone and dolomite,
               Oxfordian, Jurassic). A five-input, one-dimensional output
               approach is employed, assuming the lithofacies are in
               ascending/descending order with respect to paleoenvironmental
               energy levels. To consider the possible appearance of new
               logfacies not seen in training mode, which may potentially
               appear in test wells, the maximum number of outputs is set to 20
               instead of four, the designated number of lithofacies in the
               study area. This study found eleven major clusters. The clusters
               were compared to depositional lithofacies identified by manual
               core examination. The clusters were ordered by the SOM in a
               pattern consistent with environmental gradients inferred from
               core examination: bind/boundstone, grainstone, packstone, and
               wackestone. This new approach predicted lithofacies identity
               from well log data with 78.8\% accuracy which is more accurate
               than using a backpropagation neural network (57.3\%). The
               clusters produced by the SOM are ordered with respect to
               paleoenvironmental energy levels. This energy-related clustering
               provides geologists and petroleum engineers with valuable
               geologic information about the logfacies and their
               interrelationships. This advantage is not obtained in
               backpropagation neural networks and adaptive resonance theory
               neural networks.},
  journal   = {Comput. Geosci.},
  publisher = {Elsevier},
  volume    =  28,
  number    =  2,
  pages     = {223--229},
  month     =  mar,
  year      =  2002,
  url       = {http://www.sciencedirect.com/science/article/pii/S009830040100067X},
  keywords  = {Neural networks; Carbonate rocks; Paleoenvironmental energy;
               Well log},
  issn      = {0098-3004},
  doi       = {10.1016/S0098-3004(01)00067-X}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ferreira2018-gr,
  title     = {{Texture-Based} Similarity Graph to Aid Seismic Interpretation},
  author    = {Ferreira, R and Brazil, E V and Silva, R and {others}},
  abstract  = {Seismic interpreters use their trained eyes to assess the
               similarity between seismic datasets. However, to find and
               evaluate all relevant parts of a seismic cube can be a
               time-consuming task. We have developed a method based on texture
               analysis and graph theory that can automatically compare seismic
               lines. Such a method has the potential to help experts in
               several tasks and, to the best of our knowledge, it is the first
               one to tackle seismic image similarity combining texture
               descriptors and graphs. This work proposes a texture-based …},
  journal   = {ACE 2018 Annual},
  publisher = {searchanddiscovery.com},
  year      =  2018,
  url       = {http://www.searchanddiscovery.com/documents/2018/70365ferreira/ndx_ferreira.pdf}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Feng1998-ck,
  title     = {Neural network dynamic modelling of rock microfracturing
               sequences under triaxial compressive stress conditions},
  author    = {Feng, Xia-Ting and Seto, Masahiro},
  abstract  = {Rock fracturing processes are very complicated nonlinear dynamic
               systems. Distributions of acoustic emission (AE) events in the
               time dimension during microfracturing processes of rock under
               triaxial compressive stress conditions have fractal structures
               that proceed as C(t)∝tD, where the fractal dimension D is
               0.43$\leq$D<1.0. As the fracturing process progresses, the
               system's state initially changes from ordered to disordered
               (fractal dimension D decreases from about 1 to about 0.48) and
               then changes back to ordered (fractal dimension increases from
               0.48 to about 0.91). Corresponding to each evolutionary process
               of the system's states, AE event patterns such as the AE event
               rate, AE count rate, and amplitude in rock fracturing processes
               were recognized using neural network techniques. AE event
               patterns at 8--10 succeeding time points were predicted using
               the corresponding models. AE event patterns in rock
               microfracturing processes are effectively described by the
               neural dynamic model NN(n,h,1). The models so obtained are
               applicable for extrapolated recognition of AE event patterns
               with adequate accuracy. An improved learning algorithm is
               proposed to train the networks with generally improved
               performance of the models.},
  journal   = {Tectonophysics},
  publisher = {Elsevier},
  volume    =  292,
  number    =  3,
  pages     = {293--309},
  month     =  jul,
  year      =  1998,
  url       = {http://www.sciencedirect.com/science/article/pii/S0040195198000729},
  keywords  = {rock microfracturing process; acoustic emission; neural network;
               fractal; forecasting; multi-step extrapolating pattern
               recognition},
  issn      = {0040-1951},
  doi       = {10.1016/S0040-1951(98)00072-9}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Fang2017-dm,
  title     = {{SeismOlympics}},
  author    = {Fang, Lihua and Wu, Zhongliang and Song, Kuan},
  abstract  = {On 23 May 2017, a clear day in Chengdu, the capital city of
               Sichuan Province in China, located∼ 80 km away from the
               epicenter of the 2008 M s 8.0 Wenchuan earthquake, Alibaba Cloud
               (the largest cloud computing company in China, a subsidiary of
               Alibaba …},
  journal   = {Seismol. Res. Lett.},
  publisher = {GeoScienceWorld},
  volume    =  88,
  number    =  6,
  pages     = {1429--1430},
  month     =  nov,
  year      =  2017,
  url       = {https://pubs.geoscienceworld.org/ssa/srl/article-abstract/88/6/1429/353988},
  issn      = {0895-0695},
  doi       = {10.1785/0220170134}
}

@ARTICLE{Falsaperla1996-bj,
  title     = {Automatic classification of volcanic earthquakes by using
               {Multi-Layered} neural networks},
  author    = {Falsaperla, S and Graziani, S and Nunnari, G and Spampinato, S},
  abstract  = {The application of neural networks as classifiers of seismic
               events is described with the aim of developing an automatic
               system for the classification of `explosion quakes' at the
               Stromboli volcano. The architecture of the network that we
               trained to identify four different classes of shocks was a
               Multi-Layer Perceptron, using the Back Error Propagation
               algorithm. Five different approaches for representing the
               information embedded in the seismograms, both in the time and in
               the frequency domain, were considered, and the results compared.
               The direct use of the time series of the shocks was not
               satisfactory. The auto-correlation function worked well, but in
               some cases it was misleading. A better performance was obtained
               with a frequency domain representation. Finally, the use of the
               envelope function did not work well. Combining parameters such
               as the auto-correlation and envelope functions can improve one
               source of error, but it may introduce new ones. The performance
               obtained highlights the importance of the data attributes used
               for the training of the network. Topologies with eight neurons
               in a single hidden layer gave, on average, the best results
               among the considered neural network structures. The overall
               results provide a large number of events (89\% with the best
               performance) correctly classified, indicating that this
               automatic technique is reliable, and encouraging further
               applications in the field of volcanic seismology.},
  journal   = {Nat. Hazards},
  publisher = {Springer},
  volume    =  13,
  number    =  3,
  pages     = {205--228},
  month     =  may,
  year      =  1996,
  url       = {https://doi.org/10.1007/BF00215816},
  issn      = {0921-030X, 1573-0840},
  doi       = {10.1007/BF00215816}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Falsaperla2013-uj,
  title     = {The failed eruption of Mt. Etna in December 2005: Evidence from
               volcanic tremor analyses},
  author    = {Falsaperla, S and Barberi, G and {others}},
  abstract  = {Strong changes in seismic radiation, comparable to those
               preceding and/or accompanying eruptive activity in recent years,
               were recorded at Mt. Etna volcano, Italy, from November 2005 to
               January 2006. The amplitude of volcanic tremor peaked in
               mid‐December 2005 after a continuous, slow increase from August
               2005 onward, during which neither effusive nor paroxysmal
               activity was observed by volcanologists and alpine guides.
               During this time span, the centroid locations of volcanic tremor
               moved toward the surface, more and more …},
  journal   = {Geochem. Geophys. Geosyst.},
  publisher = {Wiley Online Library},
  year      =  2013,
  url       = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1002/2013GC004976}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Esposito2006-xw,
  title     = {Automatic Discrimination among Landslide, {Explosion-Quake}, and
               Microtremor Seismic Signals at Stromboli Volcano Using Neural
               Networks},
  author    = {Esposito, A M and Giudicepietro, F and Scarpetta, S and D'Auria,
               L and Marinaro, M and Martini, M},
  abstract  = {In this article we report on the implementation of an automatic
               system for discriminating landslide seismic signals on Stromboli
               island (southern Italy). This is a critical point for monitoring
               the evolution of this volcanic island, where at the end of 2002
               a violent tsunami occurred, triggered by a big landslide. We
               have devised a supervised neural system to discriminate among
               landslide, explosion-quake, and volcanic microtremor signals. We
               first preprocess the data to obtain a compact representation of
               the seismic records. Both spectral …},
  journal   = {Bull. Seismol. Soc. Am.},
  publisher = {GeoScienceWorld},
  volume    =  96,
  number    = {4A},
  pages     = {1230--1240},
  month     =  aug,
  year      =  2006,
  url       = {https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/96/4A/1230/146685},
  issn      = {0037-1106},
  doi       = {10.1785/0120050097}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Emelyanova2017-vy,
  title     = {Unsupervised identification of electrofacies employing machine
               learning},
  author    = {Emelyanova, I and Pervukhina, M and Clennell, M and {others}},
  abstract  = {Machine learning techniques are widely used in petrophysicics
               and geophysics to solve complex and non-linear problems of
               practical importance. In particular, numerous applications for
               identifying electrofacies from well logs have been conducted.
               However, there is no unique approach for reliable automatic
               classification of electrofacies as the accuracy of the applied
               algorithms may vary depending on data and initial conditions. To
               overcome instability in outcomes from various algorithms, we
               suggest applying different …},
  journal   = {79th EAGE Conference},
  publisher = {earthdoc.org},
  year      =  2017,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=89274}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Dutkiewicz2015-mw,
  title     = {Census of seafloor sediments in the world's ocean},
  author    = {Dutkiewicz, Adriana and Dietmar M{\"u}ller, R and O'Callaghan,
               Simon and J{\'o}nasson, Hj{\"o}rtur},
  abstract  = {Knowing the patterns of distribution of sediments in the global
               ocean is critical for understanding biogeochemical cycles and
               how deep-sea deposits respond to environmental change at the sea
               surface. We present the first digital map of seafloor
               lithologies based on descriptions of nearly 14,500 samples from
               original cruise reports, interpolated using a support vector
               machine algorithm. We show that sediment distribution is more
               complex, with significant deviations from earlier hand-drawn
               maps, and that major …},
  journal   = {Geology},
  publisher = {GeoScienceWorld},
  volume    =  43,
  number    =  9,
  pages     = {795--798},
  month     =  sep,
  year      =  2015,
  url       = {https://pubs.geoscienceworld.org/gsa/geology/article-abstract/43/9/795/131939},
  issn      = {0091-7613},
  doi       = {10.1130/G36883.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Draelos2012-pz,
  title     = {False Event Screening Using Data Mining in Historical Archives},
  author    = {Draelos, Timothy J and Procopio, Michael J and Lewis, Jennifer E
               and Young, Christopher J},
  abstract  = {Analysts working at the International Data Centre (IDC) in
               support of treaty monitoring through the Comprehensive
               Nuclear-Test-Ban Treaty Organization (CTBTO) spend a significant
               amount of time reviewing hypothesized seismic events produced by
               an automatic processing system to ensure a highquality event
               bulletin, which is then made available to the member states of
               the CTBT. Such a system is characterized as forming signal
               detections from the waveforms recorded at the International
               Monitoring System (IMS) stations …},
  journal   = {Seismol. Res. Lett.},
  publisher = {GeoScienceWorld},
  volume    =  83,
  number    =  2,
  pages     = {267--274},
  month     =  mar,
  year      =  2012,
  url       = {https://pubs.geoscienceworld.org/ssa/srl/article-abstract/83/2/267/143932},
  issn      = {0895-0695},
  doi       = {10.1785/gssrl.83.2.267}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Draelos2015-yh,
  title     = {A new method for producing automated seismic bulletins:
               Probabilistic event detection, association, and location},
  author    = {Draelos, T J and Ballard, S and Young, C J and {others}},
  abstract  = {Given a set of observations within a specified time window, a
               fitness value is calculated at each grid node by summing
               station‐specific conditional fitness values. Assuming each
               observation was generated by a refracted P wave, these values
               are proportional to the conditional probabilities that each
               observation was generated by a seismic event at the grid node.
               The node with highest fitness value is accepted as a
               hypothetical event location, subject to some minimal fitness
               value, and all arrivals within a longer time window consistent …},
  journal   = {Bulletin of the},
  publisher = {pubs.geoscienceworld.org},
  year      =  2015,
  url       = {https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/105/5/2453/331946}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Dowla1990-rd,
  title     = {Seismic discrimination with artificial neural networks:
               Preliminary results with regional spectral data},
  author    = {Dowla, Farid U and Taylor, Steven R and Anderson, Russell W},
  abstract  = {An application of artificial neural networks (ANN) for
               discrimination between natural earthquakes and underground
               nuclear explosions has been studied using distance corrected
               spectral data of regional seismic phases. Pn, Pg, and Lg spectra
               have been analyzed from 83 western US earthquakes and 87 Nevada
               Test Site explosions recorded at the four broadband seismic
               stations operated by Lawrence Livermore National Laboratory.
               Distance corrections are applied to the raw spectra using
               existing frequency-dependent Q …},
  journal   = {Bull. Seismol. Soc. Am.},
  publisher = {GeoScienceWorld},
  volume    =  80,
  number    =  5,
  pages     = {1346--1373},
  month     =  oct,
  year      =  1990,
  url       = {https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/80/5/1346/119382},
  issn      = {0037-1106}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Dodge2016-ah,
  title     = {Large‐scale test of dynamic correlation processors: Implications
               for correlation‐based seismic pipelines},
  author    = {Dodge, D A and Harris, D B},
  abstract  = {Correlation detectors are of considerable interest to seismic
               monitoring communities because they offer reduced detection
               thresholds and combine detection, location, and identification
               functions into a single operation. They appear to be ideal for
               applications requiring screening of frequent repeating events.
               But questions remain about how broadly empirical correlation
               methods are applicable. We describe the effectiveness of banks
               of correlation detectors in a system that combines traditional
               power detectors with correlation …},
  journal   = {Bull. Seismol. Soc. Am.},
  publisher = {pubs.geoscienceworld.org},
  year      =  2016,
  url       = {https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/106/2/435/332173}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Dodge2015-eu,
  title     = {Initial global seismic cross‐correlation results: Implications
               for empirical signal detectors},
  author    = {Dodge, D A and Walter, W R},
  abstract  = {In this work, we cross‐correlated waveforms in a global dataset
               consisting of over 310 million waveforms from nearly 3.8 million
               events recorded between 1970 and 2013 for two purposes: to
               better understand the nature of global seismicity and to
               evaluate correlation as a technique for automated event
               processing. We found that about 14.5\% of the events for which
               we have at least one waveform correlated with at least one other
               event at the 0.6 or higher level. Within the geographic regions
               where our waveform holdings are complete or …},
  journal   = {Bull. Seismol. Soc. Am.},
  publisher = {pubs.geoscienceworld.org},
  year      =  2015,
  url       = {https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/105/1/240/323489}
}

@INCOLLECTION{Di2017-ox,
  title     = {Seismic-fault detection based on multiattribute support vector
               machine analysis},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2017},
  author    = {Di, H and Shafiq, M and AlRegib, G},
  abstract  = {Reliable fault detection is one of the major tasks of subsurface
               interpretation and reservoir characterization from
               three-dimensional (3D) seismic surveying. This study presents an
               innovative workflow based on multi-attribute support vector
               machine (SVM) analysis of a seismic volume, which consists of
               four steps. First, three groups of seismic attributes are
               selected and computed from the volume of seismic amplitude,
               including edge-detection, geometric, and texture, all of which
               clearly highlight the seismic faults in the attribute images.
               Second, two sets of training samples are prepared by manually
               picking on the faults and the nonfaulting zones, respectively.
               Third, the SVM analysis is performed on the training datasets
               that builds an optimal classification model for volumetric
               processing. Finally, applying the SVM model to the whole seismic
               survey leads to a binary volume, in which the presence of a
               fault is labelled as ones. The added values of the proposed
               method are verified through applications to the seismic dataset
               over the Great South Basin in New Zealand, where the dominant
               features are polygonal faults of varying sizes and orientations.
               The results demonstrate not only good match between the detected
               faults and the original seismic images, but also great potential
               for quantitative fault interpretation, such as
               semi-automatic/automatic fault extraction, to aid structural
               framework modeling and reservoir simulation in the exploration
               areas of numerous faults and fractures Presentation Date:
               Wednesday, September 27, 2017 Start Time: 8:30 AM Location: 350D
               Presentation Type: ORAL},
  publisher = {Society of Exploration Geophysicists},
  pages     = {2039--2044},
  series    = {SEG Technical Program Expanded Abstracts},
  month     =  aug,
  year      =  2017,
  url       = {https://doi.org/10.1190/segam2017-17748277.1},
  doi       = {10.1190/segam2017-17748277.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Di2018-dz,
  title     = {Deep convolutional neural networks for seismic salt-body
               delineation},
  author    = {Di, H and Wang, Z and AlRegib, G},
  abstract  = {Salt-bodies are important subsurface structures with significant
               implications for hydrocarbon accumulation and sealing in
               offshore petroleum reservoirs, and accurate salt-body imaging
               and delineation is now greatly facilitated with the availability
               of 3D seismic surveying. However, considering the growing of
               seismic data size, the efficiency of interpreting a salt- body
               increasingly relies on the development of powerful computational
               interpretation tools that are capable of mimicking an
               experienced interpreter's intelligence. In recent years, with …},
  journal   = {AAPG Annual Convention and},
  publisher = {searchanddiscovery.com},
  year      =  2018,
  url       = {http://www.searchanddiscovery.com/documents/2018/70360di/ndx_di.pdf}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Di2017-qn,
  title     = {Multi-attribute k-means cluster analysis for salt boundary
               detection},
  author    = {Di, H and Shafiq, M and AlRegib, G},
  abstract  = {Robust detection of salt bodies has been the recent focus of
               hydrocarbon exploration and production from 3D seismic surveying
               in the last decade. This study presents a new salt- boundary
               detection method based on multi-attribute k-means cluster
               analysis, which consists of two major components. First, a suite
               of seismic attributes is selected and computed from the seismic
               volume, from which the salt boundaries can be readily
               differentiated from the surrounding non-boundary features in
               various ways. Second, the k …},
  journal   = {79th EAGE Conference and Exhibition},
  publisher = {earthdoc.org},
  year      =  2017,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=88632}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{DeVries2017-or,
  title     = {Enabling large‐scale viscoelastic calculations via neural
               network acceleration},
  author    = {DeVries, P M R and Thompson, T B and {others}},
  abstract  = {One of the most significant challenges involved in efforts to
               understand the effects of repeated earthquake cycle activity is
               the computational costs of large‐scale viscoelastic earthquake
               cycle models. Computationally intensive viscoelastic codes must
               be evaluated at thousands of times and locations, and as a
               result, studies tend to adopt a few fixed rheological structures
               and model geometries and examine the predicted time‐dependent
               deformation over short (< 10 years) time periods at a given
               depth after a large earthquake …},
  journal   = {Geophys. Res. Lett.},
  publisher = {Wiley Online Library},
  year      =  2017,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/2017GL072716},
  issn      = {0094-8276}
}

@article{devries2018deep,
  title={Deep learning of aftershock patterns following large earthquakes},
  author={DeVries, Phoebe MR and Vi{\'e}gas, Fernanda and Wattenberg, Martin and Meade, Brendan J},
  journal={Nature},
  volume={560},
  number={7720},
  pages={632},
  year={2018},
  publisher={Nature Publishing Group}
}

@inproceedings{mignan2019deeper,
  title={A Deeper Look into ‘Deep Learning of Aftershock Patterns Following Large Earthquakes’: Illustrating First Principles in Neural Network Physical Interpretability},
  author={Mignan, Arnaud and Broccardo, Marco},
  booktitle={International Work-Conference on Artificial Neural Networks},
  pages={3--14},
  year={2019},
  organization={Springer}
}

@article{mignan2019one,
  title={One neuron versus deep learning in aftershock prediction},
  author={Mignan, Arnaud and Broccardo, Marco},
  journal={Nature},
  volume={574},
  number={7776},
  pages={E1--E3},
  year={2019},
  publisher={NATURE PUBLISHING GROUP}
}

@ARTICLE{Devilee1999-mr,
  title     = {An efficient, probabilistic neural network approach to solving
               inverse problems: Inverting surface wave velocities for Eurasian
               crustal thickness},
  author    = {Devilee, R J R and Curtis, A and Roy-Chowdhury, K},
  abstract  = {Nonlinear inverse problems usually have no analytical solution
               and may be solved by Monte Carlo methods that create a set of
               samples, representative of the a posteriori distribution. We
               show how neural networks can be trained on these samples to give
               a continuous approximation to the inverse relation in a compact
               and computationally efficient form. We examine the strengths and
               weaknesses of this approach and use it to determine the full a
               posteriori distribution of crustal thickness from surface wave
               velocities. The solution to this inverse problem shows
               significant asymmetry and large uncertainties due to trade-off
               with shear velocity structure around the Moho. We produce maps
               of maximum likelihood crustal thickness across Eurasia which are
               in agreement with current knowledge about the crust; thus we
               provide an independent confirmation of these models. In this
               application, characterized by repeated inversion of similar
               data, the neural network algorithm proves to be very efficient.},
  journal   = {J. Geophys. Res.},
  publisher = {Wiley Online Library},
  volume    =  104,
  number    = {B12},
  pages     = {28841--28857},
  month     =  dec,
  year      =  1999,
  url       = {http://doi.wiley.com/10.1029/1999JB900273},
  issn      = {0148-0227},
  doi       = {10.1029/1999JB900273}
}

@ARTICLE{Dammeier2016-mf,
  title     = {Automatic detection of alpine rockslides in continuous seismic
               data using hidden Markov models},
  author    = {Dammeier, Franziska and Moore, Jeffrey R and Hammer, Conny and
               Haslinger, Florian and Loew, Simon},
  abstract  = {Abstract Data from continuously recording permanent seismic
               networks can contain information about rockslide occurrence and
               timing complementary to eyewitness observations and thus aid in
               construction of robust event catalogs. However, detecting
               infrequent rockslide signals within large volumes of continuous
               seismic waveform data remains challenging and often requires
               demanding manual intervention. We adapted an automatic
               classification method using hidden Markov models to detect
               rockslide signals in seismic data from two stations in central
               Switzerland. We first processed 21 known rockslides, with event
               volumes spanning 3 orders of magnitude and station event
               distances varying by 1 order of magnitude, which resulted in 13
               and 19 successfully classified events at the two stations.
               Retraining the models to incorporate seismic noise from the day
               of the event improved the respective results to 16 and 19
               successful classifications. The missed events generally had low
               signal-to-noise ratio and small to medium volumes. We then
               processed nearly 14?years of continuous seismic data from the
               same two stations to detect previously unknown events. After
               postprocessing, we classified 30 new events as rockslides, of
               which we could verify three through independent observation. In
               particular, the largest new event, with estimated volume of
               500,000?m3, was not generally known within the Swiss landslide
               community, highlighting the importance of regional seismic data
               analysis even in densely populated mountainous regions. Our
               method can be easily implemented as part of existing earthquake
               monitoring systems, and with an average event detection rate of
               about two per month, manual verification would not significantly
               increase operational workload.},
  journal   = {J. Geophys. Res. Earth Surf.},
  publisher = {Wiley Online Library},
  volume    =  121,
  number    =  2,
  pages     = {351--371},
  series    = {of the Ser. Lect. Notes in Comput. Sci},
  month     =  feb,
  year      =  2016,
  url       = {http://doi.wiley.com/10.1002/2015JF003647},
  issn      = {2169-9003},
  doi       = {10.1002/2015JF003647}
}

@ARTICLE{Dai1997-tu,
  title     = {Application of back-propagation neural networks to
               identification of seismic arrival types},
  author    = {Dai, Hengchang and MacBeth, Colin},
  abstract  = {A back-propagation neural network (BPNN) approach is developed
               to identify P- and S-arrivals from three-component recordings of
               local earthquake data. The BPNN is trained by selecting trace
               segments of P- and S-waves and noise bursts converted into an
               attribute space based on the degree of polarization (DOP). After
               training, the network can automatically identify the type of
               arrival on earthquake recordings. Compared with manual analysis,
               a BPNN trained with nine groups of DOP segments can correctly
               identify 82.3\% of the P-arrivals and 62.6\% of the S-arrivals
               from one seismic station, and when trained with five groups from
               a training dataset selected from another seismic station, it can
               correctly identify 76.6\% of the P-arrivals and 60.5\% of
               S-arrivals. This approach is adaptive and needs only the onset
               time of arrivals as input, although its performance cannot be
               improved by simply adding more training datasets due to the
               complexity of DOP patterns. Our experience suggests that other
               information or another network may be necessary to improve its
               performance.},
  journal   = {Phys. Earth Planet. Inter.},
  publisher = {Elsevier},
  volume    =  101,
  number    =  3,
  pages     = {177--188},
  month     =  may,
  year      =  1997,
  url       = {http://www.sciencedirect.com/science/article/pii/S0031920197000046},
  issn      = {0031-9201},
  doi       = {10.1016/S0031-9201(97)00004-6}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Dai1997-ta,
  title     = {The application of back‐propagation neural network to automatic
               picking seismic arrivals from single‐component recordings},
  author    = {Dai, H and MacBeth, C},
  abstract  = {An automatic approach is developed to pick P and S arrivals from
               single component (1-C) recordings of local earthquake data. In
               this approach a back propagation neural network (BPNN) accepts a
               normalized segment (window of 40 samples) of absolute amplitudes
               from the 1-C recordings as its input pattern, calculating two
               output values between 0 and 1. The outputs (0, 1) or (1, 0)
               correspond to the presence of an arrival or background noise
               within a moving window. The two outputs form a time series. The
               P and S arrivals are then retrieved …},
  journal   = {J. Geophys. Res. [Solid Earth]},
  publisher = {Wiley Online Library},
  year      =  1997,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1029/97JB00625}
}

@ARTICLE{Dai1995-ke,
  title     = {Automatic picking of seismic arrivals in local earthquake data
               using an artificial neural network},
  author    = {Dai, Hengchang and MacBeth, Colin},
  abstract  = {A preliminary study is performed to test the ability of an
               artificial neural network (ANN) to detect and pick seismic
               arrivals from local earthquake data. This is achieved using
               three-component recordings by utilizing the vector modulus of
               these seismic records as the network input. A discriminant
               function, F(t), determined from the output of the trained ANN,
               is then employed to define the arrival onset. 877 pre-triggered
               recordings from two stations in a local earthquake network are
               analysed by an ANN trained with only nine P waves and nine noise
               segments. The data have a range of magnitudes (ML) from -0.3 to
               1.0, and signal-to-noise ratios from 1 to 200. Comparing the
               results with manual picks, the ANN can accurately detect 93.9
               per cent of the P waves and also 90.3 per cent of the S waves
               with a F(t) threshold set at 0.6 (maximum is 1.0). These
               statistics do not include false alarms due to other non-seismic
               signals or unusable records due to excessive noise. In 17.2 per
               cent of the cases the ANN detected false alarms prior to the
               event. Determining the onset times by using the local maximum of
               F(t), we find that 75.4 per cent of the P-wave estimates and
               66.7 per cent of the S-wave estimates are within one sample
               increment (10 ms) of the reference data picked manually. Only
               7.7 per cent of the P-wave estimates and 11.8 per cent of the
               S-wave estimates are inaccurate by more than five sample
               increments (50 ms). The majority of these records have distinct
               local P and S waves. The ANN also works for seismograms with low
               signal-to-noise ratios, where visual examination is difficult.
               The examples show the adaptive nature of the ANN, and that its
               ability to pick may be improved by adding or adjusting the
               training data. The ANN has potential as a tool to pick arrivals
               automatically. This algorithm has been adopted as a component in
               the early stages of our development of an automated subsystem to
               analyse local earthquake data. Further potential applications
               for the neural network include editing of poor traces (before
               present algorithm) and rejection of false alarms (after this
               present algorithm).},
  journal   = {Geophys. J. Int.},
  publisher = {Oxford University Press},
  volume    =  120,
  number    =  3,
  pages     = {758--774},
  month     =  mar,
  year      =  1995,
  url       = {https://academic.oup.com/gji/article-abstract/120/3/758/779585},
  issn      = {0956-540X},
  doi       = {10.1111/j.1365-246X.1995.tb01851.x}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Dai1994-ez,
  title     = {Split shear-wave analysis using an artificial neural network},
  author    = {Dai, H and MacBeth, C},
  abstract  = {Artificial neural networks (ANNs) are simple models that attempt
               to simulate the operation of neurons in the brain. Although ANNs
               are relatively new in seismology, their origins can be traced
               back to the 1940s when psychologists began developing models of
               human learning. One of the most exciting developments in ANNs
               was the advent of the Perceptron, the idea that a network of
               elemental processors arrayed in a marmer reminiscent of
               biological neural networks might be able to learn how to
               recognize and classify patterns in an autonomous …},
  journal   = {First Break},
  publisher = {earthdoc.org},
  year      =  1994,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=28365},
  issn      = {0263-5046}
}

@ARTICLE{Dai1994-fs,
  title     = {A Neural network picker for {VSP} data},
  author    = {Dai, H and MacBeth, C},
  abstract  = {Artificial neural networks (ANN) are presented as a way of
               automatically picking shear-wave arrival onset times in VSP
               data. Picking is achieved by utilizing the relative vector
               modulus of two horizontal component recordings as the neural
               network input. A discriminant function, F (t), determined by the
               output of the trained ANN, is then employed to pick the arrival
               onset. The results demonstrate this neural network architecture
               is successful after training by a few selected datasets.},
  journal   = {56th EAEG Meeting},
  publisher = {earthdoc.org},
  year      =  1994,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=12499}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cui2010-rn,
  title     = {Automatic feature recognition for {GPR} image processing},
  author    = {Cui, Yi-An and Wang, Lu and Xiao, Jian-Ping},
  abstract  = {This paper presents an automatic feature recognition method
               based on center-surround difference detecting and fuzzy logic
               that can be applied in ground-penetrating radar (GPR) image
               processing. Adopted center-surround difference method, the
               salient local image regions are extracted from the GPR images as
               features of detected objects. And fuzzy logic strategy is used
               to match the detected features and features in template
               database. This way, the problem of objects detecting, which is
               the key problem in GPR image processing, can be …},
  journal   = {Proc. World Acad. of Sci. Eng. Technol.},
  publisher = {pdfs.semanticscholar.org},
  volume    =  61,
  pages     = {176--179},
  year      =  2010,
  url       = {https://pdfs.semanticscholar.org/edd6/3447f33c032fe26dfb970e92f6194e98df97.pdf},
  issn      = {1307-6884}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Chen2017-wg,
  title     = {Application of one-class support vector machine to quickly
               identify multivariate anomalies from geochemical exploration
               data},
  author    = {Chen, Yongliang and Wu, Wei},
  abstract  = {Identifying multivariate anomalies from geochemical exploration
               data in a complex geological setting is very challenging because
               the complex geological setting may lead to an unknown
               high-dimensional distribution of the geochemical exploration
               data. One-class support vector machine (OCSVM) can give useful
               results in outlier detection in high- dimension or without any
               assumptions on the distribution of data. Thus, we applied the
               OCSVM model to identify multivariate geochemical anomalies from
               stream sediment survey …},
  journal   = {Geochem. Explor. Environ. Analy.},
  publisher = {GeoScienceWorld},
  volume    =  17,
  number    =  3,
  pages     = {231--238},
  month     =  aug,
  year      =  2017,
  url       = {https://pubs.geoscienceworld.org/geea/article-abstract/17/3/231/519385},
  issn      = {1467-7873},
  doi       = {10.1144/geochem2016-024}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Chevitarese2018-kd,
  title     = {Seismic facies segmentation using deep learning},
  booktitle = {{ACE} 2018 Annual Convention \& Exhibition},
  author    = {Chevitarese, Daniel and Szwarcman, Daniela and Silva, Reinaldo
               Mozart D and Brazil, Emilio Vital},
  abstract  = {Seismic reflection surveying is the most used method to obtain
               subsurface information in the Oil \& Gas exploration industry.
               with this data, one may determine structural and stratigraphic
               geometric features and potential hydrocarbon deposit locations.
               Even though it is paramount, seismic data interpretation is an
               extremely time-consuming and human- intensive task, mainly due
               to the ever-larger volumes of seismic data and the geological
               complexity present in the study areas. In response, computer-aid
               systems assisting …},
  publisher = {searchanddiscovery.com},
  year      =  2018,
  url       = {http://www.searchanddiscovery.com/documents/2018/42286chevitarese/ndx_chevitarese.pdf}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Chen2012-ws,
  title     = {Geological risk evaluation using the Support Vector Machine with
               examples from the late Triassic--early Jurassic structural play
               in western Sverdrup Basin, Canadian Arctic Archipelago},
  author    = {Chen, Zhuoheng and Liu, Yexin and Osadetz, Kirk},
  abstract  = {A meaningful exploration decision depends not only on a reliable
               estimate of resource potential, but also on a robust geological
               risk evaluation of the exploration targets. We propose a Support
               Vector Machine approach for geological risk evaluation of
               petroleum occurrence in a petroleum play. The resulting risk map
               can be used to highlight the geographic locations of potential
               undiscovered petroleum resources and help visualize regional
               exploration risk. Treating risk evaluation as a two-category
               classification with …},
  journal   = {Bull. Can. Petrol. Geol.},
  publisher = {Canadian Society of Petroleum Geologists},
  volume    =  60,
  number    =  3,
  pages     = {142--157},
  year      =  2012,
  url       = {https://pubs.geoscienceworld.org/cspg/bcpg/article-abstract/60/3/142/266453}
}

@ARTICLE{Chen2015-ih,
  title     = {Mineral potential mapping with a restricted Boltzmann machine},
  author    = {Chen, Yongliang},
  abstract  = {A restricted Boltzmann machine can be trained to encode and
               reconstruct training samples from a training sample population
               with an unknown complex probability distribution. Small
               probability samples can be differentiated from the training
               sample population due to their comparatively larger encoded and
               reconstructed errors. In mineral potential mapping, mineral
               potential areas usually take up only a small proportion of the
               whole mineral exploration region and have specific evidence map
               patterns. Assume that the whole mineral exploration region is
               divided into uniform cells and a restricted Boltzmann machine is
               then trained on all the cells. As a small proportion of the
               total training cells, mineral potential cells have much larger
               encoded and reconstructed errors compared to non-mineral
               potential cells. Based on the encoded and reconstructed errors
               of the training cells, ASC and ASE are thus defined as two
               mineral potential indicators for mineral potential mapping with
               the trained restricted Boltzmann machine. The Altay district in
               northern Xinjiang in China, which is linked with a complex
               geological setting, is chosen as a case study area. Restricted
               Boltzmann machines with 12 visible units and differing hidden
               units are constructed and trained on 9582 training cells in the
               study area. The ASC, ASE, posterior probability, and
               deposit-bearing probability are used to predict the mineral
               potential of each grid cell in the study area. The AUC (area
               under the curve), a measure of aggregated classification
               performance in machine learning, is applied to measure the
               mineral potential mapping performance of these four mineral
               potential indicators. The results show that the four mineral
               potential indicators perform similarly well. Therefore, a
               restricted Boltzmann machine can be trained to map mineral
               potentials, and the ASC and ASE are two feasible indicators for
               the mineral potential mapping with the trained restricted
               Boltzmann machine.},
  journal   = {Ore Geol. Rev.},
  publisher = {Elsevier},
  volume    =  71,
  pages     = {749--760},
  month     =  dec,
  year      =  2015,
  url       = {http://www.sciencedirect.com/science/article/pii/S0169136814002029},
  keywords  = {Restricted Boltzmann machine; Weights of evidence model;
               Logistic regression; Mineral potential mapping; Mineral
               potential indicator; Evidence map pattern},
  issn      = {0169-1368},
  doi       = {10.1016/j.oregeorev.2014.08.012}
}

@ARTICLE{Chen2014-zv,
  title     = {Application of continuous restricted Boltzmann machine to
               identify multivariate geochemical anomaly},
  author    = {Chen, Yongliang and Lu, Laijun and Li, Xuebin},
  abstract  = {In multivariate geochemical anomaly identification, geochemical
               background sample population is usually supposed to satisfy a
               known multivariate probability distribution, such as
               multivariate Gaussian distribution, so that a simple predefined
               function can describe the general features of the multivariate
               geochemical background. However, complex geological settings
               often result in an unknown complex multivariate probability
               distribution of the geochemical background sample population. In
               this case, the predefined simple function can't effectively
               describe the characteristics of the complex multivariate
               geochemical background. Continuous restricted Boltzmann machine
               can be trained to encode and reconstruct statistical samples
               from an unknown complex multivariate probability distribution.
               Large probability samples can be encoded and reconstructed
               better than small ones. Therefore, the trained continuous
               restricted Boltzmann machine can differentiate the small
               probability samples from the training sample population. In
               geochemical exploration, the overwhelming majority of
               geochemical samples are the background samples from the
               geochemical background sample population. Comparing with the
               background samples, geochemical anomaly samples are the small
               probability samples that can be identified by the trained
               continuous restricted Boltzmann machine from the training
               geochemical sample population. Two anomaly indicators, ASC and
               ASE, are defined on the basis of the trained continuous
               restricted Boltzmann machine for the multivariate geochemical
               anomaly identification. The Baishan district in northeastern
               China linked with a complex geological background is chosen as a
               case study area. Continuous restricted Boltzmann machines with
               14 visible units and differing hidden units are constructed and
               trained on all the 6607 geochemical samples in the study area.
               The ASCs and ASEs are used to identify the multivariate
               geochemical anomaly samples from the training geochemical sample
               population. Likelihood ratio is used to test the performance of
               these two types of anomaly indicators. The results show that ASC
               and ASE have similar good performance in the multivariate
               geochemical anomaly identification. The identified multivariate
               geochemical anomalies are spatially consistent with the known
               mineral deposits and extend along the direction of the regional
               tectonics in the study area.},
  journal   = {J. Geochem. Explor.},
  publisher = {Elsevier},
  volume    =  140,
  pages     = {56--63},
  month     =  may,
  year      =  2014,
  url       = {http://www.sciencedirect.com/science/article/pii/S0375674214000764},
  keywords  = {Continuous restricted Boltzmann machine; Multivariate
               geochemical data; Geochemical background; Geochemical anomaly;
               Geochemical exploration},
  issn      = {0375-6742},
  doi       = {10.1016/j.gexplo.2014.02.013}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Chang2005-jl,
  title     = {Fuzzy exemplar-based inference system for flood forecasting},
  author    = {Chang, Li-Chiu and Chang, Fi-John and Tsai, Ya-Hsin},
  abstract  = {Fuzzy inference systems have been successfully applied in
               numerous fields since they can effectively model human knowledge
               and adaptively make decision processes. In this paper we present
               an innovative fuzzy exemplar-based inference system (FEIS) for
               flood forecasting. The FEIS is based on a fuzzy inference
               system, with its clustering ability enhanced through the
               Exemplar-Aided Constructor of Hyper-rectangles algorithm, which
               can effectively simulate human intelligence by learning from
               experience. The FEIS exhibits …},
  journal   = {Water Resour. Res.},
  publisher = {Wiley Online Library},
  volume    =  41,
  number    =  2,
  year      =  2005,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2004WR003037},
  issn      = {0043-1397}
}

@ARTICLE{Chaki2018-mr,
  title     = {{Well-Log} and Seismic Data Integration for Reservoir
               Characterization: A Signal Processing and {Machine-Learning}
               Perspective},
  author    = {Chaki, S and Routray, A and Mohanty, W K},
  abstract  = {Reservoir characterization (RC) is a process of finding
               petrophysical properties of the subsurface mainly from the
               seismic and well-log data. The nonlinear and heterogeneous
               nature of the subsurface is the major bottleneck in estimating
               the reservoir properties. In the past two decades, the RC has
               eventually turned out to be an interdisciplinary field of
               research involving computational science, signal processing,
               geostatistics, and geophysics. This article provides the
               interdisciplinary perspective in RC focusing on the applications
               of signal processing and machine learning (ML). We provide an
               account of various state-of-the-art algorithms while
               categorizing them into three stages in an RC framework:
               preprocessing, prediction, and postprocessing. RC has been known
               to be a highly data-driven problem. Huge volumes of seismic and
               well-log data are cleverly integrated by experts to decipher the
               subsurface properties. Some of the anomalies may lead to the
               existence of a potential reservoir. The signal processing tools
               are primarily required for information matching, preprocessing
               for noise and artifacts, and postprocessing for removing
               irregularities in the prediction, whereas the ML tools are
               required to map the seismic data to well logs. This article
               provides a comprehensive study on the recent advances in RC
               involving seismic volumes and well logs.},
  journal   = {IEEE Signal Process. Mag.},
  publisher = {ieeexplore.ieee.org},
  volume    =  35,
  number    =  2,
  pages     = {72--81},
  month     =  mar,
  year      =  2018,
  url       = {http://dx.doi.org/10.1109/MSP.2017.2776602},
  keywords  = {data integration;geophysical signal processing;hydrocarbon
               reservoirs;learning (artificial intelligence);seismology;well
               logging;seismic data integration;reservoir
               characterization;machine-learning perspective;petrophysical
               properties;seismic log data;well-log data;nonlinear
               nature;heterogeneous nature;reservoir
               properties;interdisciplinary perspective;RC framework;highly
               data-driven problem;subsurface properties;potential
               reservoir;signal processing tools;map the seismic data;seismic
               volumes;information matching;Prediction algorithms;Signal
               processing algorithms;Feature extraction;Artificial neural
               networks;Signal resolution;Reservoirs},
  issn      = {1053-5888},
  doi       = {10.1109/MSP.2017.2776602}
}


@ARTICLE{Cate2017-na,
  title     = {Machine learning as a tool for geologists},
  author    = {Cat{\'e}, A and Perozzi, L and Gloaguen, E and Blouin, M},
  abstract  = {Machine learning is becoming an appealing tool in various fields
               of earth sciences, especially in resources estimation. Six
               machine learning algorithms have been used to predict the
               presence of gold mineralization in drill core from geophysical
               logs acquired at the Lalor deposit, Manitoba, Canada. Results
               show that the integration of a set of rock physical properties ?
               measured at closely spaced intervals along the drill core ? with
               ensemble machine learning algorithms allows the detection of
               gold-bearing intervals with an adequate rate of success. Since
               the resulting prediction is continuous along the drill core, the
               use of this type of tool in the future will help geologists in
               selecting sound intervals for assay sampling and in modeling
               more continuous ore bodies during the entire life of a mine.},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  36,
  number    =  3,
  pages     = {215--219},
  month     =  mar,
  year      =  2017,
  url       = {https://doi.org/10.1190/tle36030215.1},
  issn      = {1070-485X},
  doi       = {10.1190/tle36030215.1}
}



% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cate2018-mb,
  title     = {Classification of lithostratigraphic and alteration units from
               drillhole lithogeochemical data using machine learning: A case
               study from the Lalor volcanogenic massive sulphide deposit, Snow
               Lake, Manitoba, Canada},
  author    = {Cat{\'e}, Antoine and Schetselaar, Ernst and Mercier-Langevin,
               Patrick and Ross, Pierre-Simon},
  abstract  = {Classification of rock types using geochemical variables is
               widely used in geosciences, but most standard classification
               methods are restricted to the simultaneous use of two or three
               variables at a time. Machine learning-based methods allow for a
               multivariate approach to classification problems, potentially
               increasing classification success rates. Here a series of
               multivariate machine learning classification algorithms,
               together with different sets of lithogeochemistry-derived
               variables, are tested on samples collected at the Lalor Zn-Cu-Au
               …},
  journal   = {J. Geochem. Explor.},
  publisher = {Elsevier},
  volume    =  188,
  pages     = {216--228},
  year      =  2018,
  url       = {https://www.sciencedirect.com/science/article/pii/S0375674217305083},
  issn      = {0375-6742}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Castellaro2007-mp,
  title     = {Classification of pre-eruption and non-pre-eruption epochs at
               Mount Etna volcano by means of artificial neural networks},
  author    = {Castellaro, Silvia and Mulargia, Francesco},
  abstract  = {We apply artificial neural networks to the classification of
               pre-eruption time epochs of Mount Etna volcano on the basis of
               variables depending on tectonics and on the volcano 'recharging
               system'. We consider time-epochs from 7 to 30 days and train the
               supervised nets, with the aim of recognizing the time epochs
               preceding summit eruptions, lateral eruptions and not preceding
               any eruption. Tested on a number of independent data sets, these
               patterns are found to be efficient (75$\pm$10\% success) in
               recognizing pre-summit …},
  journal   = {Geophys. Res. Lett.},
  publisher = {Wiley Online Library},
  volume    =  34,
  number    =  10,
  year      =  2007,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2007GL029513},
  issn      = {0094-8276}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Carreira2018-bp,
  title     = {A Comparison of Machine Learning Processes for Classification of
               Rock Units Using Well Log Data},
  booktitle = {80th {EAGE} Conference and Exhibition 2018},
  author    = {Carreira, V and Neto, C Ponte and Bijani, R},
  abstract  = {This work aims to define a comparison between a Kohonen SOM, an
               euclidean and a mahalanobean classificators. This comparison
               uses two well log data from a synthetic syneclises sedimentary
               basin type. It is remarkable that the Mahalanobis classifier
               produced a higher error when compared to the Euclidean
               classifier and the SOM. The SOM presented better results for the
               two synthetic examples, with an error of 0.7\% for the first
               well and 1.5\% for the second. In contrast, Mahalanobis and
               Euclidean classifiers presented an error of …},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=92908}
}

@ARTICLE{Carranza2015-jp,
  title     = {Data-driven predictive mapping of gold prospectivity, Baguio
               district, Philippines: Application of Random Forests algorithm},
  author    = {Carranza, Emmanuel John M and Laborte, Alice G},
  abstract  = {The Random Forests (RF) algorithm has recently become a
               fledgling method for data-driven predictive mapping of mineral
               prospectivity, and so it is instructive to further study its
               efficacy in this particular field. This study, carried out using
               Baguio gold district (Philippines), examines (a) the sensitivity
               of the RF algorithm to different sets of deposit and non-deposit
               locations as training data and (b) the performance of RF
               modeling compared to established methods for data-driven
               predictive mapping of mineral prospectivity. We found that RF
               modeling with different training sets of deposit/non-deposit
               locations is stable and reproducible, and it accurately captures
               the spatial relationships between the predictor variables and
               the training deposit/non-deposit locations. For data-driven
               predictive mapping of epithermal Au prospectivity in the Baguio
               district, we found that (a) the success-rates of RF modeling are
               superior to those of weights-of-evidence, evidential belief and
               logistic regression modeling and (b) the prediction-rate of RF
               modeling is superior to that of weights-of-evidence modeling but
               approximately equal to those of evidential belief and logistic
               regression modeling. Therefore, the RF algorithm is potentially
               much more useful than existing methods that are currently used
               for data-driven predictive mapping of mineral prospectivity.
               However, further testing of the method in other areas is needed
               to fully explore its usefulness in data-driven predictive
               mapping of mineral prospectivity.},
  journal   = {Ore Geol. Rev.},
  publisher = {Elsevier},
  volume    =  71,
  pages     = {777--787},
  month     =  dec,
  year      =  2015,
  url       = {http://www.sciencedirect.com/science/article/pii/S016913681400198X},
  keywords  = {Mineral prospectivity mapping; Ensemble of regression trees;
               Epithermal Au; Spatial correlation},
  issn      = {0169-1368},
  doi       = {10.1016/j.oregeorev.2014.08.010}
}

@ARTICLE{Cao2017-gp,
  title     = {Time-lapse reservoir property change estimation from seismic
               using machine learning},
  author    = {Cao, J and Roy, B},
  abstract  = {Time-lapse seismic analysis is an important tool in reservoir
               management, well planning, and reservoir model updating.
               Existing 4D close-the-loop methods utilize rock-physics models
               and simulation models, and typically work well in simple 4D
               cases such as water flood movement (where the primary change is
               the saturations), but they face challenges in reliably and
               quantitatively estimating 4D reservoir property changes when the
               reservoir dynamics are complex. We demonstrate a data-driven
               quantitative method that uses machine learning to leverage the
               inherent physics between time-lapse reservoir property changes
               and seismic attributes. The method can simultaneously utilize
               multiple seismic attributes, including attributes derived from
               prestack seismic, from multiple 4D seismic surveys. It
               significantly improves the efficiency and reduces the cycle time
               for quantitative 4D interpretation. We evaluate the method
               through a study based on synthetic data modeled after a complex
               North Sea reservoir with long production and injection history.
               For this reservoir, separation and estimation of the time-lapse
               pressure and saturation change are the critical objectives.
               Results show high prediction accuracy for all the reservoir
               properties including pressure, saturations, and compaction
               changes for the blind validation test. Estimated maps of all the
               reservoir property changes match very well with the simulation
               model in the synthetic study. This work also demonstrates that
               prestack seismic attributes significantly improved the
               estimation of 4D pressure and saturation changes.},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  36,
  number    =  3,
  pages     = {234--238},
  month     =  mar,
  year      =  2017,
  url       = {https://doi.org/10.1190/tle36030234.1},
  issn      = {1070-485X},
  doi       = {10.1190/tle36030234.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Canchumuni2017-ur,
  title       = {Integration of Ensemble Data Assimilation and Deep Learning
                 for History Matching Facies Models},
  booktitle   = {{OTC} Brasil},
  author      = {Canchumuni, Smith Arauco and Emerick, Alexandre A and Pacheco,
                 Marco Aurelio and {Others}},
  abstract    = {Ensemble data assimilation methods have been applied with
                 remarkable success in several real-life history-matching
                 problems. However, because these methods rely on Gaussian
                 assumptions, their performance is severely degraded when the
                 prior geology is described in terms of complex facies
                 distributions. This fact motivated an intense investigation
                 reported in the literature to develop efficient and robust
                 parameterizations. Despite the large number of publications,
                 preserving plausible geological features when updating facies
                 models is still …},
  publisher   = {onepetro.org},
  institution = {Offshore Technology Conference},
  year        =  2017,
  url         = {https://www.onepetro.org/conference-paper/OTC-28015-MS}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{CalderonMacias1997-pl,
  title     = {Hopfield neural networks, and mean field annealing for seismic
               deconvolution and multiple attenuation},
  author    = {Calder{\'o}n‐Mac{\'\i}as, C and Sen, M and Stoffa, P},
  abstract  = {We describe a global optimization method called mean field
               annealing (MFA) and its application to two basic problems in
               seismic data processing: Seismic deconvolution and surface
               related multiple attenuation. MFA replaces the stochastic nature
               of the simulated annealing method with a set of deterministic
               update rules that act on the average value of the variables
               rather than on the variables themselves, based on the mean field
               approximation. As the temperature is lowered, the MFA rules
               update the variables in terms of their values at a previous
               temperature. By minimizing averages, it is possible to converge
               to an equilibrium state considerably faster than a standard
               simulated annealing method. The update rules are dependent on
               the form of the cost function and are obtained easily when the
               cost function resembles the energy function of a Hopfield
               network. The mapping of a problem onto a Hopfield network is not
               a precondition for using MFA, but it makes analytic calculations
               simpler. The seismic deconvolution problem can be mapped onto a
               Hopfield network by parameterizing the source and the
               reflectivity in terms of binary neurons. In this context, the
               solution of the problem is obtained when the neurons of the
               network reach their stable states. By minimizing the cost
               function of the network with MFA and using an appropriate
               cooling schedule, it is possible to escape local minima. A
               similar idea can also be applied to design an operator that
               attenuates surface related multiple reflections from plane?wave
               transformed seismograms assuming a 1-D earth. The cost function
               for the multiple elimination problem is based on the criterion
               of minimum energy of the multiple suppressed data.},
  journal   = {Geophysics},
  publisher = {Society of Exploration Geophysicists},
  volume    =  62,
  number    =  3,
  pages     = {992--1002},
  month     =  may,
  year      =  1997,
  url       = {https://doi.org/10.1190/1.1444205},
  issn      = {0016-8033},
  doi       = {10.1190/1.1444205}
}

@INPROCEEDINGS{Cabrera2017-uj,
  title  = {Evaluation of boosting algorithms for prospectivity mapping},
  author = {Cabrera, Irving},
  month  =  sep,
  year   =  2017
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Butterworth2016-nk,
  title     = {Tectonic environments of South American porphyry copper
               magmatism through time revealed by spatiotemporal data mining},
  author    = {Butterworth, N and Steinberg, D and M{\"u}ller, R D and
               Williams, S and {others}},
  abstract  = {Porphyry ore deposits are known to be associated with arc
               magmatism on the overriding plate at subduction zones. While
               general mechanisms for driving magmatism are well established,
               specific subduction-related parameters linking episodes of ore
               deposit formation to specific tectonic environments have only
               been qualitatively inferred and have not been formally tested.
               We develop a four-dimensional approach to reconstruct age-dated
               ore deposits, with the aim of isolating the tectonomagmatic
               parameters leading to the …},
  publisher = {Wiley Online Library},
  year      =  2016,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/2016TC004289}
}

@ARTICLE{Bruyelle2014-sj,
  title     = {Neural networks and their derivatives for history matching and
               reservoir optimization problems},
  author    = {Bruyelle, J{\'e}r{\'e}mie and Gu{\'e}rillot, Dominique},
  abstract  = {In geosciences, complex forward problems met in geophysics,
               petroleum system analysis, and reservoir engineering problems
               often require replacing these forward problems by proxies, and
               these proxies are used for optimizations problems. For instance,
               history matching of observed field data requires a so large
               number of reservoir simulation runs (especially when using
               geostatistical geological models) that it is often impossible to
               use the full reservoir simulator. Therefore, several techniques
               have been proposed to mimic the reservoir simulations using
               proxies. Due to the use of experimental approach, most authors
               propose to use second-order polynomials. In this paper, we
               demonstrate that (1) neural networks can also be second-order
               polynomials. Therefore, the use of a neural network as a proxy
               is much more flexible and adaptable to the nonlinearity of the
               problem to be solved; (2) first-order and second-order
               derivatives of the neural network can be obtained providing
               gradients and Hessian for optimizers. For inverse problems met
               in seismic inversion, well by well production data, optimal well
               locations, source rock generation, etc., most of the time,
               gradient methods are used for finding an optimal solution. The
               paper will describe how to calculate these gradients from a
               neural network built as a proxy. When needed, the Hessian can
               also be obtained from the neural network approach. On a real
               case study, the ability of neural networks to reproduce complex
               phenomena (water cuts, production rates, etc.) is shown.
               Comparisons with second polynomials (and kriging methods) will
               be done demonstrating the superiority of the neural network
               approach as soon as nonlinearity behaviors are present in the
               responses of the simulator. The gradients and the Hessian of the
               neural network will be compared to those of the real response
               function.},
  journal   = {Computational Geosciences},
  publisher = {Springer},
  volume    =  18,
  number    =  3,
  pages     = {549--561},
  month     =  aug,
  year      =  2014,
  url       = {https://doi.org/10.1007/s10596-013-9390-y},
  issn      = {1573-1499},
  doi       = {10.1007/s10596-013-9390-y}
}

@ARTICLE{Braeuer2015-yj,
  title     = {A new interpretation of seismic tomography in the southern Dead
               Sea basin using neural network clustering techniques:
               {INTERPRETATION} {OF} {TOMOGRAPHY} {IN} {THE} {SDSB}},
  author    = {Braeuer, Benjamin and Bauer, Klaus},
  abstract  = {Abstract The Dead Sea is a prime location to study the structure
               and development of pull-apart basins. We analyzed tomographic
               models of Vp, Vs, and Vp/Vs using self-organizing map clustering
               techniques. The method allows us to identify major lithologies
               by their petrophysical signatures. Remapping the clusters into
               the subsurface reveals the distribution of basin sediments,
               prebasin sedimentary rocks, and crystalline basement. The Dead
               Sea basin shows an asymmetric structure with thickness variation
               from 5?km in the west to 13?km in the east. Most importantly, we
               identified a distinct, well-defined body under the eastern part
               of the basin down to 18?km depth. Considering its geometry and
               petrophysical signature, this unit is interpreted as a buried
               counterpart of the shallow prebasin sediments encountered
               outside of the basin and not as crystalline basement. The
               seismicity distribution supports our results, where events are
               concentrated along boundaries of the basin and the deep prebasin
               sedimentary body. Our results suggest that the Dead Sea basin is
               about 4?km deeper than assumed from previous studies.},
  journal   = {Geophys. Res. Lett.},
  publisher = {Wiley Online Library},
  volume    =  42,
  number    =  22,
  pages     = {9772--9780},
  series    = {Lecture Notes Comput. Sci},
  month     =  nov,
  year      =  2015,
  url       = {http://doi.wiley.com/10.1002/2015GL066559},
  issn      = {0094-8276},
  doi       = {10.1002/2015GL066559}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Le_Bouteiller2018-ma,
  title     = {Mixing Unsupervised and {Knowledge-Based} Analysis for
               Heterogeneous Object Delineation in Seismic Data},
  booktitle = {80th {EAGE} Conference and Exhibition 2018},
  author    = {Le Bouteiller, P and Charl{\'e}ty, J and Delprat-Jannaud, F and
               Granjeon, D and Gorini, C},
  abstract  = {Seismic interpretation is increasingly supported by
               quantitative, partly-automated methods. For economic purposes,
               some geological objects (geobodies) are targeted for automated
               delineation in seismic data. Some of them are depicted by a
               variety of internal seismic facies. Geobody detection is often
               based on the supervised retrieval of a defined seismic facies.
               It usually assumes homogeneous properties inside the targeted
               object. Unsupervised classification algorithms are better suited
               for highlighting the variety of facies inside a …},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=92121}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Blouin2017-gt,
  title     = {Automated facies prediction in drillholes using machine learning},
  booktitle = {79th {EAGE} Conference and Exhibition 2017-Workshops},
  author    = {Blouin, M and Cat{\'e}, A and Perozzi, L and Gloaguen, E},
  abstract  = {Machine learning is a popular topic in geosciences at the
               moment. It allows the management and interpretation of data in
               quantities and varieties (number of variables) that a human
               being would not be able to achieve. Rock physical properties
               acquired along drillholes can be used to generate predictions
               about the nature and characteristics of the rock when wireline
               logging is taking place. In this paper, we investigate the
               accuracy of facies prediction using machine learning algorithms
               by automatically interpreting geological …},
  publisher = {earthdoc.org},
  year      =  2017,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=89276}
}

@ARTICLE{Boateng2017-uf,
  title     = {Porosity inversion by Caianiello neural networks with
               {Levenberg-Marquardt} optimization},
  author    = {Boateng, C and Fu, L and Yu, W and Xizhu, G},
  abstract  = {AbstractCaianiello neural networks (CNNs) incorporated with the
               Robinson seismic convolutional model are modified by the
               Levenberg-Marquardt algorithm to improve convergence. CNNs are
               extended to the multiattribute domain for reservoir property
               inversion, with time-varying signal processing by a
               frequency-domain block implementation using fast Fourier
               transforms. Optimal inversion can be achieved by applying the
               Levenberg-Marquardt optimization to multiattribute domain CNNs
               for convergency improvement due to its ability to swing between
               the steepest-descent and Gauss-Newton algorithms. The
               methodology is applied to porosity estimation in an oilfield
               with six wells in the Bohai Basin of China. Cross-validation
               results indicate significant correlation between actual porosity
               logs and predicted porosity logs. Compared with a traditional
               method, our technique is robust.},
  journal   = {Interpretation},
  publisher = {Society of Exploration Geophysicists},
  volume    =  5,
  number    =  3,
  pages     = {SL33--SL42},
  month     =  aug,
  year      =  2017,
  url       = {https://doi.org/10.1190/INT-2016-0119.1},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2016-0119.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Blouin2017-vv,
  title     = {Facies classification using machine learning: lessons from
               {SEG-ML} contest},
  booktitle = {79th {EAGE} Conference and Exhibition 2017-Workshops},
  author    = {Blouin, M},
  abstract  = {New resources exploration and exploitation sites collect at high
               resolution and rate multiple sources of data, generating
               considerable amount of information to process and eventually,
               interpret. Newly developed Machine Learning algorithms can help
               overcoming this challenge to gain better insight on data and
               resources. As the latter is hot topic right now in geoscience,
               Matt Hall, Editor of Leading Edge's Geophysical Tutorial
               launches a contest for facies prediction in 2016 October issue.
               For this purpose, wireline logs and geological facies …},
  publisher = {earthdoc.org},
  year      =  2017,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=89360}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Blondelle2017-dv,
  title     = {Machine Learning can extract the information needed for
               modelling and data analysing from unstructured documents},
  booktitle = {79th {EAGE} Conference and Exhibition 2017-Workshops},
  author    = {Blondelle, H and Juneja, A and Micaelli, J and Neri, P},
  abstract  = {Since its early days, the exploration and production industry
               has handled large volumes of data, mainly measurements, to build
               subsurface models used for strategic or technical decisions.
               More recently, data analytics technologies have emerged to
               complement the modelling tools, with notable successes in the
               domain of field monitoring. But the broader adoption of new
               analytical tools is made difficult due to the limited access to
               the large percentage of relevant data that is stored in
               unstructured formats. This issue is not new …},
  publisher = {earthdoc.org},
  year      =  2017,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=89273}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Birkenfeld2010-rd,
  title     = {Automatic detection of reflexion hyperbolas in {GPR} data with
               neural networks},
  booktitle = {World Automation Congress},
  author    = {Birkenfeld, Sven},
  abstract  = {In order to locate cylindrical objects like pipes and cables
               buried underground using ground penetrating radar it is
               necessary to detect reflexion hyperbolas in the measured
               radargrams. In practice, this task is in many cases complicated
               due to different geological environments, incomplete or
               disturbed hyperbolas, and first of all the fact that nearby
               objects lead to hyperbolas interfering with each other. In this
               paper we present an automatic detection system based on a
               specially connected neural network using receptive fields. We
               show that …},
  publisher = {researchgate.net},
  pages     = {1--6},
  year      =  2010,
  url       = {https://www.researchgate.net/profile/Sven_Birkenfeld/publication/221671913_Automatic_detection_of_reflexion_hyperbolas_in_GPR_data_with_neural_networks/links/00b7d5303634cb6e1a000000.pdf}
}

@ARTICLE{Blinston2017-jk,
  title     = {Machine learning systems open up access to large volumes of
               valuable information lying dormant in unstructured documents},
  author    = {Blinston, K and Blondelle, H},
  abstract  = {Like many other types of data in the energy industry, well data
               stored electronically can be divided into two categories: (1)
               data stored in relational or object databases that are highly
               structured and (2) data located in documents in various formats
               (TIFF, JPG, PDF, XLS, etc.) that are typically gathered in
               folders in a semistructured or unstructured form. Typically,
               these data break down into 20\% structured data versus 80\%
               semi- or unstructured data; this figure is in line with what is
               observed for other types of data across the industry. This
               situation affects the ability to make informed decisions since
               geoscientific software and risk-assessment analytic systems only
               operate on structured data. Current practices to extract data
               and metadata from unstructured documents involve a mainly manual
               and costly process. Data model limitations of the most prevalent
               databases are a further hindrance to the capture of unstructured
               data. We discuss a feasibility study to access the 11,500 well
               headers and 450,000 documents from the United Kingdom
               Continental Shelf (UKCS) that were released by Common Data
               Access Limited (CDAL ? a wholly owned subsidiary of Oil and Gas
               UK, funded by 55 operators to share subsurface E\&P data) as
               part of its 2016 Unstructured Data Challenge initiative. A
               cost-effective solution based on emerging machine learning
               technology ?taught? and guided by data-management experts can
               support the reliable indexing and cataloging of these forms of
               data, paving the way for much more reliable E\&P business
               decisions in the future.},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  36,
  number    =  3,
  pages     = {257--261},
  month     =  mar,
  year      =  2017,
  url       = {https://doi.org/10.1190/tle36030257.1},
  issn      = {1070-485X},
  doi       = {10.1190/tle36030257.1}
}

@ARTICLE{Bicego2013-ox,
  title     = {Classification of Seismic Volcanic Signals Using
               {Hidden-Markov-Model-Based} Generative Embeddings},
  author    = {Bicego, M and Acosta-Mu{\~n}oz, C and Orozco-Alzate, M},
  abstract  = {The automated classification of seismic volcanic signals has
               been faced with several different pattern recognition
               approaches. Among them, hidden Markov models (HMMs) have been
               advocated as a cost-effective option having the advantages of a
               straightforward Bayesian interpretation and the capacity of
               dealing with seismic sequences of different lengths. In the
               volcano seismology scenario, HMM-based classification schemes
               were only based on a standard and purely generative scheme,
               i.e., the Bayes rule: training an HMM per class and classifying
               an incoming seismic signal according to the class whose model
               shows the highest likelihood. In this paper, a novel HMM-based
               classification approach for pretriggered seismic volcanic
               signals is proposed. The main idea is to enrich the classical
               HMM scheme with a discriminative step that is able to recover
               from situations when the classical Bayes classification rule is
               not sufficient. More in detail, a generative embedding scheme is
               used, which employs the models to map the signals into a vector
               space, which is called generative embedding space. In such a
               space, any discriminative vector-based classifier can be
               applied. A thorough set of experiments, which is carried out on
               pretriggered signals recorded at Galeras Volcano in Colombia,
               shows that the proposed approach typically outperforms standard
               HMM-based classification schemes, also in some cross-station
               cases.},
  journal   = {IEEE Trans. Geosci. Remote Sens.},
  publisher = {ieeexplore.ieee.org},
  volume    =  51,
  number    =  6,
  pages     = {3400--3409},
  month     =  jun,
  year      =  2013,
  url       = {http://dx.doi.org/10.1109/TGRS.2012.2220370},
  keywords  = {Bayes methods;geophysical signal processing;hidden Markov
               models;pattern recognition;seismology;signal
               classification;volcanology;seismic volcanic signal
               classification;hidden-Markov-model-based generative
               embeddings;automated classification;pattern recognition
               approaches;HMM;straightforward Bayesian interpretation;seismic
               sequences;volcano seismology scenario;Bayes rule;pretriggered
               seismic volcanic signals;classical Bayes classification
               rule;vector space;generative embedding space;discriminative
               vector-based classifier;pretriggered signals;Galeras
               Volcano;Colombia;Hidden Markov
               models;Training;Earthquakes;Standards;Vectors;Volcanoes;Computational
               modeling;Generative embeddings;hidden Markov models
               (HMMs);pattern recognition;seismic volcanic signals;volcano
               seismology},
  issn      = {0196-2892},
  doi       = {10.1109/TGRS.2012.2220370}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Bhatt2002-kj,
  title     = {Determination of facies from well logs using modular neural
               networks},
  author    = {Bhatt, A and Helle, H B},
  abstract  = {Zonation of well logs and the correlation of zones between wells
               are primary tasks in sub- surface geological and engineering
               analysis. We propose in this paper an artificial neural network
               (ANN) approach for objective clustering and identification of
               facies from well logs. The method relies upon combining
               back-propagation neural networks in ensembles and modular
               systems, where the multi-class classification problem of facies
               identification has effectively been reduced to a number of
               two-class problems. Based on the neural network …},
  journal   = {Pet. Geosci.},
  publisher = {earthdoc.org},
  year      =  2002,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=37980},
  issn      = {1354-0793}
}

@ARTICLE{Bhowmick2018-lr,
  title         = {Deep Autoassociative Neural Networks for Noise Reduction in
                   Seismic data},
  author        = {Bhowmick, Debjani and Gupta, Deepak K and Maiti, Saumen and
                   Shankar, Uma},
  abstract      = {Machine learning is currently a trending topic in various
                   science and engineering disciplines, and the field of
                   geophysics is no exception. With the advent of powerful
                   computers, it is now possible to train the machine to learn
                   complex patterns in the data, which may not be easily
                   realized using the traditional methods. Among the various
                   machine learning methods, the artificial neural networks
                   (ANNs) have received enormous attention. A variant of ANNs,
                   autoassociative neural network (autoNN) tries to learn the
                   reconstruction of input itself using backpropagation. In an
                   autoNN, the input and output are the same, and an
                   approximation to the identity mapping is obtained in a
                   nonlinear setting. AutoNNs have primarily been used to
                   extract sparse internal representations of any input and
                   reduce its dimensionality. In this paper, we explore the
                   potential of autoNNs in reducing random noise in geophysical
                   data. In this paper, the first results of this study are
                   presented. The synthetic mathematical example demonstrates
                   the concept of autoNN. For the test seismic data, it is
                   observed that autoNN can significantly remove the vertical
                   time- and frequency-local noise, however, the resolution of
                   the output signal is compromised to a certain extent. Future
                   work includes testing larger examples with several different
                   types of noise, and using deep-stacked-autoNNs to further
                   reduce the noise, ensuring minimal compromise with the
                   resolution of the signal.},
                     title={Deep Autoassociative Neural Networks for Noise Reduction in Seismic data},
  journal={ArXiv},
  month         =  may,
  year          =  2018,
  url           = {http://arxiv.org/abs/1805.00291},
  archivePrefix = {arXiv},
  eprint        = {1805.00291},
  primaryClass  = {cs.CE},
  arxivid       = {1805.00291}
}

@ARTICLE{Beyreuther2008-mz,
  title     = {Continuous earthquake detection and classification using
               discrete Hidden Markov Models},
  author    = {Beyreuther, Moritz and Wassermann, Joachim},
  abstract  = {We present a novel technique to solve the automatic detection
               and classification problem of earth tremor in a single step by
               using Hidden Markov Modelling (HMM). While this technique was
               originally developed in speech recognition, it already showed
               great promise when applied to volcano induced seismic signals.
               We apply the HMM classifier to a much simpler problem, that is,
               the detection and distance dependent classification of small to
               medium sized earthquakes. Using the smaller and possibly not
               perfect data set of earthquakes recorded with three stations of
               the Bavarian Earthquake Service enables us to better evaluate
               the advantages and disadvantages of the proposed algorithm and
               to compare the results with simple and widely used detection
               techniques (e.g. recursive short-term versus long-term average).
               Overall the performance of HMM shows good results in the
               pre-triggered classification tasks and reasonable results in the
               continuous case. The application of HMMs is illustrated step by
               step so it can be used as recipe for other applications. Special
               emphasize is given to the important problem of selecting the
               features, which best describe the properties of the different
               signals that are to be classified.},
  journal   = {Geophys. J. Int.},
  publisher = {Oxford University Press},
  volume    =  175,
  number    =  3,
  pages     = {1055--1066},
  month     =  dec,
  year      =  2008,
  url       = {https://academic.oup.com/gji/article-abstract/175/3/1055/634811},
  issn      = {0956-540X},
  doi       = {10.1111/j.1365-246X.2008.03921.x}
}

@INCOLLECTION{Bestagini2017-nh,
  title     = {A machine learning approach to facies classification using well
               logs},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2017},
  author    = {Bestagini, P and Lipari, V and Tubaro, S},
  abstract  = {In this work we describe a machine learning pipeline for facies
               classification based on wireline logging measurements. The
               algorithm has been designed to work even with a relatively small
               training set and amount of features. The method is based on a
               gradient boosting classifier which demonstrated to be effective
               in such a circumstance. A key aspect of the algorithm is feature
               augmentation, which resulted in a significant boost in accuracy.
               The algorithm has been tested also through participation to the
               SEG machine learning contest. Presentation Date: Wednesday,
               September 27, 2017 Start Time: 3:05 PM Location: 350D
               Presentation Type: ORAL},
  publisher = {Society of Exploration Geophysicists},
  pages     = {2137--2142},
  series    = {SEG Technical Program Expanded Abstracts},
  month     =  aug,
  year      =  2017,
  url       = {https://doi.org/10.1190/segam2017-17729805.1},
  doi       = {10.1190/segam2017-17729805.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Bauer2015-hy,
  title     = {Lithological control on gas hydrate saturation as revealed by
               signal classification of {NMR} logging data},
  author    = {Bauer, Klaus and Kulenkampff, Johannes and Henninges, Jan and
               Spangenberg, Erik},
  abstract  = {In this paper, nuclear magnetic resonance (NMR) downhole logging
               data are analyzed with a new strategy to study gas
               hydrate-bearing sediments in the Mackenzie Delta (NW Canada). In
               NMR logging, transverse relaxation time (T 2) distribution
               curves are usually used to determine single-valued parameters
               such as apparent total porosity or hydrocarbon saturation. Our
               approach analyzes the entire T 2 distribution curves as
               quasi-continuous signals to characterize the rock formation. We
               apply self-organizing maps, a neural network …},
  journal   = {J. Geophys. Res. [Solid Earth]},
  publisher = {Wiley Online Library},
  volume    =  120,
  number    =  9,
  pages     = {6001--6017},
  year      =  2015,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/2015JB012150}
}

@ARTICLE{Bauer2008-pv,
  title     = {Neural network analysis of crosshole tomographic images: The
               seismic signature of gas hydrate bearing sediments in the
               Mackenzie Delta ({NW} Canada)},
  author    = {Bauer, K and Pratt, R G and Haberland, C and Weber, M},
  abstract  = {Crosshole seismic experiments were conducted to study the
               in-situ properties of gas hydrate bearing sediments (GHBS) in
               the Mackenzie Delta (NW Canada). Seismic tomography provided
               images of P velocity, anisotropy, and attenuation.
               Self-organizing maps (SOM) are powerful neural network
               techniques to classify and interpret multi-attribute data sets.
               The coincident tomographic images are translated to a set of
               data vectors in order to train a Kohonen layer. The total
               gradient of the model vectors is determined for the trained SOM
               and a watershed segmentation algorithm is used to visualize and
               map the lithological clusters with well-defined seismic
               signatures. Application to the Mallik data reveals four major
               litho-types: (1) GHBS, (2) sands, (3) shale/coal interlayering,
               and (4) silt. The signature of seismic P wave characteristics
               distinguished for the GHBS (high velocities, strong anisotropy
               and attenuation) is new and can be used for new exploration
               strategies to map and quantify gas hydrates.},
  journal   = {Geophys. Res. Lett.},
  publisher = {Wiley Online Library},
  volume    =  35,
  number    =  19,
  pages     = {340},
  month     =  oct,
  year      =  2008,
  url       = {http://doi.wiley.com/10.1029/2008GL035263},
  issn      = {0094-8276},
  doi       = {10.1029/2008GL035263}
}

@ARTICLE{Ballabio2012-xv,
  title     = {Support Vector Machines for Landslide Susceptibility Mapping:
               The Staffora River Basin Case Study, Italy},
  author    = {Ballabio, Cristiano and Sterlacchini, Simone},
  abstract  = {The aim of this study is the application of support vector
               machines (SVM) to landslide susceptibility mapping. SVM are a
               set of machine learning methods in which model capacity matches
               data complexity. The research is based on a conceptual framework
               targeted to apply and test all the procedural steps for
               landslide susceptibility modeling from model selection, to
               investigation of predictive variables, from empirical
               cross-validation of results, to analysis of predicted patterns.
               SVM were successfully applied and the final susceptibility map
               was interpreted via success and prediction rate curves and
               receiver operating characteristic (ROC) curves, to support the
               modeling results and assess the robustness of the model. SVM
               appeared to be very specific learners, able to discriminate
               between the informative input and random noise. About 78\% of
               occurrences was identified within the 20\% of the most
               susceptible study area for the cross-validation set. Then the
               final susceptibility map was compared with other maps, addressed
               by different statistical approaches, commonly used in
               susceptibility mapping, such as logistic regression, linear
               discriminant analysis, and naive Bayes classifier. The SVM
               procedure was found feasible and able to outperform other
               techniques in terms of accuracy and generalization capacity. The
               over-performance of SVM against the other techniques was around
               18\% for the cross-validation set, considering the 20\% of the
               most susceptible area. Moreover, by analyzing receiver operating
               characteristic (ROC) curves, SVM appeared to be less prone to
               false positives than the other models. The study was applied in
               the Staffora river basin (Lombardy, Northern Italy), an area of
               about 275 km2 characterized by a very high density of
               landslides, mainly superficial slope failures triggered by
               intense rainfall events.},
  journal   = {Math. Geosci.},
  publisher = {Springer},
  volume    =  44,
  number    =  1,
  pages     = {47--70},
  month     =  jan,
  year      =  2012,
  url       = {https://doi.org/10.1007/s11004-011-9379-9},
  issn      = {1874-8961, 1874-8953},
  doi       = {10.1007/s11004-011-9379-9}
}

@ARTICLE{Bagheripour2014-ak,
  title     = {Committee neural network model for rock permeability prediction},
  author    = {Bagheripour, Parisa},
  abstract  = {Quantitative formulation between conventional well log data and
               rock permeability, undoubtedly the most critical parameter of
               hydrocarbon reservoir, could be a potent tool for solving
               problems associated with almost all tasks involved in petroleum
               engineering. The present study proposes a novel approach in
               charge of the quest for high-accuracy method of permeability
               prediction. At the first stage, overlapping of conventional well
               log data (inputs) was eliminated by means of principal component
               analysis (PCA). Subsequently, rock permeability was predicted
               from extracted PCs using multi-layer perceptron (MLP), radial
               basis function (RBF), and generalized regression neural network
               (GRNN). Eventually, a committee neural network (CNN) was
               constructed by virtue of genetic algorithm (GA) to enhance the
               precision of ultimate permeability prediction. The values of
               rock permeability, derived from the MPL, RBF, and GRNN models,
               were used as inputs of CNN. The proposed CNN combines results of
               different ANNs to reap beneficial advantages of all models and
               consequently producing more accurate estimations. The GA,
               embedded in the structure of the CNN assigns a weight factor to
               each ANN which shows relative involvement of each ANN in overall
               prediction of rock permeability from PCs of conventional well
               logs. The proposed methodology was applied in Kangan and Dalan
               Formations, which are the major carbonate reservoir rocks of
               South Pars Gas Field-Iran. A group of 350 data points was used
               to establish the CNN model, and a group of 245 data points was
               employed to assess the reliability of constructed CNN model.
               Results showed that the CNN method performed better than
               individual intelligent systems performing alone.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  104,
  pages     = {142--148},
  month     =  may,
  year      =  2014,
  url       = {http://www.sciencedirect.com/science/article/pii/S092698511400069X},
  keywords  = {Multi-layer perceptron (MLP); Radial basis function (RBF);
               Generalized regression neural network (GRNN); Genetic algorithm
               (GA); Committee neural network (CNN); Rock permeability},
  issn      = {0926-9851},
  doi       = {10.1016/j.jappgeo.2014.03.001}
}

@ARTICLE{Asoodeh2013-dd,
  title     = {Fuzzy classifier based support vector regression framework for
               Poisson ratio determination},
  author    = {Asoodeh, Mojtaba and Bagheripour, Parisa},
  abstract  = {Poisson ratio is considered as one of the most important rock
               mechanical properties of hydrocarbon reservoirs. Determination
               of this parameter through laboratory measurement is time, cost,
               and labor intensive. Furthermore, laboratory measurements do not
               provide continuous data along the reservoir intervals. Hence, a
               fast, accurate, and inexpensive way of determining Poisson ratio
               which produces continuous data over the whole reservoir interval
               is desirable. For this purpose, support vector regression (SVR)
               method based on statistical learning theory (SLT) was employed
               as a supervised learning algorithm to estimate Poisson ratio
               from conventional well log data. SVR is capable of accurately
               extracting the implicit knowledge contained in conventional well
               logs and converting the gained knowledge into Poisson ratio
               data. Structural risk minimization (SRM) principle which is
               embedded in the SVR structure in addition to empirical risk
               minimization (EMR) principle provides a robust model for finding
               quantitative formulation between conventional well log data and
               Poisson ratio. Although satisfying results were obtained from an
               individual SVR model, it had flaws of overestimation in low
               Poisson ratios and underestimation in high Poisson ratios. These
               errors were eliminated through implementation of fuzzy
               classifier based SVR (FCBSVR). The FCBSVR significantly improved
               accuracy of the final prediction. This strategy was successfully
               applied to data from carbonate reservoir rocks of an Iranian Oil
               Field. Results indicated that SVR predicted Poisson ratio values
               are in good agreement with measured values.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  96,
  pages     = {7--10},
  month     =  sep,
  year      =  2013,
  url       = {http://www.sciencedirect.com/science/article/pii/S0926985113001237},
  keywords  = {Fuzzy classifier based support vector regression (FCBSVR);
               Statistical learning theory (SLT); Structural risk minimization
               (SRM); Empirical risk minimization (EMR); Poisson ratio},
  issn      = {0926-9851},
  doi       = {10.1016/j.jappgeo.2013.06.006}
}

@ARTICLE{Asoodeh2014-mm,
  title     = {{ACE} stimulated neural network for shear wave velocity
               determination from well logs},
  author    = {Asoodeh, Mojtaba and Bagheripour, Parisa},
  abstract  = {Shear wave velocity provides invaluable information for
               geomechanical, geophysical, and reservoir characterization
               studies. However, measurement of shear wave velocity is time,
               cost and labor intensive. This study proposes a swift and exact
               methodology, called ACE stimulated neural network, for
               prediction of shear wave velocity from available well logs such
               that it will be able to surpass previous models. The proposed
               method is composed of two major parts: 1) transforming
               input/output data space to a higher correlated space using
               alternative condition expectation (ACE), and 2) making a neural
               network formulation in transformed data space. Transforming in
               the first step makes it easier for neural network to find the
               complicated underlying dependency of input/output data.
               Therefore, neural network will be able to develop an accurate
               and strong formulation between conventional well logs and shear
               wave velocity. The Propounded approach was successfully applied
               in one of the carbonate gas fields of Iran. A comparison between
               proposed model and previous models showed superiority of ACE
               stimulated neural network.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  107,
  pages     = {102--107},
  month     =  aug,
  year      =  2014,
  url       = {http://www.sciencedirect.com/science/article/pii/S0926985114001487},
  keywords  = {Petrophysics; Rock mechanics; Well logging; ACE stimulated
               neural network},
  issn      = {0926-9851},
  doi       = {10.1016/j.jappgeo.2014.05.014}
}

@ARTICLE{Ashida1996-gk,
  title     = {Data processing of reflection seismic data by use of neural
               network},
  author    = {Ashida, Yuzuru},
  abstract  = {The present paper proposes an algorithm for data processing of
               reflection seismic data using of neural networks. A neural
               network algorithm was applied to the reading of arrival time of
               first break signal, the recognition of waveform in seismic trace
               and the automatic picking of result of constant velocity scan
               among the various data processing techniques. A layered network
               with the correct answer, so called, teacher's signal, in
               training period by the error back propagation algorithm was
               used. The general procedure of processing of reflection seismic
               data by use of neural network is as follows. 1.1. Constitution
               of the most suitable network for the target processing.2.2.
               Setting of the weight values to all units in the layers and the
               teacher's signal.3.3. Calculation of the output signals from the
               output layer by activating the network.4.4. Estimation of
               learning signal from the energy of errors between the actual
               output signal and the teacher's signal.5.5. Calculation of the
               change of weight values by using learning signal so as to
               minimize the energy of errors between the actual signal and the
               teacher's signal.6.6. Steps (3) to (5) are repeated till the
               errors fall into the designated limitation or the designated
               learning count is reached. As a result of model studies, it was
               determined that the proposed algorithm performed the readings of
               arrival time of first break signal, the waveform recognition and
               the automatic picking of velocity analysis result with good
               accuracy.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  35,
  number    =  2,
  pages     = {89--98},
  month     =  sep,
  year      =  1996,
  url       = {http://www.sciencedirect.com/science/article/pii/0926985196000109},
  issn      = {0926-9851},
  doi       = {10.1016/0926-9851(96)00010-9}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Asefa2005-uj,
  title     = {Support vector machines for nonlinear state space
               reconstruction: Application to the Great Salt Lake time series},
  author    = {Asefa, Tirusew and Kemblowski, Mariush and Lall, Upmanu and
               Urroz, Gilberto},
  abstract  = {The reconstruction of low-order nonlinear dynamics from the time
               series of a state variable has been an active area of research
               in the last decade. The 154 year long, biweekly time series of
               the Great Salt Lake volume has been analyzed by many researchers
               from this perspective. In this study, we present the application
               of a powerful state space reconstruction methodology using the
               method of support vector machines (SVM) to this data set. SVM
               are machine learning systems that use a hypothesis space of
               linear functions in a kernel …},
  journal   = {Water Resour. Res.},
  publisher = {Wiley Online Library},
  volume    =  41,
  number    =  12,
  year      =  2005,
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2004WR003785},
  issn      = {0043-1397}
}

@ARTICLE{Araya-Polo2017-ky,
  title     = {Automated fault detection without seismic processing},
  author    = {Araya-Polo, M and Dahlke, T and Frogner, C and Zhang, C and
               Poggio, T and Hohl, D},
  abstract  = {For hydrocarbon exploration, large volumes of data are acquired
               and used in physical modeling-based workflows to identify
               geologic features of interest such as fault networks, salt
               bodies, or, in general, elements of petroleum systems. The
               adjoint modeling step, which transforms the data into the model
               space, and subsequent interpretation can be very expensive, both
               in terms of computing resources and domain-expert time. We
               propose and implement a unique approach that bypasses these
               demanding steps, directly assisting interpretation. We do this
               by training a deep neural network to learn a mapping
               relationship between the data space and the final output
               (particularly, spatial points indicating fault presence). The
               key to obtaining accurate predictions is the use of the
               Wasserstein loss function, which properly handles the structured
               output ? in our case, by exploiting fault surface continuity.
               The promising results shown here for synthetic data demonstrate
               a new way of using seismic data and suggest more direct methods
               to identify key elements in the subsurface.},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  36,
  number    =  3,
  pages     = {208--214},
  month     =  mar,
  year      =  2017,
  url       = {https://doi.org/10.1190/tle36030208.1},
  issn      = {1070-485X},
  doi       = {10.1190/tle36030208.1}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Araya-Polo2018-nr,
  title     = {Deep {Learning-Driven} {Pore-Scale} Simulation For Permeability
               Estimation},
  booktitle = {{ECMOR} {XVI-16th} European Conference on the Mathematics of Oil
               Recovery},
  author    = {Araya-Polo, M and Alpak, F O and Hunter, S and Hofmann, R and
               Saxena, N},
  abstract  = {Current micro-CT image resolution is limited to~ 1-2 microns. A
               recent study has identified that at least 10 image voxels are
               needed to resolve pore throats, which limits the applicability
               of direct simulations using the Digital Rock (DR) technology to
               medium-to …},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=93919}
}

@ARTICLE{Araya-Polo2018-xf,
  title     = {Deep-learning tomography},
  author    = {Araya-Polo, M and Jennings, J and Adler, A and Dahlke, T},
  abstract  = {Abstract Velocity-model building is a key step in hydrocarbon
               exploration. The main product of velocity-model building is an
               initial model of the subsurface that is subsequently used in
               seismic imaging and interpretation workflows. Reflection or
               refraction tomography and full-waveform inversion (FWI) are the
               most commonly used techniques in velocity-model building. On one
               hand, tomography is a time-consuming activity that relies on
               successive updates of highly human-curated analysis of gathers.
               On the other hand, FWI is very computationally demanding with no
               guarantees of global convergence. We propose and implement a
               novel concept that bypasses these demanding steps, directly
               producing an accurate gridding or layered velocity model from
               shot gathers. Our approach relies on training deep neural
               networks. The resulting predictive model maps relationships
               between the data space and the final output (particularly the
               presence of high-velocity segments that might indicate salt
               formations). The training task takes a few hours for 2D data,
               but the inference step (predicting a model from previously
               unseen data) takes only seconds. The promising results shown
               here for synthetic 2D data demonstrate a new way of using
               seismic data and suggest fast turnaround of workflows that now
               make use of machine-learning approaches to identify key
               structures in the subsurface.},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  37,
  number    =  1,
  pages     = {58--66},
  month     =  jan,
  year      =  2018,
  url       = {https://doi.org/10.1190/tle37010058.1},
  issn      = {1070-485X},
  doi       = {10.1190/tle37010058.1}
}

@ARTICLE{Ansari2014-ci,
  title     = {Use seismic colored inversion and power law committee machine
               based on imperial competitive algorithm for improving porosity
               prediction in a heterogeneous reservoir},
  author    = {Ansari, Hamid Reza},
  abstract  = {In this paper we propose a new method for predicting rock
               porosity based on a combination of several artificial
               intelligence systems. The method focuses on one of the Iranian
               carbonate fields in the Persian Gulf. Because there is strong
               heterogeneity in carbonate formations, estimation of rock
               properties experiences more challenge than sandstone. For this
               purpose, seismic colored inversion (SCI) and a new approach of
               committee machine are used in order to improve porosity
               estimation. The study comprises three major steps. First, a
               series of sample-based attributes is calculated from 3D seismic
               volume. Acoustic impedance is an important attribute that is
               obtained by the SCI method in this study. Second, porosity log
               is predicted from seismic attributes using common intelligent
               computation systems including: probabilistic neural network
               (PNN), radial basis function network (RBFN), multi-layer feed
               forward network (MLFN), $\epsilon$-support vector regression
               ($\epsilon$-SVR) and adaptive neuro-fuzzy inference system
               (ANFIS). Finally, a power law committee machine (PLCM) is
               constructed based on imperial competitive algorithm (ICA) to
               combine the results of all previous predictions in a single
               solution. This technique is called PLCM-ICA in this paper. The
               results show that PLCM-ICA model improved the results of neural
               networks, support vector machine and neuro-fuzzy system.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  108,
  pages     = {61--68},
  month     =  sep,
  year      =  2014,
  url       = {http://www.sciencedirect.com/science/article/pii/S092698511400192X},
  keywords  = {Neural networks; Neuro-fuzzy; Support vector regression; Power
               law committee machine; Imperial competitive algorithm; Colored
               inversion},
  issn      = {0926-9851},
  doi       = {10.1016/j.jappgeo.2014.06.016}
}

@ARTICLE{Anifowose2017-tu,
  title     = {Ensemble machine learning: An untapped modeling paradigm for
               petroleum reservoir characterization},
  author    = {Anifowose, Fatai Adesina and Labadin, Jane and Abdulraheem,
               Abdulazeez},
  abstract  = {The successful applications of the conventional Computational
               Intelligence (CI) techniques and Hybrid Intelligent Systems
               (HIS) in petroleum reservoir characterization have been
               reported. However, these techniques are limited in their
               capability to handle a single hypothesis of a problem at a time.
               The major objective of the reservoir characterization process is
               to produce models that are robust enough to help improve the
               accuracy of the predictions of reservoir properties for use in
               full-field and large-scale simulation models. Research in CI
               continues to evolve new techniques and paradigms to meet this
               noble objective. It has been shown that there are uncertainties
               in the reservoir characterization process as well as the optimal
               choice of CI/HIS models parameters. The main challenge is to
               develop models that are capable of handling multiple hypotheses
               to reduce the uncertainties thereby ensuring optimal solutions.
               The ensemble machine learning paradigm has been established to
               tackle this challenge. This new machine learning technology has
               not been adequately explored in handling some of the petroleum
               engineering challenges. This paper rigorously reviews the
               concept of ensemble learning paradigm, presents successful
               applications outside petroleum engineering and the geosciences,
               discusses a few successful attempts in petroleum engineering and
               the geosciences, and concludes with some recommendations for the
               much-needed future applications.},
  journal   = {J. Pet. Sci. Eng.},
  publisher = {Elsevier},
  volume    =  151,
  pages     = {480--487},
  month     =  mar,
  year      =  2017,
  url       = {http://www.sciencedirect.com/science/article/pii/S0920410517300712},
  keywords  = {Ensemble machine learning; Reservoir characterization and
               modeling; Petroleum reservoir properties; Computational
               intelligence},
  issn      = {0920-4105},
  doi       = {10.1016/j.petrol.2017.01.024}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Anifowose2017-bx,
  title     = {Carbonate Reservoir Cementation Factor Modeling Using Wireline
               Logs and Artificial Intelligence Methodology},
  booktitle = {79th {EAGE} Conference and Exhibition 2017-Workshops},
  author    = {Anifowose, F and Ayadiuno, C and Rashedian, F},
  abstract  = {An approach, comprising statistical and artificial intelligence
               techniques, to modeling rock cementation factor in a Saudi
               Arabian carbonate reservoir using wireline logs is presented.
               The objective is to obtain a more accurate prediction of rock
               cementation factor, denoted by the exponent, m, in Archie's
               equation, as a variable log using multivariate linear regression
               (MLR), artificial neural networks, and support vector machines.
               Published equations by Nugent, Lucia and Shell are empirical
               derivations based on porosity logs and assumptions …},
  publisher = {earthdoc.org},
  year      =  2017,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=89285}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Amorese2015-bg,
  title     = {Automatic Clustering of Macroseismic Intensity Data Points from
               Internet Questionnaires: Efficiency of the Partitioning around
               Medoids ({PAM})},
  author    = {Amor{\`e}se, Daniel and Bossu, R{\'e}my and Mazet‐Roux, Gilles},
  abstract  = {In the early history of scientific seismology, the systematic
               collection of macroseismic information was performed through
               standardized paper questionnaires. The Internet is changing the
               way earthquakes are monitored by citizens (Wald et al., 1999;
               Bossu et al., 2011, 2014). With the phenomenal growth of the
               Internet, many Internet-based macroseismic survey systems have
               been implemented in the last decade in many parts of the world
               (see Wald et al., 2011, for a survey of these systems). These
               kinds of systems …},
  journal   = {Seismol. Res. Lett.},
  publisher = {GeoScienceWorld},
  volume    =  86,
  number    =  4,
  pages     = {1171--1177},
  month     =  jul,
  year      =  2015,
  url       = {https://pubs.geoscienceworld.org/ssa/srl/article-abstract/86/4/1171/315532},
  issn      = {0895-0695},
  doi       = {10.1785/0220140140}
}

@ARTICLE{Amin2017-yu,
  title     = {Automated salt-dome detection using an attribute ranking
               framework with a dictionary-based classifier},
  author    = {Amin, A and Deriche, M and Shafiq, M and Wang, Z and AlRegib, G},
  abstract  = {AbstractWe have developed a dictionary-based classification
               approach for salt-dome detection within migrated seismic
               volumes. The proposed workflow uses seismic attributes derived
               from the gray-level co-occurrence matrix, Gabor filter, and
               higher order singular-value decomposition to effectively learn
               and detect the salt bodies. We use an information theoretic
               framework to rank the seismic attributes as per their salt-dome
               classification performance. Based on this ranking, we select the
               top K attributes for dictionary training, testing, and
               classification. To improve the accuracy of the detected salt
               bodies and make the proposed workflow robust to different data
               sets, we introduce a refining step that uses edge strength and
               energy values to detect the shape of the salt-dome boundary
               within the classified patches. The optimal set of attributes and
               the refining step ensure that the proposed workflow yields good
               results for detecting salt-dome boundaries even in the presence
               of weak seismic reflections. We use the seismic data from the
               Netherlands offshore F3 block (North Sea) to demonstrate the
               effectiveness of the proposed workflow in detecting salt bodies.
               Using subjective and objective evaluation metrics, we compare
               the results of the proposed workflow with existing gradient-,
               texture-, and patch-based classification methods. The
               experimental results show that the proposed workflow outperforms
               existing salt-dome delineation techniques in terms of accuracy
               and precision.},
  journal   = {Interpretation},
  publisher = {Society of Exploration Geophysicists},
  volume    =  5,
  number    =  3,
  pages     = {SJ61--SJ79},
  month     =  aug,
  year      =  2017,
  url       = {https://doi.org/10.1190/INT-2016-0084.1},
  issn      = {2324-8858},
  doi       = {10.1190/INT-2016-0084.1}
}

@ARTICLE{AlRegib2018-yr,
  title     = {Subsurface Structure Analysis Using Computational Interpretation
               and Learning: A Visual Signal Processing Perspective},
  author    = {AlRegib, G and Deriche, M and Long, Z and Di, H and Wang, Z and
               Alaudah, Y and Shafiq, M A and Alfarraj, M},
  abstract  = {Understanding Earth's subsurface structures has been and
               continues to be an essential component of various applications
               such as environmental monitoring, carbon sequestration, and oil
               and gas exploration. By viewing the seismic volumes that are
               generated through the processing of recorded seismic traces,
               researchers were able to learn from applying advanced image
               processing and computer vision algorithms to effectively analyze
               and understand Earth's subsurface structures. In this article,
               we first summarize the recent advances in this direction that
               relied heavily on the fields of image processing and computer
               vision. Second, we discuss the challenges in seismic
               interpretation and provide insights and some directions to
               address such challenges using emerging machine-learning
               algorithms.},
  journal   = {IEEE Signal Process. Mag.},
  publisher = {ieeexplore.ieee.org},
  volume    =  35,
  number    =  2,
  pages     = {82--98},
  month     =  mar,
  year      =  2018,
  url       = {http://dx.doi.org/10.1109/MSP.2017.2785979},
  keywords  = {computer vision;environmental monitoring
               (geophysics);geophysical image processing;learning (artificial
               intelligence);seismology;seismic volumes;recorded seismic
               traces;advanced image processing;computer vision
               algorithms;Earth's subsurface structures;seismic
               interpretation;subsurface structure analysis;computational
               interpretation;visual signal processing
               perspective;environmental monitoring;carbon
               sequestration;machine-learning algorithms;oil-and-gas
               exploration;Earth;Image processing;Computer vision;Environmental
               monitoring;Carbon;Oil drilling;Gas industry},
  issn      = {1053-5888},
  doi       = {10.1109/MSP.2017.2785979}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Allen2016-xi,
  title     = {Geologically constrained electrofacies classification of fluvial
               deposits: An example from the Cretaceous Mesaverde Group, Uinta
               and Piceance Basins},
  author    = {Allen, Daniel B and Pranter, Matthew J},
  abstract  = {Statistical classification methods consisting of the k-nearest
               neighbor algorithm (k-NN), a probabilistic clustering procedure
               (PCP), and a novel method that incorporates outcrop- based
               thickness criteria through the use of well log indicator flags
               are evaluated for their ability to distinguish fluvial
               architectural elements of the upper Mesaverde Group of the
               Piceance and Uinta Basins as distinct electrofacies classes.
               Data used in training and testing of the classification methods
               come from paired cores and well logs consisting of 1626 …},
  journal   = {AAPG Bull.},
  publisher = {GeoScienceWorld},
  volume    =  100,
  number    =  12,
  pages     = {1775--1801},
  month     =  dec,
  year      =  2016,
  url       = {https://pubs.geoscienceworld.org/segweb/aapgbull/article/100/12/1775/223929},
  issn      = {0149-1423},
  doi       = {10.1306/05131614229}
}

@ARTICLE{Al-Nuaimy2000-sa,
  title     = {Automatic detection of buried utilities and solid objects with
               {GPR} using neural networks and pattern recognition},
  author    = {Al-Nuaimy, W and Huang, Y and Nakhkash, M and Fang, M T C and
               Nguyen, V T and Eriksen, A},
  abstract  = {The task of locating buried utilities using ground penetrating
               radar is addressed, and a novel processing technique
               computationally suitable for on-site imaging is proposed. The
               developed system comprises a neural network classifier, a
               pattern recognition stage, and additional pre-processing,
               feature-extraction and image processing stages. Automatic
               selection of the areas of the radargram containing useful
               information results in a reduced data set and hence a reduction
               in computation time. A backpropagation neural network is
               employed to identify portions of the radar image corresponding
               to target reflections by training it to recognise the Welch
               power spectral density estimate of signal segments reflected
               from various types of buried target. This results in a
               classification of the radargram into useful and redundant
               sections, and further processing is performed only on the
               former. The Hough Transform is then applied to the edges of
               these reflections, in order to accurately identify the depth and
               position of the buried targets. This allows a high resolution
               reconstruction of the subsurface with reduced computation time.
               The system was tested on data containing pipes, cables and
               anti-personnel landmines, and the results indicate that
               automatic and effective detection and mapping of such structures
               can be achieved in near real-time.},
  journal   = {J. Appl. Geophys.},
  publisher = {Elsevier},
  volume    =  43,
  number    =  2,
  pages     = {157--165},
  month     =  mar,
  year      =  2000,
  url       = {http://www.sciencedirect.com/science/article/pii/S0926985199000555},
  keywords  = {Neural networks; Pattern recognition; Hough transform;
               Ground-penetrating radar},
  issn      = {0926-9851},
  doi       = {10.1016/S0926-9851(99)00055-5}
}

@ARTICLE{Al-Abadi2018-vg,
  title     = {Mapping flood susceptibility in an arid region of southern Iraq
               using ensemble machine learning classifiers: a comparative study},
  author    = {Al-Abadi, Alaa M},
  abstract  = {This study examined the efficacy of three machine ensemble
               classifiers, namely, random forest, rotation forest and
               AdaBoost, in assessing flood susceptibility in an arid region of
               southern Iraq. A dataset was created from flooded and
               non-flooded areas to train and validate the ensemble classifiers
               using a binary classification scheme (1---flood, 0---non-flood).
               The prepared dataset was then partitioned into two sets with a
               70/30 ratio: 70\% (2478 pixels) for training and 30\% (1062
               pixels) for testing. A total of 10 influential flood factors
               were selected and prepared based on data availability and a
               literature review. The selected factors were surface elevation,
               slope, plain curvature, topographic wetness index, stream power
               index, distance to rivers, drainage density, lithology, soil and
               land use/land cover. The information gain ratio was first
               utilised to explore the predictive abilities of the factors. The
               predictive performances of the three ensemble models were
               compared using six statistical measures: sensitivity,
               specificity, accuracy, kappa, root mean square error and area
               under the operating characteristics curve. The results revealed
               that the AdaBoost classifier was the best in terms of the
               statistical measures, followed by the random forest and rotation
               forest models. A flood susceptibility map was prepared based on
               the result of each classifier and classified into five zones:
               very low, low, moderate, high and very high. For the model with
               the best performance, i.e., the AdaBoost model, these zones were
               distributed over an area of 6002 km2 (44\%) for the very
               low--low zone, 2477 km2 (18\%) for the moderate zone and 5048
               km2 (40\%) for the high--very high zones. This study proved the
               high capabilities of ensemble machine learning classifiers to
               decipher flood susceptibility zones in an arid region.},
  journal   = {Arabian Journal of Geosciences},
  publisher = {Springer},
  volume    =  11,
  number    =  9,
  pages     = {218},
  month     =  may,
  year      =  2018,
  url       = {https://doi.org/10.1007/s12517-018-3584-5},
  issn      = {1866-7538},
  doi       = {10.1007/s12517-018-3584-5}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Akhmetov2018-uc,
  title     = {Operational Selection of Wells for Hydraulic Fracturing
               Treatment Through Machine Learning},
  booktitle = {Saint Petersburg 2018},
  author    = {Akhmetov, A and Shishaev, G},
  abstract  = {The purpose of the work is the development of methodology for
               the operational selection of wells for hydraulic fracturing
               treatment based on machine learning for Field A. In order to
               prepare information for machine learning the data from the
               simulation model, monthly field reports, well test, HF reports
               are collected and analyzed. Principal component analysis was
               used in order to find out correlating between themselves
               parameters and exclude them from the database. Target for binary
               classification parameter is efficiency of HF treatment. After …},
  publisher = {earthdoc.org},
  year      =  2018,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=91476}
}

@ARTICLE{Abedi2012-um,
  title     = {Support vector machine for multi-classification of mineral prospectivity areas},
  author    = {Abedi, Maysam and Norouzi, Gholam-Hossain and Bahroudi, Abbas},
  abstract  = {In this paper on mineral prospectivity mapping, a supervised
               classification method called Support Vector Machine (SVM) is
               used to explore porphyry-Cu deposits. Different data layers of
               geological, geophysical and geochemical themes are integrated to
               evaluate the Now Chun porphyry-Cu deposit, located in the Kerman
               province of Iran, and to prepare a prospectivity map for mineral
               exploration. The SVM method, a data-driven approach to pattern
               recognition, had a correct-classification rate of 52.38\% for
               twenty-one boreholes divided into five classes. The results of
               the study indicated the capability of SVM as a supervised
               learning algorithm tool for the predictive mapping of mineral
               prospects. Multi-classification of the prospect for detailed
               study could increase the resolution of the prospectivity map and
               decrease the drilling risk.},
  journal   = {Comput. Geosci.},
  publisher = {Elsevier},
  volume    =  46,
  pages     = {272--283},
  month     =  sep,
  year      =  2012,
  url       = {http://www.sciencedirect.com/science/article/pii/S0098300411004389},
  keywords  = {Mineral prospectivity mapping; SVM method; Multi-classification;
               Porphyry copper; Now Chun deposit},
  issn      = {0098-3004},
  doi       = {10.1016/j.cageo.2011.12.014}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Minkoff2004-jr,
  title     = {Coupled geomechanics and flow simulation for time‐lapse seismic
               modeling},
  author    = {Minkoff, S and Stone, C and Bryant, S and Peszynska, M},
  abstract  = {To accurately predict production in compactible reservoirs, we
               must use coupled models of fluid flow and mechanical
               deformation. Staggered?in?time loose coupling of flow and
               deformation via a high?level numerical interface that repeatedly
               calls first flow and then mechanics allows us to leverage the
               decades of work put into individual flow and mechanics
               simulators while still capturing realistic coupled physics.
               These two processes are often naturally modeled using different
               time stepping schemes and different spatial grids?flow should
               only model the reservoir, whereas mechanics requires a grid that
               extends to the earth's surface for overburden loading and may
               extend further than the reservoir in the lateral directions.
               Although spatial and temporal variability between flow and
               mechanics can be difficult to accommodate with full coupling, it
               is easily handled via loose coupling. We calculate the total
               stress by adding pore pressures to the effective rock stress. In
               turn, changes in volume strain induce updates to porosity and
               permeability and, hence, dynamically alter the flow solution
               during simulation. Incorporating the resulting time?dependent
               pressures, saturations, and porosities (from coupled flow and
               mechanics) into Gassmann's equations results in seismic wave
               velocities and densities that can differ markedly from those
               calculated from flow alone. In a synthetic numerical experiment
               based on Belridge field, California, incorporation of coupled
               flow and mechanical deformation into time?lapse calculations
               produces compressional wave velocities that differ markedly from
               those produced by flow alone. In fact, it is the closing of the
               pores themselves (reduction in permeability) in this example
               which has the greatest impact on fluid pressures and saturations
               and, hence, elastic wave parameters such as velocity.},
  journal   = {Geophysics},
  publisher = {Society of Exploration Geophysicists},
  volume    =  69,
  number    =  1,
  pages     = {200--211},
  month     =  jan,
  year      =  2004,
  url       = {https://doi.org/10.1190/1.1649388},
  issn      = {0016-8033},
  doi       = {10.1190/1.1649388}
}

@ARTICLE{Tura2005-zy,
  title   = {Monitoring primary depletion reservoirs using amplitudes and time
             shifts from high-repeat seismic surveys},
  author  = {Tura, Ali and Barker, Timothy and Cattermole, Paul and Collins,
             Chuck and Davis, Jerry and Hatchell, Paul and Koster, Klaas and
             Schutjens, Peter and Wills, Peter},
  journal = {Lead. Edge},
  volume  =  24,
  number  =  12,
  pages   = {1214--1221},
  month   =  dec,
  year    =  2005,
  url     = {http://library.seg.org/doi/10.1190/1.2149620},
  issn    = {1070-485X},
  doi     = {10.1190/1.2149620}
}

@INPROCEEDINGS{Herwanger2013-wq,
  title     = {Time-lapse seismic data-calibrated geomechanical model reveals
               hydraulic fracture re-orientation},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2013},
  author    = {Herwanger, Jorg V and Mohamed, Farid R and Newman, Robert and
               Vejb{\ae}k, Ole},
  abstract  = {The orientation and size of fractures created during hydraulic
               stimulation is governed by the in-situ stress state. Reservoir
               production changes both the magnitude and the direction of the
               principal stresses, and these stress changes can be calculated
               using a geomechanical model. In this study, we employ a 4D
               geomechanical model calibrated with time-lapse seismic time
               shift data to understand the direction of fracture growth during
               hydraulic stimulation of a horizontal injector well. The
               horizontal well was drilled in the (expected) direction of the
               maximum horizontal stress, such that the strike direction of the
               fractures is aligned with the wellbore axis. Our study shows
               that production from a nearby well has rotated the directions of
               horizontal stresses, and some of the hydraulic fractures now
               grow perpendicular to the wellbore axis. The stress-field
               calculations and predicted directions of hydraulic fractures are
               substantiated by the observed time-lapse seismic amplitude
               signal. This signal shows increased fluid flow in the predicted
               fracture direction for individual stimulated zones.},
  publisher = {Society of Exploration Geophysicists},
  pages     = {4949--4953},
  month     =  sep,
  year      =  2013,
  url       = {http://dx.doi.org/10.1190/segam2013-0947.1},
  keywords  = {``4D; azimuth; rock physics; tensor''; traveltime},
  issn      = {1949-4645},
  doi       = {10.1190/segam2013-0947.1}
}

@inbook{Barkved_undated-hd,
author = {Olav I. Barkved and Tron Kristiansen and Erling Fjær},
title = {The 4D seismic response of a compacting reservoir—examples from the Valhall Field, Norway},
booktitle = {SEG Technical Program Expanded Abstracts 2005},
chapter = {},
pages = {2508-2511},
year = {2005},
doi = {10.1190/1.2148232},
URL = {https://library.seg.org/doi/abs/10.1190/1.2148232},
eprint = {https://library.seg.org/doi/pdf/10.1190/1.2148232}
}

@ARTICLE{Rickett2007-yo,
  title   = {{4D} time strain and the seismic signature of geomechanical
             compaction at Genesis},
  author  = {Rickett, James and Duranti, Luca and Ramon, San and Hudson, Usa
             Tom and Regel, Bernard and Orleans, New},
  journal = {Lead. Edge},
  volume  =  26,
  number  =  5,
  pages   = {644--647},
  month   =  may,
  year    =  2007,
  url     = {http://library.seg.org/doi/10.1190/1.2737103},
  issn    = {1070-485X},
  doi     = {10.1190/1.2737103}
}

@ARTICLE{Hawkins2007-xa,
  title    = {Production-induced stresses from time-lapse time shifts: A
              geomechanics case study from Franklin and Elgin fields},
  author   = {Hawkins, Keith and Howe, Sharon and Hollingworth, Steve and
              Conroy, Graham and Lotfi Ben-Brahim, U K and Tindle, Claire and
              Taylor, Neville and Joffroy, Gregory and Onaisi, Atef and Total,
              E and Aberdeen, P and K., U},
  abstract = {Franklin and Elgin fields were discovered in 1986 and 1991,
              respectively, within the U.K. North Sea Central Graben blocks
              22/30 and 29/5. The producing reservoirs are contained in the
              Jurassic Fulmar shallow-marine and Pentland fluvial formations at
              depths of 5100--5600 m subsea. The fields presented significant
              development challenges both in terms of seismic imaging
              complexity and being in a state of exceptionally high
              pressure/high temperature (HPHT). Addressing these challenges
              meant that production could not commence until 2001.},
  journal  = {Lead. Edge},
  volume   =  26,
  number   =  5,
  pages    = {655--662},
  month    =  may,
  year     =  2007,
  url      = {http://library.seg.org/doi/10.1190/1.2737105},
  issn     = {1070-485X},
  doi      = {10.1190/1.2737105}
}

@ARTICLE{Ebaid2008-id,
  title   = {First dual-vessel high-repeat {GoM} {4D} survey shows development
             options at Holstein Field},
  author  = {Ebaid, Hesham and Tura, Ali and Nasser, Mosab and Hatchell, Paul
             and Smit, Frans and Payne, Nigel and Herron, Don and Stanley,
             Darrell and Kaldy, John and Barousse, Chuck},
  journal = {Lead. Edge},
  volume  =  27,
  number  =  12,
  pages   = {1622--1625},
  month   =  dec,
  year    =  2008,
  url     = {http://library.seg.org/doi/10.1190/1.3036965},
  issn    = {1070-485X},
  doi     = {10.1190/1.3036965}
}

@ARTICLE{Hatchell2005-op,
  title    = {Measuring reservoir compaction using time-lapse timeshifts},
  author   = {Hatchell, P J and Bourne, S J and Netherlands., The},
  abstract = {Time-lapse timeshifts refer to the differences in two-way seismic
              travel times that are frequently observed in the analysis of
              time-lapse seismic surveys. One source of timeshifts originates
              inside the reservoir interval as a result of changes in the
              pore-fluid properties that alter the seismic velocity. Another is
              from changes in seismic velocity and layer thickness that occur
              both inside and outside of the reservoir as a result of reservoir
              compaction and stress and strain redistribution in the
              surrounding formations. Timeshifts induced by changes in fluid
              properties are always zero above the top reservoir reflection
              event and constant below the base of the reservoir. These
              fluidinduced timeshifts can be significant (for example, when gas
              is released as an oil passes through bubble point) and are
              routinely calculated using Gassmann or similar theories and are
              not the focus of this paper. The compaction-induced timeshifts
              have opposite gradients on the inside and outside of the
              reservoir. Within the reservoir, the reduction in layer thickness
              and the expected increase in seismic velocity will reduce the
              seismic travel time across these layers. Outside the reservoir,
              the decrease in reservoir thickness is exactly balanced by
              surface subsidence and rock expansion. The expanding overburden
              produces increased layer thickness and slower seismic velocities
              that increase the seismic travel times. Observations on real
              time-lapse seismic data over compacting reservoirs show that the
              positive timeshifts that accrue in the overburden are larger than
              the negative timeshifts that accrue inside the reservoir (the
              sign convention chosen is that positive timeshifts result when
              the seismic travel time increases). The amount of overburden
              elongation cannot exceed the amount of reservoir compaction. So
              if the change in velocity were simply proportional to the change
              in vertical strain, the reduction in travel time through the
              reservoir would exceed the increase in travel time though the
              overburden. The net effect would be a negative timeshift below
              the reservoir. Instead positive timeshifts are observed below
              compacting reservoir indicting velocity reduction per unit
              elongation strain significantly exceeds the velocity increase per
              unit contraction strain. Using simple models of the
              velocity-strain response it is shown that time-lapse timeshifts
              are proportional to the stretching of the overburden layers and
              that this is highly correlated with the reservoir compaction. The
              net result is that time-lapse timeshifts are a good measurement
              of the reservoir compaction.},
  journal  = {SEG/Houston 2005 Annual Meeting},
  pages    = {2500--2504},
  year     =  2005
}

@ARTICLE{Hatchell2005-eg,
  title   = {Rocks under strain: Strain-induced time-lapse time shifts are
             observed for depleting reservoirs},
  author  = {Hatchell, Paul and Bourne, Stephen and Netherlands, The},
  journal = {Lead. Edge},
  volume  =  24,
  number  =  12,
  pages   = {1222--1225},
  month   =  dec,
  year    =  2005,
  url     = {http://library.seg.org/doi/10.1190/1.2149624},
  issn    = {1070-485X},
  doi     = {10.1190/1.2149624}
}

@ARTICLE{Nickel2003-pb,
  title   = {New tools for {4D} seismic analysis in compacting reservoirs},
  author  = {Nickel, M and Schlaf, J and S{\o}nneland, L},
  journal = {Pet. Geosci.},
  volume  =  9,
  number  =  1,
  pages   = {53--59},
  month   =  jan,
  year    =  2003,
  url     = {http://pg.lyellcollection.org/cgi/doi/10.1144/1354-079302-540},
  issn    = {1354-0793},
  doi     = {10.1144/1354-079302-540}
}

@ARTICLE{Hawkins_undated-xd,
  title  = {Geomechanical stresses from {4D} timeshifts measured around the
            depleting Franklin and Elgin reservoirs},
  author = {Hawkins, Keith and Howe, Sharon and Hollingworth, Steve and Conroy,
            Graham and Ben-Brahim, Cggveritas Lotfi and Tindle, Claire and
            Taylor, Neville and Joffroy, Gregory and Onaisi, Atef and Total, E
            and Uk, P}
}

@ARTICLE{Herwanger_undated-qv,
  title  = {Predicting time-lapse stress effects in seismic data},
  author = {Herwanger, Jorg and Geco, Western and Steve Horne, U K and
            Instruments, Electromagnetic}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Rste2017-bz,
  title     = {Overburden {4D} time shifts --- Indicating undrained areas and
               fault transmissibility in the reservoir},
  author    = {R⊘ste, T and Ke, G},
  abstract  = {Abstract Production-induced geomechanical stress changes cause
               velocity changes in the overburden that might be detected as 4D
               seismic time shifts. The strength of the velocity changes
               depends on the degree of pressure changes and the elastic
               properties of the reservoir and overburden layers. Even small
               velocity changes (less than 1\%) might accumulate into
               detectable seismic time shifts at the top reservoir, since the
               overburden thickness typically ranges from one to several
               kilometers. Reservoir pressure changes inducing seismic time
               shifts are observed in the overburden of the Snorre, Heidrun,
               and Statfjord fields, all located on the Norwegian Continental
               Shelf. The strong correlation between overburden time shifts,
               geomechanics, and reservoir pressure changes is used to indicate
               undrained areas and transmissibility across faults, which is
               useful information for increased oil recovery, well planning,
               and reservoir model updating. 4D geomechanical models are built
               with input from simulated reservoir pressures. Geomechanical
               strain and velocity changes are linked through a ?dilation?
               factor, R. The Snorre, Heidrun, and Statfjord fields indicate an
               average R value of about 15 for the overburden, when combining
               modeled vertical strain with observed seismic time shifts.
               However, this study also shows strong vertical variation in R,
               implying that R might be layer dependent. For the Statfjord
               Field, seabed subsidence measurements from gravity and GPS
               monitoring are used to calibrate the geomechanical model. The
               Snorre Field results show that both reservoir pressure depletion
               and pressure buildup can be identified by the use of overburden
               time shifts. The properties of the reservoir formations and
               surrounding layers of the investigated fields are typical for
               many fields on the Norwegian Continental Shelf. This implies
               that pressure-induced time shifts might be expected for many
               producing fields, not only chalk or high-pressure,
               high-temperature reservoirs but also sandstone reservoirs close
               to hydrostatic pressure.},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  36,
  number    =  5,
  pages     = {423--430},
  month     =  may,
  year      =  2017,
  url       = {https://doi.org/10.1190/tle36050423.1},
  issn      = {1070-485X},
  doi       = {10.1190/tle36050423.1}
}

@INPROCEEDINGS{Hatchell2003-rd,
  title     = {Whole earth 4D: Reservoir monitoring geomechanics},
  booktitle = {73rd {SEG} Meeting, Dallas, {USA}, Expanded Abstracts},
  author    = {Hatchell, P J and Van Den Beukel, A and Molenaar, M M and Maron,
               K P and Kenter, C J and Stammeijer, Jgf and Van der Velde, J J
               and Sayers, C and {Others}},
  pages     = {1330--1333},
  year      =  2003
}


@ARTICLE{Janssen_undated-xw,
  title  = {Measuring velocity sensitivity to production-induced strain at the
            Ekosk Field using time-lapse time-shifts and compaction logs},
  author = {Janssen, Aaron L and Smith, Brackin A and Norway, Conoco Phillips}
}

@ARTICLE{Rau_Schiott2008-ux,
  title    = {Time-lapse inversion and geomechanical modelling of the South
              Arne field},
  author   = {Rau Schiott, C and Bertrand-Biran, V and Juhl Hansen, H and
              Koutsabeloulis, N and Westeng, K},
  abstract = {Time-lapse seismic technology is routinely used to monitor
              production-related reservoir changes. Indeed, the analysis of
              observed seismic 4D effects and estimation of the corresponding
              elastic attributes provide valuable information about the
              dynamics of the reservoir (saturation, pore pressure),
              particularly away from existing wells, into areas where
              production data is `blind.' However, the interpretation of
              time-lapse response can be complex as different reservoir
              property changes can lead to the same variation in a given
              elastic parameter. This is particularly true for chalk fields
              undergoing porosity reduction in addition to change in fluid and
              pore pressure depletion.},
  journal  = {First Break},
  volume   =  26,
  number   =  5,
  month    =  may,
  year     =  2008,
  url      = {http://earthdoc.eage.org/publication/download/?publication=27996},
  language = {en},
  issn     = {0263-5046, 1365-2397}
}

@ARTICLE{Lumley2001-kx,
  title     = {Time-lapse seismic reservoir monitoring},
  author    = {Lumley, David E},
  abstract  = {Time-lapse seismic reservoir monitoring has advanced rapidly
               over\textbackslashnthe past decade. There are currently about 75
               active projects worldwide,\textbackslashnand more than 100
               cumulative projects in the past decade or so.
               The\textbackslashnpresent total annual expenditures on 4-D
               seismic projects are on\textbackslashnthe order of 50-100
               million US. This currently represents a
               much\textbackslashnsmaller market than 3-D seismic, but the use
               of 4-D seismic has grown\textbackslashnexponentially over the
               past decade and is expected to continue to\textbackslashndo so.
               The major opportunity provided by 4-D seismic data is
               its\textbackslashnability to image fluid flow in the volumetric
               region not sampled\textbackslashnby wells. Fluid flow is thus
               directly imaged by 4-D seismic data,\textbackslashnfather than
               solely predicted by flow simulation. In contrast to
               3-D\textbackslashnseismic, which is an exploration and
               development tool, 4-D seismic\textbackslashnis quickly becoming
               a vital engineering reservoir management
               tool.\textbackslashnTime-lapse seismic images can identify
               bypassed oil to be targeted\textbackslashnfor infill drilling,
               and add major reserves to production to extend\textbackslashna
               field's economic life. 3-D seismic can monitor the progress
               of\textbackslashncostly injected fluid fronts (water, gas,
               steam, CO2, etc.) that\textbackslashncan save hundreds of
               millions of dollars in optimizing
               injection\textbackslashnprograms. 4-D seismic can map reservoir
               compartmentalization and\textbackslashnthe fluid-flow properties
               of faults (sealing versus leaking), which\textbackslashncan be
               extremely useful for optimal design of production
               facilities\textbackslashnand well paths in complex reservoir
               flow systems. Rock physics measurements\textbackslashnmade in
               the mid 1980 Stanford University predicted that thermal
               enhanced\textbackslashnoil recovery (EOR) processes, especially
               steam injection, should\textbackslashnbe visible in repeated
               surface seismic surveys. The first field tests\textbackslashnof
               the concept were conducted in the mid-late 1980s and early
               1990s\textbackslashnin Canada, the US, and Indonesia at several
               steam injection sites\textbackslashnand one fireflood site.
               These early projects showed conclusively\textbackslashnthat
               large anomalies related to steam and heated gas were
               indeed\textbackslashnstrikingly visible in time-lapse seismic
               data. This was followed\textbackslashnby projects to monitor
               isothermal gas-fluid movement, particularly\textbackslashnby
               early work in the North Sea and Paris basin. These gas
               monitoring\textbackslashnexperiments were also successful, but
               it became clearer that the\textbackslashninteraction of the
               reservoir rock, fluid, and gas components
               could\textbackslashnenhance or degrade the time-lapse seismic
               signal depending on specific\textbackslashnreservoir conditions.
               The past five years has seen an increased focus\textbackslashnon
               monitoring of oil-water systems. Here, the 4-D seismic
               technique\textbackslashnworks well in unconsolidated
               high-porosity sands with high gas-to-oil\textbackslashnratio
               (GOR) oil and salty brine, works moderately well in
               somewhat\textbackslashnconsolidated porous rocks with live oil,
               and is technically challenging\textbackslashnin applications
               involving dead oil or stiff rocks like
               carbonates\textbackslashnor cemented sandstones, independent of
               the rock's fluid content.\textbackslashnIt is now recognized
               that successful monitoring of fluid flow
               depends\textbackslashnon critical reservoir rock and fluid
               properties pressure and temperature\textbackslashnvalues, and
               high-fidelity seismic acquisition, processing, and
               interpretation.\textbackslashnMuch work has been done on
               feasibility risk analysis, and on
               modeling\textbackslashntime-lapse seismic data from 3-D
               heterogeneous reservoir models,\textbackslashnrock physics data,
               and flow simulation results. Acquisition and
               processing\textbackslashnservice companies continue to enhance
               repeatability and accuracy\textbackslashnof their field hardware
               and processing algorithms. Multicube
               quantitative\textbackslashninterpretation and inversion
               techniques for time-lapse seismic data\textbackslashnare
               evolving, especially in ways that integrate 3-D seismic
               data\textbackslashnwith other reservoir data types such as well
               logs, pressure, temperature\textbackslashnand saturation data,
               core measurements, flow simulations, and
               production\textbackslashndata. Current research and the road
               ahead involves ocean-bottom and\textbackslashnborehole seismic,
               permanent sensor installations, real-time
               reservoir\textbackslashnmonitoring instrumentation, sear waves,
               nonseismic techniques (such\textbackslashnas electromagnetics,
               gravity and radar), inversion for
               fluid-flow\textbackslashnproperties with uncertainty analysis,
               reservoir data integration,\textbackslashnseismic history
               matching and reservoir model updating.},
  journal   = {Geophysics},
  publisher = {Society of Exploration Geophysicists},
  volume    =  66,
  number    =  1,
  pages     = {50--53},
  month     =  jan,
  year      =  2001,
  url       = {http://library.seg.org/doi/abs/10.1190/1.1444921},
  keywords  = {geo; sound},
  issn      = {0016-8033},
  doi       = {10.1190/1.1444921}
}

@INCOLLECTION{Herwanger2010-uo,
  title     = {Applying time-lapse seismic methods to reservoir management and
               field development planning at South Arne, Danish North Sea |
               Petroleum {GeologyFrom} Mature Basins to New Frontiers --
               Proceedings of the 7th Petroleum Geology Conference |
               {GeoScienceWorld} Books | {GeoScienceWorld}},
  booktitle = {Petroleum Geology: From Mature Basins to New
               {Frontiers---Proceedings} of the 7th Petroleum Geology
               Conference},
  author    = {Herwanger, J V and Schi{\o}tt, C R and Frederiksen, R and If, F
               and Vejb{\ae}k, O V and Wold, R and Hansen, H J and Palmer, E
               and Koutsabeloulis, N},
  abstract  = {At South Arne a highly repeatable time-lapse seismic survey
               (normalized root-mean-square error or NRMS of less than 0.1)
               allowed us to reliably monitor reservoir production processes
               during five years of reservoir depletion. Time-lapse AVO
               (amplitude v. offset) inversion and rock-physics analysis
               enables accurate monitoring of fluid pathways. On the crest of
               the field, water injection results in a heterogeneous sweep of
               the reservoir, whereby the majority of the injected water
               intrudes into a highly porous body. This is in contrast to a
               pre-existing reservoir simulation model predicting a homogeneous
               sweep. On the SW flank, time-lapse AVO inversion to changes in
               water saturation DSw reveals that the drainage pattern is fault
               controlled. Time-lapse seismic data furthermore explain the lack
               of production from the far end of a horizontal producer (as
               observed by production logging), by showing that the injected
               water does not result in the expected pressure support. On the
               highly porous crest of the reservoir compaction occurs.
               Time-lapse time shifts in the overburden are used as a measure
               for compaction and are compared with predictions of reservoir
               compaction from reservoir geomechanical modelling. In areas
               where compaction observations and predictions disagree,
               time-lapse seismic data give the necessary insight to validate,
               calibrate and update the reservoir geomechanical model. The
               information contained in time-lapse seismic data can only be
               fully extracted and used when the reservoir simulation model,
               the reservoir geomechanical model and the time-lapse seismic
               inversion models are co-visualized and available in the same
               software application with one set of coordinates. This allows
               for easy and reliable investigation of reservoir depletion and
               gives deeper insight than using reservoir simulation or
               time-lapse seismic individually.},
  publisher = {Geological Society of London},
  pages     = {523--535},
  month     =  jan,
  year      =  2010,
  url       = {https://pubs.geoscienceworld.org/books/book/1918/chapter/107336670/},
  keywords  = {Avo inversion; Compaction; Petroleum geology and reservoir;
               Production; Reservoir geomechanics; Rock physics; Time-lapse
               seismic},
  doi       = {10.1144/0070523}
}

@MISC{Astratti2015-pc,
  title        = {Mapping and time-lapse analysis of South Arne Chalk fault
                  network using new developments in seismic dip computation |
                  Fundamental Controls on Fluid Flow in {CarbonatesCurrent}
                  Workflows to Emerging Technologies | {GeoScienceWorld} Books
                  | {GeoScienceWorld}},
  author       = {Astratti, D and Aarre, V and Vejb{\ae}k, O V and White, G},
  abstract     = {In a reservoir, faults at the limit of the seismic resolution
                  can be crucial to explain pro- duction history and to
                  optimize field development. However, in most cases the detail
                  required to describe such subtle features depends on the
                  assistance of seismic attributes and semi-automated
                  interpretation techniques. We generated a detailed
                  description of the fault network in the South Arne Chalk
                  Group using a workflow based on a globally consistent
                  computation of the seismic dip. This led to more accurate
                  seismic edge attributes than gained with standard dip
                  estimation techniques. We analysed each fault set and
                  qualitatively assessed its control on fluid flow. Our
                  investigation suggests that the two fracture sets that
                  influence production developed along the same WNW--ESE
                  structural trend and cannot be separated based on the seismic
                  data alone. These faults were active both during and post
                  Chalk deposition. We observe ENE--WSW linea- ments that match
                  the pattern of a time-lapse seismic amplitude anomaly
                  associated with water injection. It remains to be verified
                  whether these lineaments could be an extension of overburden
                  faults, as well as whether the increased intensity of the
                  fault network as seen on the 2005 v. the 1995 3D seismic
                  survey was caused by production effects. The},
  year         =  2015,
  url          = {https://pubs.geoscienceworld.org/books/book/1777/chapter/107678615/},
  howpublished = {\url{https://pubs.geoscienceworld.org/books/book/1777/chapter/107678615/}},
  note         = {Accessed: 2018-1-28},
  doi          = {10.1144/SP406.10}
}

@ARTICLE{Landro2004-yc,
  title     = {Quantitative estimation of compaction and velocity changes using
               {4D} impedance and traveltime changes},
  author    = {Landr{\o}, M and Stammeijer, J},
  abstract  = {In some hydrocarbon reservoirs, severe compaction of the
               reservoir rocks is observed. This compaction is caused by
               production, and it is often associated with changes in the
               overburden. Time?lapse (or 4D) seismic data are used to monitor
               this compaction process. Since the compaction causes changes in
               both layer thickness and seismic velocities, it is crucial to
               distinguish between the two effects.Two new seismic methods for
               monitoring compacting reservoirs are introduced, one based on
               measured seismic prestack traveltime changes, and the other
               based on poststack traveltime and amplitude changes. In contrast
               to earlier methods, these methods do not require additional
               empirical relationships, such as, for instance, a
               velocity?porosity relationship. The uncertainties in estimates
               for compaction and velocity change are expressed in terms of
               errors in the traveltime and amplitude measurements. These
               errors are directly related to the quality and repeatability of
               time?lapse seismic data. For a reservoir at 3000?m depth with 9
               m of compaction, and assuming a 4D timeshift error of 0.5 ms at
               near offset and 2 ms at far offset, we find relative uncertainty
               in the compaction estimate of approximately 50?60\% using
               traveltime information only.},
  journal   = {Geophysics},
  publisher = {Society of Exploration Geophysicists},
  volume    =  69,
  number    =  4,
  pages     = {949--957},
  month     =  jul,
  year      =  2004,
  url       = {https://doi.org/10.1190/1.1778238},
  issn      = {0016-8033},
  doi       = {10.1190/1.1778238}
}

@ARTICLE{Osdal2011-xg,
  title     = {Estimation of changes in water column velocities and thicknesses
               from time lapse seismic data},
  author    = {Osdal, B{\aa}rd and Landr{\o}, Martin},
  abstract  = {Sea-bed diffractions are frequently observed for several of the
               fields in the Norwegian Sea and the Barents Sea. This is a
               challenge in time lapse seismic analysis, since diffracted
               multiples are difficult to remove by processing and therefore is
               a major source of poor time lapse data quality. In this work we
               test if the diffractions can be used for enhanced 4D
               interpretation. By analysing the time-shift of the sea-bed
               diffraction hyperbola between the base and monitor it is tested
               if changes in water velocity and tides can be estimated. Two
               models using time lapse diffraction analysis are tested: the
               first one simply adds time-shifts for the two branches of the
               diffraction hyperbola and this average time-shift is then used
               to estimate the water velocity change. The other method uses an
               inversion method based on the diffraction equation for a point
               diffractor to estimate the velocity change. In-line
               common-midpoint shifts are estimated by subtracting the
               time-shifts of both hyperbola branches followed by direct
               inversion. The diffraction based time-shifts are compared to
               time-shifts estimated by standard cross-correlation of the
               sea-bed reflection. The averaging method gives slightly higher
               uncertainties, while the inversion using an exact traveltime
               equation gives similar uncertainties compared to the sea-bed
               reflection method.},
  journal   = {Geophys. Prospect.},
  publisher = {Blackwell Publishing Ltd},
  volume    =  59,
  number    =  2,
  pages     = {295--309},
  month     =  mar,
  year      =  2011,
  url       = {http://dx.doi.org/10.1111/j.1365-2478.2010.00923.x},
  keywords  = {Hyperbola; Sea-bed; Time-shift},
  issn      = {0016-8025, 1365-2478},
  doi       = {10.1111/j.1365-2478.2010.00923.x}
}

@ARTICLE{Landro2012-vq,
  title     = {Normal modes in seismic data --- Revisited},
  author    = {Landr{\o}, M and Hatchell, P},
  abstract  = {ABSTRACTAt long distances from a seismic shot, the recorded
               signal is dominated by reflections and refractions within the
               water layer. This guided wave signal is complex and often is
               referred to as normal or harmonic modes. From the period
               equation, we derive a new approximate expression for the local
               minima in group velocity versus frequency. We use two data sets
               as examples: one old experiment where the seismic signal is
               recorded at approximately 13 km offset and another example using
               life of field seismic data from the Valhall Field. We identify
               four and five normal modes for the two examples, respectively. A
               fair fit is observed between the estimated and modeled normal
               mode curves. Based on the period equation for normal modes, we
               derive a simple, approximate equation that relates the
               traveltime difference between various modes directly to the
               velocity of the second layer. Using this technique for offsets
               ranging from 6 to 10 km (in step of 1 km), we find consistent
               velocity values for the second layer. We think that this method
               can be extended to estimate shallow lateral velocity variations
               if the method is applied for the whole field. We find that the
               simple equations and approximations used here offer a nice tool
               for initial investigations and understanding of normal modes,
               although a multilayered method is needed for detailed analysis.
               A comparison of three vintages of estimated normal mode curves
               for the Valhall field example representing seabed locations
               shifted by 1 km indicates that minor shifts in group velocity
               minima for the various modes are detectable.},
  journal   = {Geophysics},
  publisher = {Society of Exploration Geophysicists},
  volume    =  77,
  number    =  4,
  pages     = {W27--W40},
  month     =  jun,
  year      =  2012,
  url       = {https://doi.org/10.1190/geo2011-0094.1},
  issn      = {0016-8033},
  doi       = {10.1190/geo2011-0094.1}
}

@ARTICLE{Landro2011-hw,
  title   = {Seismic monitoring of an old underground blowout -- 20 years later},
  author  = {Landr{\o}, M},
  journal = {First Break},
  volume  =  29,
  number  =  1791,
  year    =  2011,
  url     = {http://dx.doi.org/10.3997/1365-2397.2011017},
  issn    = {0263-5046},
  doi     = {10.3997/1365-2397.2011017}
}

@INCOLLECTION{Landro2015-mi,
  title     = {{4D} Seismic},
  booktitle = {Petroleum Geoscience},
  author    = {Landr{\o}, Martin},
  abstract  = {The term 4D seismic reflects that calendar time represents the
               fourth dimension. A more precise term is repeated seismic,
               because that is actually what is done: a seismic survey over a
               given area (oil/gas field) is repeated in order to monitor
               production changes. Time-lapse seismic is another term used for
               this. For some reason, the term 4D seismic is most common, and
               we will therefore use it here. It is important to note that if
               we repeat 2D surveys, it is still denoted 4D seismic according
               to this definition. Recent examples of such surveys are repeated
               2D lines acquired over the Troll gas province.},
  publisher = {Springer, Berlin, Heidelberg},
  pages     = {489--514},
  year      =  2015,
  url       = {https://link.springer.com/chapter/10.1007/978-3-642-34132-8_19},
  language  = {en},
  isbn      = {9783642341311, 9783642341328},
  doi       = {10.1007/978-3-642-34132-8\_19}
}

@ARTICLE{Landro1999-tf,
  title     = {Repeatability issues of {3-D} {VSP} data},
  author    = {Landr{\o}, M},
  abstract  = {Increased repeatability is recognized as one major issue for
               improving the time?lapse seismic technology as a reservoir
               management tool. A 3-D vertical seismic profiling (VSP) data
               set, acquired over a period of two days, is used to analyze how
               repeatable a permanent installed geophone array can be and how
               repeatability changes with inaccuracies in source positioning.
               It is found that for a frequency range between 3.5 and 50 Hz,
               the difference root?mean?square (rms) level between two recorded
               traces belonging to two different shots is about 8\%. This fact
               shows that there is a potential for acquiring very accurate
               time?lapse seismic data by using a permanently installed
               downhole geophone array. Repeatability variation with increasing
               shot separation distances is analyzed, showing a rapid decrease
               in repeatability as the accuracy of the positioning of the
               repeat survey decreases. Horizontal geophone components show
               approximately the same degree of repeatability compared to the
               vertical component, but horizontal geophone data is slightly
               more sensitive to positioning errors. The results show that
               repeated 3-D VSP surveys (preferably using permanently installed
               geophone arrays) might be an efficient tool for detailed and
               precise monitoring of fluid and pressure changes within a
               hydrocarbon reservoir.},
  journal   = {Geophysics},
  publisher = {Society of Exploration Geophysicists},
  volume    =  64,
  number    =  6,
  pages     = {1673--1679},
  month     =  nov,
  year      =  1999,
  url       = {https://doi.org/10.1190/1.1444671},
  issn      = {0016-8033},
  doi       = {10.1190/1.1444671}
}

@ARTICLE{Addis2017-rl,
  title     = {The geology of geomechanics: petroleum geomechanical engineering
               in field development planning},
  author    = {Addis, M A},
  abstract  = {Abstract The application of geomechanics to oil and gas field
               development leads to significant improvements in the economic
               performance of the asset. The geomechanical issues that affect
               field development start at the exploration stage and continue to
               affect appraisal and development decisions all the way through
               to field abandonment. Field developments now use improved static
               reservoir characterization, which includes both the mechanical
               properties of the field and the initial stress distribution over
               the field, along with numerical reservoir modelling to assess
               the dynamic stress evolution that accompanies oil and gas
               production, or fluid injection, into the
               reservoirs.Characterizing large volumes of rock in the
               subsurface for geomechanical analysis is accompanied by
               uncertainty resulting from the low core sampling rates of around
               1 part per trillion (ppt) for geomechanical properties and due
               to the remote geophysical and petrophysical techniques used to
               construct field models. However, some uncertainties also result
               from theoretical simplifications used to describe the
               geomechanical behaviour of the geology.This paper provides a
               brief overview of geomechanical engineering applied to petroleum
               field developments. Select case studies are used to highlight
               how detailed geological knowledge improves the geomechanical
               characterization and analysis of field developments. The first
               case study investigates the stress regimes present in active
               fault systems and re-evaluates the industry9s interpretation of
               Andersonian stress states of faulting. The second case study
               discusses how the stress magnitudes and, potentially, stress
               regimes can change as a result of production and pore pressure
               depletion in an oil or gas field. The last case study addresses
               the geomechanical characterization of reservoirs, showing how
               subtle changes in geological processes are manifested in
               significant variations in strength. The studies presented here
               illustrate how the timely application of petroleum geomechanical
               engineering can significantly enhance field development,
               including drilling performance, infill drilling, completion
               design, production and recovery.},
  journal   = {Geological Society, London, Special Publications},
  publisher = {Geological Society of London},
  volume    =  458,
  number    =  1,
  pages     = {7--29},
  month     =  jan,
  year      =  2017,
  url       = {http://sp.lyellcollection.org/content/458/1/7},
  language  = {en},
  issn      = {0305-8719, 2041-4927},
  doi       = {10.1144/SP458.7}
}

@BOOK{Sayers2010-pl,
  title  = {Geophysics Under Stress},
  author = {Sayers, Colin M},
  year   =  2010,
  url    = {http://dx.doi.org/10.1190/1.9781560802129},
  doi    = {10.1190/1.9781560802129}
}

@INPROCEEDINGS{Ouenes2004-gn,
  title     = {Seismically Driven Improved Fractured Reservoir Characterization},
  booktitle = {{SPE} International Petroleum Conference in Mexico},
  author    = {Ouenes, Ahmed and Zellou, Abdel M and Robinson, Gary and Balogh,
               Dave and Araktingi, Udo},
  year      =  2004,
  url       = {http://dx.doi.org/10.2118/92031-ms},
  doi       = {10.2118/92031-ms}
}

@ARTICLE{Nature_undated-sg,
  title  = {Seismic reflections come from interfaces where the acoustic
            properties of the rocks},
  author = {Nature, The}
}

@INPROCEEDINGS{Jin2012-dw,
  title     = {Workflows for Quantitative {4D} Seismic Data Integration: A Case
               Study},
  booktitle = {{IPTC} 2012: International Petroleum Technology Conference},
  author    = {Jin, Long and Tiller, Gottfried and Weber, Daniel and Fu,
               Shipeng and Ferrandis, Javier and van den Hoek, Paul and Pirmez,
               Carlos and Fehintola, Tope and Tendo, Fidelis and Olaniyan,
               Elozino},
  year      =  2012
}

@MISC{Landa2011-xj,
  title  = {Joint Inversion of {4D} Seismic and Production Data.pdf},
  author = {Landa, Kumar},
  year   =  2011
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Schiott2008-kz,
  title   = {Time‑lapse inversion and geomechanical modelling of the South Arne
             field},
  author  = {Schi{\o}tt, Christian Rau and Bertrand-Biran, Val{\'e}rie and
             Hansen, Henrik Juhl and Koutsabeloulis, Nick and Westeng, Kjetil},
  journal = {First Break},
  volume  =  26,
  year    =  2008,
  issn    = {0263-5046}
}

@ARTICLE{Sayers2006-og,
  title     = {Sensitivity of time-lapse seismic to reservoir stress path},
  author    = {Sayers, Colin M},
  journal   = {Geophys. Prospect.},
  publisher = {Blackwell Publishing Ltd},
  volume    =  54,
  number    =  5,
  pages     = {662--662},
  month     =  sep,
  year      =  2006,
  url       = {http://dx.doi.org/10.1111/j.1365-2478.2006.00560.x},
  issn      = {0016-8025, 1365-2478},
  doi       = {10.1111/j.1365-2478.2006.00560.x}
}

@ARTICLE{Pettersen_undated-ny,
  title  = {Time-lapse seismic inversion of data from a compacting chalk
            reservoir},
  author = {{pettersen}}
}

@INPROCEEDINGS{Byerley2006-rf,
  title     = {Reducing Risk and Monitoring Water Injection Using {Time-Lapse}
               (4D) Seismic at the Ekofisk Field},
  booktitle = {68th {EAGE} Conference and Exhibition incorporating {SPE}
               {EUROPEC} 2006},
  author    = {Byerley, G and Roervik, K O and Pedersen, J and Ranaweera, K},
  year      =  2006,
  url       = {http://dx.doi.org/10.3997/2214-4609.201402390},
  doi       = {10.3997/2214-4609.201402390}
}

@INPROCEEDINGS{Christensen2006-qz,
  title     = {Seismically Driven Reservoir Characterization Using an
               Innovative Integrated Approach: Syd Arne Field},
  booktitle = {{SPE} Annual Technical Conference and Exhibition},
  author    = {Christensen, Soren Amdi and Ebbe-Dalgaard, Tanja Jo and
               Rosendal, Anders and Christensen, Jesper Werner and Robinson,
               Gary Charles and Zellou, Abdel Mogheeth and Royer, Theodore},
  year      =  2006,
  url       = {http://dx.doi.org/10.2118/103282-ms},
  doi       = {10.2118/103282-ms}
}

@INPROCEEDINGS{J_Hatchell2006-cz,
  title     = {Measuring Reservoir Compaction Using {Time-Lapse} Timeshifts},
  booktitle = {68th {EAGE} Conference and Exhibition incorporating {SPE}
               {EUROPEC} 2006},
  author    = {J. Hatchell, P and Hatchell, P J and Bourne, S J},
  year      =  2006,
  url       = {http://dx.doi.org/10.3997/2214-4609.201402015},
  doi       = {10.3997/2214-4609.201402015}
}

@MISC{Barkved2005-ai,
  title  = {Seismic time-lapse effects and stress changes Examples from a
            compacting reservoir.pdf},
  author = {Barkved, Kristiansen},
  year   =  2005
}

@ARTICLE{Smith_undated-yz,
  title  = {Ekofisk {4D} Seismic - Influence on Flow Simulation and Compaction
            Modeling},
  author = {Smith, Brackin A and Sylte, James E and Clausen, Claus K and
            Norway, Phillips Petroleum Company and Guilbot, Jerome and Norge,
            Totalfina Elf Exploration}
}

@INPROCEEDINGS{Guilbot2002-pj,
  title     = {Interpretation tools and methods for chalk reservoir
               characterization},
  booktitle = {64th {EAGE} Conference \& Exhibition},
  author    = {Guilbot, J and Smith, B and Pirera, F},
  year      =  2002
}

@INPROCEEDINGS{Maao2000-pr,
  title     = {Prestack calibration of time-lapse seismic data},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2000},
  author    = {Maa{\o}, Frank and Sollie, Roger and Hokstad, Ketil},
  publisher = {Society of Exploration Geophysicists},
  pages     = {2150--2153},
  month     =  jan,
  year      =  2000,
  url       = {http://library.seg.org/doi/abs/10.1190/1.1815875},
  issn      = {1949-4645},
  doi       = {10.1190/1.1815875}
}

@INPROCEEDINGS{Lafet2009-lm,
  title     = {Global {4D} seismic inversion and time-lapse fluid
               classification},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2009},
  author    = {Lafet, Y and Roure, B and Doyen, P M and Buran, H},
  publisher = {Society of Exploration Geophysicists},
  pages     = {3830--3834},
  month     =  jan,
  year      =  2009,
  url       = {http://library.seg.org/doi/abs/10.1190/1.3255666},
  doi       = {10.1190/1.3255666}
}

@INPROCEEDINGS{Eidsvik2009-wz,
  title     = {Blocky inversion of time-lapse seismic {AVO} data},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2009},
  author    = {Eidsvik, Jo and Theune, Ulrich},
  publisher = {Society of Exploration Geophysicists},
  pages     = {3820--3824},
  month     =  jan,
  year      =  2009,
  url       = {http://library.seg.org/doi/abs/10.1190/1.3255664},
  doi       = {10.1190/1.3255664}
}

@INPROCEEDINGS{MacBeth2004-pj,
  title     = {Deconvolving permeability from time-lapsed seismic data},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2004},
  author    = {MacBeth, Colin},
  publisher = {Society of Exploration Geophysicists},
  pages     = {2291--2294},
  month     =  jan,
  year      =  2004,
  url       = {http://library.seg.org/doi/abs/10.1190/1.1843312},
  doi       = {10.1190/1.1843312}
}

@ARTICLE{Vanorio2010-qu,
  title   = {The rock physics basis for {4D} seismic monitoring of fate: Are we
             there yet?},
  author  = {Vanorio, Tiziana and Mavko, Gary and Vialle, Stephanie and Spratt,
             Kyle},
  journal = {Lead. Edge},
  volume  =  29,
  number  =  2,
  pages   = {156--162},
  month   =  feb,
  year    =  2010,
  url     = {http://library.seg.org/doi/abs/10.1190/1.3304818},
  issn    = {1070-485X},
  doi     = {10.1190/1.3304818}
}

@INCOLLECTION{Johnston2013-qg,
  title     = {6. Seismic Processing of {4D} Data},
  booktitle = {Practical Applications of Time-lapse Seismic Data},
  author    = {Johnston, David H},
  publisher = {Society of Exploration Geophysicists},
  pages     = {103--126},
  month     =  jan,
  year      =  2013,
  url       = {http://library.seg.org/doi/abs/10.1190/1.9781560803126.ch6},
  doi       = {10.1190/1.9781560803126.ch6}
}

@ARTICLE{Skjervheim2007-br,
  title   = {Incorporating {4D} seismic data in reservoir simulation models
             using ensemble Kalman filter},
  author  = {Skjervheim, J-A and Evensen, G and Aanonsen, S I and Ruud, B O and
             Johansen, T a},
  journal = {SPE Journal},
  volume  =  12,
  number  =  3,
  pages   = {282--292},
  year    =  2007,
  url     = {http://dx.doi.org/10.2118/95789-PA},
  issn    = {1086-055X},
  doi     = {10.2118/95789-PA}
}

@PHDTHESIS{Suman2013-vg,
  title  = {Joint Inversion of Production and Time-lapse Seismic data:
            Application to Norne Field},
  author = {Suman, Amit},
  year   =  2013,
  url    = {https://pangea.stanford.edu/researchgroups/scrf/resources/theses}
}

@ARTICLE{Arts2004-ym,
  title   = {Monitoring of {CO2} injected at Sleipner using time-lapse seismic
             data},
  author  = {Arts, R and Eiken, O and Chadwick, A and Zweigel, P and van der
             Meer, L and Zinszner, B},
  journal = {Energy},
  volume  =  29,
  number  = {9-10},
  pages   = {1383--1392},
  month   =  jul,
  year    =  2004,
  url     = {http://www.sciencedirect.com/science/article/pii/S0360544204001550},
  issn    = {0360-5442},
  doi     = {10.1016/j.energy.2004.03.072}
}

@ARTICLE{Brice2001-dl,
  title   = {Perturbations in {4D} marine seismic},
  author  = {Brice, Tim and Larsen, Leif and Morice, Steve and Svendsun, Morten},
  journal = {ASEG Extended Abstracts},
  volume  =  2001,
  number  =  1,
  pages   = {1},
  year    =  2001,
  url     = {http://www.publish.csiro.au/?paper=ASEG2001ab010},
  issn    = {2202-0586},
  doi     = {10.1071/ASEG2001ab010}
}

@ARTICLE{Batzle1992-gc,
  title    = {Seismic properties of pore fluids},
  author   = {Batzle, Michael and Wang, Zhijing\textbackslash},
  abstract = {Abstract Pore fluids strongly influence the seismic properties of
              rocks. The densities, bulk moduli, velocities, and viscosities of
              common pore fluids are usually oversimplified in geophysics. We
              use a combination of thermodynamic relationships, empirical
              trends, and ... \textbackslashn},
  journal  = {Geophysics},
  volume   =  57,
  number   =  11,
  pages    = {1396--1408},
  month    =  nov,
  year     =  1992,
  url      = {http://library.seg.org/doi/10.1190/1.1443207},
  issn     = {0016-8033},
  doi      = {10.1190/1.1443207}
}

@ARTICLE{Eastwood1994-xd,
  title   = {Seismic monitoring of steam-based recovery of bitumen},
  author  = {Eastwood, John and Lebel, Pierre and Dilay, Andrew and Blakeslee,
             Sam},
  journal = {Lead. Edge},
  volume  =  13,
  number  =  4,
  pages   = {242--251},
  month   =  apr,
  year    =  1994,
  url     = {http://library.seg.org/doi/abs/10.1190/1.1437015},
  issn    = {1070-485X},
  doi     = {10.1190/1.1437015}
}

@ARTICLE{Eastwood1993-bq,
  title   = {Temperature-dependent propagation of {P} - and - waves in Cold
             Lake oil sands: Comparison of theory and experiment},
  author  = {Eastwood, John},
  journal = {Geophysics},
  volume  =  58,
  number  =  6,
  pages   = {863--872},
  month   =  jun,
  year    =  1993,
  url     = {http://library.seg.org/doi/abs/10.1190/1.1443470},
  issn    = {0016-8033},
  doi     = {10.1190/1.1443470}
}

@ARTICLE{Landro1999-xs,
  title    = {The Gullfaks {4D} seismic study},
  author   = {Landro, M and Solheim, O a and Hilde, E and Ekren, B O and
              Stronen, L K},
  abstract = {A time lapse analysis was performed on two 3D seismic datasets
              (4D seismic) acquired over the northern part of the Gullfaks
              oilfield in the North Sea. The first survey was acquired in 1985,
              prior to the production start in 1986, a second survey was
              acquired in 1995, followed by a third in 1996. The drainage
              interpretations carried out by means of the repeated seismic
              datasets are in reasonable agreement with similar interpretations
              performed the traditional way by reservoir engineers, and have
              locally resulted in an improved understanding of drainage. The
              time lapse seismic data are routinely used in well planning
              projects on Gullfaks. In 1997, two wells were drilled into
              segments that, based on repeated seismic data, were interpreted
              to be undrained. Both wells encountered oil-filled reservoirs.
              Although these wells were not based on time lapse seismic alone,
              the wells served as a good test of the reservoir management
              potential associated with the 4D technology. Furthermore,
              waterfront movements predicted on the basis of time lapse seismic
              data are confirmed by well observations.},
  journal  = {Pet. Geosci.},
  volume   =  5,
  number   =  3,
  pages    = {213--226},
  month    =  aug,
  year     =  1999,
  url      = {http://pg.lyellcollection.org/cgi/doi/10.1144/petgeo.5.3.213},
  keywords = {production research; reservoir study; seismic data; time lapse
              three dimensional},
  issn     = {1354-0793},
  pmid     = {12103},
  doi      = {10.1144/petgeo.5.3.213}
}

@ARTICLE{Greaves1987-gj,
  title   = {Three-dimensional seismic monitoring of an enhanced oil recovery
             process},
  author  = {Greaves, Robert J and Fulp, Terrance J},
  journal = {Geophysics},
  volume  =  52,
  number  =  9,
  pages   = {1175--1187},
  month   =  sep,
  year    =  1987,
  url     = {http://library.seg.org/doi/abs/10.1190/1.1442381},
  issn    = {0016-8033},
  doi     = {10.1190/1.1442381}
}

@ARTICLE{Yin2015-ij,
  title    = {Enhancement of dynamic reservoir interpretation by correlating
              multiple {4D} seismic monitors to well behavior},
  author   = {Yin, Zhen and Ayzenberg, Milana and MacBeth, Colin and Feng, Tao
              and Chassagne, Romain},
  journal  = {Interpretation},
  volume   =  3,
  number   =  2,
  pages    = {SP35--SP52},
  month    =  may,
  year     =  2015,
  url      = {http://library.seg.org/doi/abs/10.1190/INT-2014-0194.1},
  keywords = {4D seismic; cl; interpretation; monitoring; production},
  issn     = {2324-8858},
  doi      = {10.1190/INT-2014-0194.1}
}

@ARTICLE{Fanchi2001-md,
  title   = {Time-lapse seismic monitoring in reservoir management},
  author  = {Fanchi, John R},
  journal = {Lead. Edge},
  volume  =  20,
  number  =  10,
  pages   = {1140--1147},
  month   =  oct,
  year    =  2001,
  url     = {http://library.seg.org/doi/abs/10.1190/1.1487246},
  issn    = {1070-485X},
  doi     = {10.1190/1.1487246}
}

@ARTICLE{Koster2000-aq,
  title   = {Time-lapse seismic surveys in the North Sea and their business
             impact},
  author  = {Koster, Klaas and Gabriels, Pieter and Hartung, Matthias and
             Verbeek, John and Deinum, Geurt and Staples, Rob},
  journal = {Lead. Edge},
  volume  =  19,
  number  =  3,
  pages   = {286--293},
  month   =  mar,
  year    =  2000,
  url     = {http://library.seg.org/doi/abs/10.1190/1.1438594},
  issn    = {1070-485X},
  doi     = {10.1190/1.1438594}
}

@ARTICLE{Huang2001-cu,
  title   = {Integrating time-lapse seismic with production data: A tool for
             reservoir engineering},
  author  = {Huang, Xuri},
  journal = {Lead. Edge},
  volume  =  20,
  number  =  10,
  pages   = {1148--1153},
  month   =  oct,
  year    =  2001,
  url     = {http://library.seg.org/doi/abs/10.1190/1.1487247},
  issn    = {1070-485X},
  doi     = {10.1190/1.1487247}
}

@ARTICLE{Landro2001-rz,
  title   = {Discrimination between pressure and fluid saturation changes from
             time-lapse seismic data},
  author  = {Landr{\o}, Martin},
  journal = {Geophysics},
  volume  =  66,
  number  =  3,
  pages   = {836--844},
  month   =  may,
  year    =  2001,
  url     = {http://library.seg.org/doi/abs/10.1190/1.1444973},
  issn    = {0016-8033},
  doi     = {10.1190/1.1444973}
}

@ARTICLE{Landro2003-nu,
  title    = {Discrimination between pressure and fluid saturation changes from
              marine multicomponent time-lapse seismic data},
  author   = {Landr{\o}, Martin and Veire, Helene Hafslund and Duffaut, Kenneth
              and Najjar, Nazih},
  abstract = {Explicit expressions for computing saturation- and
              pressure-related changes from time-lapse seismic data have been
              derived and tested on a real time-lapse seismic data set.
              Necessary input is near- and far-offset stacks for the baseline
              seismic survey and the repeat survey. The method has been tested
              successfully in a segment where pressure measurements in two
              wells verify a pore-pressure increase of 5 to 6 MPa between the
              baseline survey and the monitor survey. Estimated pressure
              changes using the proposed relationships fit very well with
              observations. Between the baseline and monitor seismic surveys,
              27\% of the estimated recoverable hydrocarbon reserves were
              produced from this segment. The estimated saturation changes also
              agree well with observed changes, apart from some areas in the
              water zone that are mapped as being exposed to saturation changes
              (which is unlikely). Saturation changes in other segments close
              to the original oil--water contact and the top reservoir
              interface are also estimated and confirmed by observations in
              various wells.},
  journal  = {Geophysics},
  volume   =  68,
  number   =  5,
  pages    = {1592--1599},
  month    =  sep,
  year     =  2003,
  url      = {http://library.seg.org/doi/abs/10.1190/1.1620633},
  issn     = {0016-8033},
  doi      = {10.1190/1.1620633}
}

@ARTICLE{Lumley1997-mn,
  title   = {Assessing the technical risk of a {4-D} seismic project},
  author  = {Lumley, David E and Behrens, Ronald a and Wang, Zhijing},
  journal = {Lead. Edge},
  volume  =  16,
  number  =  9,
  pages   = {1287--1292},
  month   =  sep,
  year    =  1997,
  url     = {http://library.seg.org/doi/abs/10.1190/1.1437784},
  issn    = {1070-485X},
  doi     = {10.1190/1.1437784}
}

@ARTICLE{Nguyen2015-sq,
  title    = {A review on time-lapse seismic data processing and interpretation},
  author   = {Nguyen, Phung K T and Nam, Myung Jin and Park, Chanho},
  journal  = {Geosci. J.},
  volume   =  19,
  number   =  2,
  pages    = {375--392},
  month    =  jun,
  year     =  2015,
  url      = {http://link.springer.com/10.1007/s12303-014-0054-2},
  keywords = {cross-equalization; rock physics models; time-lapse seismic
              interpretation; time-lapse seismic processing; xeq},
  issn     = {1226-4806},
  doi      = {10.1007/s12303-014-0054-2}
}

@ARTICLE{Olden2001-ll,
  title   = {Modeling combined fluid and stress change effects in the seismic
             response of a producing hydrocarbon reservoir},
  author  = {Olden, Peter and Corbett, Patrick and Westerman, Robin and
             Somerville, Jim and Smart, Brian and Koutsabeloulis, Nick},
  journal = {Lead. Edge},
  volume  =  20,
  number  =  10,
  pages   = {1154--1163},
  month   =  oct,
  year    =  2001,
  url     = {http://library.seg.org/doi/abs/10.1190/1.1486773},
  issn    = {1070-485X},
  doi     = {10.1190/1.1486773}
}

@ARTICLE{Rickett2001-nx,
  title   = {Cross-equalization data processing for time-lapse seismic
             reservoir monitoring: A case study from the Gulf of Mexico},
  author  = {Rickett, J E and Lumley, D[] E[]},
  journal = {Geophysics},
  volume  =  66,
  number  =  4,
  pages   = {1015--1025},
  month   =  jul,
  year    =  2001,
  url     = {http://library.seg.org/doi/abs/10.1190/1.1487049},
  issn    = {0016-8033},
  doi     = {10.1190/1.1487049}
}

@ARTICLE{Pennington2001-ls,
  title   = {Seismic time-lapse surprise at Teal South: That little neighbor
             reservoir is leaking!},
  author  = {Pennington, Wayne D and Acevedo, Horacio and Haataja, Joshua I and
             Minaeva, Anastasia},
  journal = {Lead. Edge},
  volume  =  20,
  number  =  10,
  pages   = {1172--1175},
  year    =  2001,
  url     = {http://library.seg.org/doi/abs/10.1190/1.1487249},
  issn    = {1070-485X},
  doi     = {10.1190/1.1487249}
}

@ARTICLE{Ross1996-ih,
  title   = {Inside the crossequalization black box},
  author  = {Ross, C P and Cunningham, G B and Weber, D P},
  journal = {Lead. Edge},
  volume  =  15,
  number  =  11,
  pages   = {1233--1240},
  month   =  nov,
  year    =  1996,
  url     = {http://www.nature.com/doifinder/10.1038/41441},
  issn    = {1070-485X},
  doi     = {10.1190/1.1437231}
}

@INPROCEEDINGS{Abreu2005-ii,
  title     = {Improving {4D} Seismic Data Interpretation using Geostatistical
               Filtering},
  booktitle = {9th International Congress of the Brazilian Geophysical Society
               \& {EXPOGEF}, Salvador, Bahia, Brazil, 11-14 September 2005},
  author    = {Abreu, Carlos Eduardo and Lucet, Nathalie and Nivlet, Philippe
               and Royer, Jean-Jacques},
  publisher = {Society of Exploration Geophysicists and Brazilian Geophysical
               Society},
  pages     = {1249--1251},
  month     =  sep,
  year      =  2005,
  url       = {http://library.seg.org/doi/10.1190/sbgf2005-248},
  doi       = {10.1190/sbgf2005-248}
}

@INPROCEEDINGS{Formento2007-qs,
  title     = {{4D} Seismic Modeling Workflow Over the Marlim Field},
  booktitle = {10th International Congress of the Brazilian Geophysical Society
               \& {EXPOGEF} 2007, Rio de Janeiro, Brazil, 19-23 November 2007},
  author    = {Formento, Jean-Luc and dos Santos, Marcos Sebastiao and
               Sansonovski, Rui Cesar and Ribeiro Junior, Nier Maciel Da Silva
               and Vasquez, Guilherme Fernandes},
  publisher = {Society of Exploration Geophysicists and Brazilian Geophysical
               Society},
  pages     = {2388--2392},
  month     =  nov,
  year      =  2007,
  url       = {http://library.seg.org/doi/abs/10.1190/sbgf2007-473},
  doi       = {10.1190/sbgf2007-473}
}

@ARTICLE{Vasquez2009-is,
  title   = {Some Lapses of {Time-Lapse} Feasibility and Interpretation Studies},
  author  = {Vasquez, Guilherme and Vargas, Eur{\'\i}pedes and dos Santos,
             Marcos and de Carvalho, Marim{\^o}nica and Justen, Julio and
             Morschbacher, Marcio and de Abreu, Carlos and Sansonowski, Rui and
             Formento, Jean Luc},
  journal = {11th International Congress of the Brazilian Geophysical Society
             \& EXPOGEF 2009, Salvador, Bahia, Brazil, 24-28 August 2009},
  volume  =  3,
  pages   = {1675--1680},
  year    =  2009,
  url     = {http://library.seg.org/doi/abs/10.1190/sbgf2009-352},
  doi     = {10.1190/sbgf2009-352}
}

@INPROCEEDINGS{Ayeni2012-xv,
  title     = {Time-lapse seismic imaging by linearized joint inversion - A
               Valhall Field case study},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2012},
  author    = {Ayeni, Gboyega and Biondi, Biondo},
  publisher = {Society of Exploration Geophysicists},
  pages     = {1--6},
  month     =  sep,
  year      =  2012,
  url       = {http://library.seg.org/doi/abs/10.1190/segam2012-0903.1},
  keywords  = {4D; acquisition; inversion; least squares; monitor},
  doi       = {10.1190/segam2012-0903.1}
}

@INPROCEEDINGS{Libin2014-ac,
  title     = {Repeatability analysis and reconstruction of towed streamer {4D}
               seismic data},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2014},
  author    = {Libin*, Zhang and Zhen, Zou and Sheng, Cao and Yun, Ling and
               Tao, Wu},
  publisher = {Society of Exploration Geophysicists},
  pages     = {4930--4934},
  month     =  aug,
  year      =  2014,
  url       = {http://library.seg.org/doi/abs/10.1190/segam2014-0731.1},
  keywords  = {4D; acquisition; marine},
  doi       = {10.1190/segam2014-0731.1}
}

@ARTICLE{Talley1998-gh,
  title   = {Dynamic reservoir characterization of Vacuum Field},
  author  = {Talley, Daniel J and Davis, Thomas L and Benson, Robert D and
             Roche, Steven L},
  journal = {Lead. Edge},
  volume  =  17,
  number  =  10,
  pages   = {1396},
  year    =  1998,
  url     = {http://dx.doi.org/10.1190/1.1437858},
  issn    = {1070-485X},
  doi     = {10.1190/1.1437858}
}

@ARTICLE{Veire2007-ri,
  title   = {Stochastic inversion of pressure and saturation changes from
             time-lapse multi component data},
  author  = {Veire, Helene Hafslund and Borgos, Hilde Grude and Landr{\o},
             Martin},
  journal = {Geophys. Prospect.},
  volume  =  55,
  number  =  6,
  pages   = {805--818},
  month   =  nov,
  year    =  2007,
  url     = {http://doi.wiley.com/10.1111/j.1365-2478.2007.00651.x},
  issn    = {0016-8025},
  doi     = {10.1111/j.1365-2478.2007.00651.x}
}

@ARTICLE{Wang1997-yx,
  title   = {Feasibility of time-lapse seismic reservoir monitoring: The
             physical basis},
  author  = {Wang, Zhijing},
  journal = {Lead. Edge},
  volume  =  16,
  number  =  9,
  pages   = {1327--1330},
  month   =  sep,
  year    =  1997,
  url     = {http://library.seg.org/doi/abs/10.1190/1.1437796},
  issn    = {1070-485X},
  pmid    = {15003161},
  doi     = {10.1190/1.1437796}
}

@ARTICLE{Wang1998-ci,
  title   = {Seismic monitoring of a {CO} 2 flood in a carbonate reservoir: A
             rock physics study},
  author  = {Wang, Zhijing and Cates, Michael E and Langan, Robert T},
  journal = {Geophysics},
  volume  =  63,
  number  =  5,
  pages   = {1604--1617},
  month   =  sep,
  year    =  1998,
  url     = {http://library.seg.org/doi/abs/10.1190/1.1444457},
  issn    = {0016-8033},
  doi     = {10.1190/1.1444457}
}

@INPROCEEDINGS{Eiken2005-ma,
  title     = {Repeatability issues of time-lapse marine seismic data},
  booktitle = {9th International Congress of the Brazilian Geophysical Society
               \& {EXPOGEF}, Salvador, Bahia, Brazil, 11-14 September 2005},
  author    = {Eiken, Ola},
  publisher = {Society of Exploration Geophysicists and Brazilian Geophysical
               Society},
  pages     = {1267--1272},
  month     =  sep,
  year      =  2005,
  url       = {http://library.seg.org/doi/10.1190/sbgf2005-251},
  doi       = {10.1190/sbgf2005-251}
}

@INPROCEEDINGS{Eiken2000-zg,
  title     = {Seismic monitoring of {CO} 2 injected into a marine acquifer},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2000},
  author    = {Eiken, O and Brevik, I and Arts, R and Lindeberg, E and
               Fagervik, K},
  publisher = {Society of Exploration Geophysicists},
  pages     = {1623--1626},
  month     =  jan,
  year      =  2000,
  url       = {http://library.seg.org/doi/pdf/10.1190/1.1815725},
  issn      = {1949-4645},
  doi       = {10.1190/1.1815725}
}

@ARTICLE{Eiken2005-iu,
  title    = {Sensitivity of time-lapse seismic data to pore pressure changes:
              Is quantification possible?},
  author   = {Eiken, Ola and T{\o}ndel, Richard},
  abstract = {Time-lapse seismic data have contributed to increased reservoir
              knowledge and improved hydrocarbon recovery, mainly by monitoring
              changes in fluid saturation. Seismic signatures of pore pressure
              changes have been less commonly reported, although some
              observations, such as large depletion (Magnus Field) and
              secondary effects such as associated gas-out-of-solution
              (Shiehallion Field) and geomechanical effects in the reservoir
              and overburden (Ekofisk, Valhall, and HTHP fields), have been
              made. Quantification of the pore pressure changes from seismic
              data has rarely been performed to date.},
  journal  = {Lead. Edge},
  volume   =  24,
  number   =  12,
  pages    = {1250--1254},
  month    =  dec,
  year     =  2005,
  url      = {http://library.seg.org/doi/abs/10.1190/1.2149638},
  issn     = {1070-485X},
  doi      = {10.1190/1.2149638}
}

@ARTICLE{Eiken2003-yn,
  title    = {A proven method for acquiring highly repeatable towed streamer
              seismic data},
  author   = {Eiken, Ola and Haugen, Geir Ultveit and Schonewille, Michel and
              Duijndam, Adri},
  abstract = {Seismic reservoir monitoring has become an important tool in the
              management of many fields. Monitoring subtle changes in the
              seismic properties of a reservoir caused by production places
              strong demands on seismic repeatability. A lack of repeatability
              limits how frequently reservoir changes can be monitored or the
              applicability of seismic monitoring at all. In this paper we show
              that towing many streamers with narrow separation, combined with
              cross-line interpolation of data onto predefined sail lines, can
              give highly repeatable marine seismic data. Results from two
              controlled zero time lag monitoring experiments in the North Sea
              demonstrate high sensitivity to changing water level and
              variations in lateral positions. After corrections by
              deterministic tidal time shifts and spatial interpolation of the
              irregularly sampled streamer data, relative rms difference
              amplitude levels are as low as 12\% for a deep, structurally
              complex field and as low as 6\% for a shallow, structurally
              simple field. Reducing the degree of nonrepeatability to as low
              as 6\% to 12\% allows monitoring of smaller reflectivity changes.
              In terms of reservoir management this has three important
              benefits: (1) reservoirs with small seismic changes resulting
              from production can be monitored, (2) reservoirs with large
              seismic changes can be monitored more frequently, and (3)
              monitoring data can be used more quantitatively.},
  journal  = {Geophysics},
  volume   =  68,
  number   =  4,
  pages    = {1303--1309},
  month    =  jul,
  year     =  2003,
  url      = {http://library.seg.org/doi/abs/10.1190/1.1598123},
  issn     = {0016-8033},
  doi      = {10.1190/1.1598123}
}

@INPROCEEDINGS{Arts2007-ng,
  title     = {Synthetic versus real time-lapse seismic data at the Sleipner
               {CO2} injection site},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2007},
  author    = {Arts, R J and Chadwick, R A and Eiken, O and Trani, M and
               Dortland, S},
  publisher = {Society of Exploration Geophysicists},
  pages     = {2974--2978},
  month     =  jan,
  year      =  2007,
  url       = {http://library.seg.org/doi/abs/10.1190/1.2793089},
  keywords  = {finite difference; monitoring; seismic; time-lapse},
  doi       = {10.1190/1.2793089}
}

@BOOK{Yilmaz2003-hp,
  title     = {Seismic data analysis : processing, inversion, and
               interpretation of seismic data},
  author    = {Yilmaz, {\"O}zdo{\u g}an},
  publisher = {Society of Exploration Geophysicists},
  month     =  mar,
  year      =  2003,
  url       = {https://market.android.com/details?id=book-kYeioAEACAAJ},
  language  = {en},
  isbn      = {9781560800941},
  doi       = {10.1190/1.9781560801580}
}

@ARTICLE{Pennington2001-cl,
  title     = {Reservoir geophysics},
  author    = {Pennington, W},
  abstract  = {The concept of petroleum reservoir geophysics is relatively new.
               In the past, the role of geophysics was largely confined to
               exploration and, to a lesser degree, the development of
               discoveries. As cost?efficiency has taken over as a driving
               force in the economics of the oil and gas industry and as major
               assets near abandonment, geophysics has increasingly been
               recognized as a tool for improving the bottom line closer to the
               wellhead. The reliability of geophysical surveys, particularly
               seismic, has greatly reduced the risk associated with drilling
               wells in existing fields, and the ability to add geophysical
               constraints to statistical models has provided a mechanism for
               directly delivering geophysical results to the reservoir
               engineer.},
  journal   = {Geophysics},
  publisher = {Society of Exploration Geophysicists},
  volume    =  66,
  number    =  1,
  pages     = {25--30},
  month     =  jan,
  year      =  2001,
  url       = {https://doi.org/10.1190/1.1444903},
  issn      = {0016-8033},
  doi       = {10.1190/1.1444903}
}

@ARTICLE{Pennington1997-xk,
  title     = {Seismic petrophysics: An applied science for reservoir
               geophysics},
  author    = {Pennington, W},
  abstract  = {Modern computational power and processing schemes have liberated
               reflection seismology from its primary purpose, structural
               mapping. It is now fairly routine to produce a number of seismic
               attributes, using either prestack or poststack data, or even
               both in combination. With these attributes, the geophysical
               interpreter can now make maps and look for
               geologically?meaningful trends in the data?or correlate them
               with well observations and use them in geostatistical models?or
               perhaps try to use them directly to solve for the rock types and
               fluids in a deterministic manner.},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  16,
  number    =  3,
  pages     = {241--246},
  month     =  mar,
  year      =  1997,
  url       = {https://doi.org/10.1190/1.1437608},
  issn      = {1070-485X},
  doi       = {10.1190/1.1437608}
}

@ARTICLE{Smith2011-jf,
  title     = {Practical seismic petrophysics: The effective use of log data
               for seismic analysis},
  author    = {Smith, T},
  abstract  = {A quick scan of the SEG web site shows that the phrase ?seismic
               petrophysics? has been used explicitly in the title of a paper
               or abstract six times, the earliest of which was by Williams et
               al. in 1996 (?The Hugoton cross-well survey; A direct look at
               stratigraphy, seismic petrophysics and shale anisotropy?).
               However, the first attempt at a definition and an expanded
               description of ?seismic petrophysics? was published by Wayne
               Pennington in The Leading Edge in 1997 (?Seismic petrophysics:
               An applied science for reservoir geophysics?). He defines
               seismic petrophysics as follows: ??the purposeful application of
               rock physics theory, as calibrated by laboratory and well
               measurements, to the interpretation of seismic data??},
  journal   = {Lead. Edge},
  publisher = {Society of Exploration Geophysicists},
  volume    =  30,
  number    =  10,
  pages     = {1128--1141},
  month     =  oct,
  year      =  2011,
  url       = {https://doi.org/10.1190/1.3657071},
  issn      = {1070-485X},
  doi       = {10.1190/1.3657071}
}

@INPROCEEDINGS{Dorn-Lopez2005-iv,
  title     = {Dan Field {Time-Lapse} Seismic (4D) , Case History of an early
               Field Trial},
  booktitle = {67th European Association of Geoscientists and Engineers, {EAGE}
               Conference and Exhibition, incorporating {SPE} {EUROPE2005} -
               Extended Abstracts},
  author    = {Dorn-Lopez, D},
  abstract  = {This paper documents a field test of time-lapse (4D) seismic
               covering part of the Dan Field in the Danish North Sea. Results
               indicate seismic detection of production-related changes in
               chalk reservoirs is possible. Modelling studies for time-lapse
               feasibility had been ongoing in these reservoirs since 1992, but
               without convincing evidence that field trials would be
               successful. Early studies considering the effects of fluid
               saturation changes in the reservoir concluded that the magnitude
               of changes in the seismic response might be below the minimum
               needed for detectability. The opportunity for a field test of
               the method occurred when seismic data acquired in 2000 repeated
               coverage over part of the Dan Field. The original 3D seismic
               survey covering the field was acquired in 1988. The 4D seismic
               field test was thus an attempt to see whether the changes to the
               reservoir that had occurred over a period of twelve years could
               be detected by time-lapse studies and whether this information
               could be exploited. An initial post-stack comparison of the two
               surveys performed in 2001 identified a number of changes that
               correlated with known water injection perforation locations in
               the Dan B-Block. A detailed modelling study was then conducted
               to determine if production and injection activities would cause
               a detectable change in seismic response and to predict the
               magnitude of that response. Modelling results indicated that the
               changes in reservoir conditions would impart an acoustic
               impedance difference in the range of 5-50 percent, which is
               considered to be above the detection threshold.},
  year      =  2005
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Rickett1998-ed,
  title     = {A cross‐equalization processing flow for off‐the‐shelf {4D}
               seismic data},
  booktitle = {{SEG} Technical Program Expanded Abstracts 1998},
  author    = {Rickett, James and Lumley, David E},
  publisher = {Society of Exploration Geophysicists},
  pages     = {16--19},
  month     =  jan,
  year      =  1998,
  url       = {http://library.seg.org/doi/abs/10.1190/1.1820252},
  doi       = {10.1190/1.1820252}
}

@INPROCEEDINGS{Micksch2014-av,
  title     = {Integrated {4D} Inversion Approach in Danish Chalk Fields},
  booktitle = {76th {EAGE} Conference and Exhibition 2014},
  author    = {Micksch, U and Herbert, I H and Cherrett, A J and Roende, H and
               Calvert, M A and Zaske, J},
  abstract  = {This paper presents an integrated 4D inversion approach applied
               in a two vintage regional and multivintage field specific 4D
               processing project during 2013. The most recent regional monitor
               survey was recorded in 2012. At first we give an overview of the
               area and available data volumes and introduce a chalk rock
               physics model to show which 4D changes are to be expected. The
               4D inversion workflow is based around a deterministic
               geostatistical inversion scheme. A time strain inversion is used
               to obtain a time aligned monitor survey and aligned differences
               between the 4D processed vintages. In addition, the time strain
               information is used as prior model information when inverting
               for 4D impedance changes. Legacy data volumes used in earlier 4D
               projects were re-inverted with the same deterministic
               geostatistical inversion algorithm for comparison with the 2013
               reprocessed datasets. Altogether thirty main inversion projects
               were executed within 14 months. We compare inversion results for
               several processing outputs and also compare adjacent fields. The
               quick turnaround made possible by the fast inversion software
               allows the asset teams very early on to interpret and include
               these data into the daily workflow, well planning or well
               interventions.},
  publisher = {EAGE},
  year      =  2014,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=75628},
  address   = {Amsterdam}
}

@INPROCEEDINGS{Rod2005-ae,
  title     = {Injection Fracturing in a Densely Spaced Line Drive Waterflood -
               The Halfdan Example},
  booktitle = {{SPE} {Europec/EAGE} Annual Conference},
  author    = {Rod, Malene Holm},
  abstract  = {Induced fractures are actively steered along horizontal water
               injection wells in a densely spaced line drive water flood, thus
               ensuring efficient sweep and minimising random connections
               between parallel producer and injector wells. Due consideration
               of flow-induced changes to the stress field reduces the risk of
               premature water breakthrough during injection at fracturing
               conditions. The paper differs from other works concerning
               flow-induced stresses by focussing on the application of this
               phenomenon and the practical experiences from a field-wide
               implementation. A technique, named ``Fracture Aligned Sweep
               Technology'' (FAST), has been implemented on the Halfdan chalk
               field in the Danish North Sea with horizontal wells drilled at
               600 ft lateral spacing in a parallel pattern of alternating
               producers and water injectors with 10,000 to 15,000 ft long
               reservoir sections. Fracturing of the injector wells is the key
               to the process of voidage replacement, due to the low mobility
               of water compared to oil and gas. FAST uses the fact that fluid
               flow in rock of low permeability affects reservoir stresses.
               Before propagating a fracture, the prevailing pressure field is
               manipulated through a period of injection below fracture
               propagation pressure and simultaneous production from the
               neighbouring wells. Numerical simulation of fracture propagation
               shows that seepage forces strongly influence the propagation
               direction when an injection fracture propagates in a laterally
               varying pressure field. At slow propagation rates the pressure
               diffusion from the fracture itself causes alignment of the
               fracture with the injection well, i.e. the technique works
               because the injection rates are actively controlled. Confinement
               of injection fractures along horizontal injector wells is
               verified by production data from areas where FAST has been
               implemented. After 2-3 years of injection, water breakthrough to
               the neighbouring producers has not occurred. A positive
               production response to the high rate injection is demonstrated
               by increasing oil rate and decreasing gas-oil ratio.},
  publisher = {Society of Petroleum Engineers},
  month     =  apr,
  year      =  2005,
  url       = {http://www.onepetro.org/doi/10.2118/94049-MS},
  isbn      = {9789073781986},
  doi       = {10.2118/94049-MS}
}

@INPROCEEDINGS{Geiss2002-bz,
  title     = {Using Flow Induced Stresses for Steering of Injection Fractures},
  booktitle = {{SPE/ISRM} Rock Mechanics Conference},
  author    = {Geiss, Roy H and Rice, Katherine P and Keller, Robert R and
               J{\o}rgensen, Ole},
  abstract  = {Both horizontal and vertical rock stress magnitudes are
               substantially affected by pore pressure gradients generated by
               production from and water injection into low permeable chalk
               fields. This is confirmed by solid mechanics stress analyses and
               by observing fracture propagation in developed fields. Stress
               changes generated around horizontal injectors placed centrally
               between two parallel horizontal producers are considered in
               detail in this paper. It is shown that overburden and sideburden
               stresses may be altered and controlled to confine propagation of
               fracturing along the length of a central openhole horizontal
               injection well. It thereby becomes possible to establish a line
               drive development based on injection of water at fracturing
               conditions at reduced risk of premature water breakthrough
               (patent pending).},
  publisher = {Society of Petroleum Engineers},
  month     =  apr,
  year      =  2002,
  url       = {http://journals.cambridge.org/abstract_S1551929513000503},
  doi       = {10.2118/78220-MS}
}

@INPROCEEDINGS{Calvert2013-qf,
  title     = {Quick Impact of New {4D} over the Halfdan Field, Danish North
               Sea},
  booktitle = {75th {EAGE} Conference \& Exhibition incorporating {SPE}
               {EUROPEC} 2013 London, {UK}, 10-13 June 2013},
  author    = {Calvert, M A and Roende, H H and Herbert, I H and Zaske, J},
  volume    =  11,
  pages     = {10--13},
  year      =  2013,
  url       = {http://www.earthdoc.org/publication/publicationdetails/?publication=68643},
  doi       = {10.3997/2214-4609.20130852}
}

@ARTICLE{Calvert2014-qg,
  title    = {The impact of a quick {4D} seismic survey and processing over the
              Halfdan Field, Danish North Sea},
  author   = {Calvert, M A and Roende, H H and Herbert, I H and Za, J and
              Hickman, P and Micksch, U},
  abstract = {The quick turnaround of seismic processing of a 4D time lapse
              survey over the Halfdan oil field allowed for interpretation and
              integration of the new 4D results seven weeks after completion of
              the seismic acquisition. Analysis of the first fast track 4D
              dataset led to improved processing parameters and an additional
              demultiple application which yielded a significantly improved
              fast track dataset 11 weeks after the seismic acquisition was
              completed. The repeat 4D seismic survey was acquired in the
              summer of 2012 in order to provide a better understanding of the
              sweep efficiency from the line drive water flood, guide future
              well interventions and improve the reservoir model. The baseline
              3D seismic data was acquired in 1992/1993, prior to field
              development, and the first monitor 3D seismic was acquired in
              2005. The rock physics model shows that increased water
              saturation due to the water flooding along the injectors in the
              Tor oil-bearing reservoir dominates the 4D change in acoustic
              impedance yielding a hardening response. The rock physics model
              was used to convert the reservoir model pressure and saturation
              changes from the three time-steps to modelled acoustic impedance
              changes. Examples will be shown from the 4D time lapse and the
              reservoir model acoustic impedance changes.},
  journal  = {First Break},
  volume   =  32,
  number   =  2017,
  pages    = {43--50},
  month    =  apr,
  year     =  2014,
  url      = {http://fb.eage.org/publication/content?id=74379},
  issn     = {0263-5046, 1365-2397},
  doi      = {10.3997/1365-2397.2014003}
}

@INPROCEEDINGS{Poulsen2012-yz,
  title     = {Characterization of Direct Fractures Using Real Time Offshore
               Analysis of Deuterium Tracer Technology},
  booktitle = {{SPE} {Europec/EAGE} Annual Conference},
  author    = {Poulsen, Allan Korsgaard and Lafond, Kim Bousquet and Voight,
               Niels and Lundgaard, Thomas and Pedersen, Lars Malcolm},
  publisher = {Society of Petroleum Engineers},
  pages     = {4--7},
  month     =  apr,
  year      =  2012,
  url       = {http://www.onepetro.org/doi/10.2118/154878-MS},
  doi       = {10.2118/154878-MS}
}

@INPROCEEDINGS{Lafond2010-nc,
  title     = {{FAST} Optimization of {Line-Drive} Water Injection},
  booktitle = {{SPE} {EUROPEC/EAGE} Annual Conference and Exhibition},
  author    = {Lafond, Kim and Pedersen, Lars Malcolm and Christiansen, Lars Bo},
  publisher = {Society of Petroleum Engineers},
  pages     = {1--16},
  month     =  apr,
  year      =  2010,
  url       = {http://www.onepetro.org/doi/10.2118/130471-MS},
  doi       = {10.2118/130471-MS}
}

@ARTICLE{Dorn-Lopez2005-lk,
  title     = {Modeling seismic response of Danish chalk reservoirs to changes
               induced by production},
  author    = {Dorn-L{\'o}pez, D and S{\o}rensen, A and Mavko, G and Fabricius,
               Ida Lykke and Hedegaard, K},
  abstract  = {This paper documents a modeling study detailing some predicted
               seismic signatures of production-related changes in chalk
               reservoirs of the Danish North Sea. Our objective was to provide
               a rock physics analysis as a gateway to understanding the
               seismic signatures of porosity, compaction, pore fluids,
               pressure, temperature and induced fractures, with particular
               application to time-lapse seismic. The study was performed in
               steps, including: 1) laboratory measurements of compressional
               and shear velocity, porosity, texture and mineralogy on core
               plugs, 2) analysis of core and log data in order to build an
               elastic model relating the parameters, 3) specification of
               physical parameters associated with various production
               scenarios, 4) modeling the seismic signatures that would result
               from hydrocarbon production, differential compaction and water
               injection. Results of the study indicate that the elastic model
               built for the chalk reservoirs is consistent at the core plug,
               electric log, and seismic scales, and can be applied to the
               entire geographic area from the Gorm, Kraka, Dan and Halfdan
               reservoirs, and possibly to other chalk reservoirs within the
               North Sea. Changes to the rock properties induced by production
               of hydrocarbons and/or injection of water can be expected to
               produce measurable and visible changes to the seismic data
               recorded at the surface. Seismic changes can be differences in
               reflection amplitude, AVO intercept and gradient changes, or
               differences in travel time. For the scenarios modeled, the
               greatest differences in seismic response occur during compaction
               of the reservoir and resulting subsidence of the overburden.
               This gives about 50 pet. change in RMS amplitude of the
               reflection from the top and base of the reservoir, and also a
               measurable change in travel time. Other effects modeled (e.g.
               water injection, movement of the OWC or the GOC) result in
               changes from 8-15 pet. in seismic amplitudes, many of which
               should be observable on a repeated surface seismic survey. This
               study, therefore, supports the idea that time-lapse seismic
               surveys may provide useful information for infill drilling,
               re-development and incremental development projects directed at
               improving hydrocarbon recovery in the producing chalk fields of
               Denmark.},
  journal   = {67th European Association of Geoscientists and Engineers, EAGE
               Conference and Exhibition, incorporating SPE EUROPE2005 -
               Extended Abstracts},
  publisher = {European Association of Geoscientists \& Engineers Publications
               B.V. (EAGE)},
  volume    = {CD-ROM},
  number    = {June},
  pages     = {1847--1850},
  year      =  2005,
  keywords  = {Elastic moduli; Mathematical models; Petroleum reser}
}

@BOOK{Johnston2013-jg,
  title     = {Practical Applications of Time-lapse Seismic Data},
  author    = {Johnston, David H},
  publisher = {Society of Exploration Geophysicists},
  month     =  jan,
  year      =  2013,
  url       = {http://library.seg.org/doi/book/10.1190/1.9781560803126},
  isbn      = {9781560803072},
  doi       = {10.1190/1.9781560803126}
}

@ARTICLE{Almutlaq2010-ho,
  title   = {Tutorial: {AVO} inversion},
  author  = {Almutlaq, Mahdi H and Margrave, Gary F},
  journal = {CREWES Res. Rep.},
  volume  =  22,
  pages   = {1--23},
  year    =  2010
}

@BOOK{Calvert2005-lp,
  title     = {Insights and Methods for {4D} Reservoir Monitoring and
               Characterization},
  author    = {Calvert, Rodney},
  publisher = {Society of Exploration Geophysicists and European Association of
               Geoscientists and Engineers},
  volume    =  3200011,
  pages     = {1--210},
  month     =  jan,
  year      =  2005,
  url       = {http://library.seg.org/doi/book/10.1190/1.9781560801696},
  isbn      = {9781560801283},
  doi       = {10.1190/1.9781560801696}
}

@INPROCEEDINGS{Chopra2009-mp,
  title     = {Using {3D} rose diagrams for correlation of seismic fracture
               lineaments with similar lineaments from attributes and well log
               data},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2009},
  author    = {Chopra, Satinder and Marfurt, Kurt J and Mai, Ha T},
  abstract  = {Detection and characterization of fractures in reservoirs is of
               great importance for maximizing hydrocarbon productivity and
               recovery efficiency. Coherence and curvature are two seismic
               attributes that have shown promise in identifying groups of
               closely spaced fractures or interconnected fracture networks.
               Curvature attributes, in particular, exhibit detailed patterns
               from fracture networks. We report the automated generation of
               rose diagrams from seismic attributes throughout the 3D volume
               which can be visually correlated to the lineaments seen on
               different seismic attributes like coherence and quanti- tatively
               correlated to the rose diagrams available from image logs. Since
               these rose diagrams are generated at regular grid points on each
               time slice, they are essentially 3D rose diagrams. Visualization
               of these volumetric 3D rose diagrams with other discontinuity
               attributes lends confidence to the interpretation of fracture
               lineaments. \copyright{} 2009 EAGE.},
  publisher = {Society of Exploration Geophysicists},
  volume    =  27,
  pages     = {3574--3578},
  month     =  jan,
  year      =  2009,
  url       = {http://library.seg.org/doi/abs/10.1190/1.3255608},
  keywords  = {attributes; fractures; reservoir characterization; seismic;
               visualization},
  issn      = {0263-5046},
  doi       = {10.1190/1.3255608}
}

@ARTICLE{Williams2016-qo,
  title    = {Evaluating the Gap between Seismic-scale and Well-scale
              Observations of Structure - A North Sea Case Study},
  author   = {Williams, R M and Pascual-Cebrian, E and Paton, G and Gutmanis, J
              C},
  abstract = {Fault and fracture studies for reservoir characterisation have
              been an essential stage of prospect generation and field
              development from seismic data and well data respectively.
              Commonly well image logs are used to predict fracture intensity
              and orientation, or small scale faults from seismic
              interpretation are used. These results are then scaled up/down
              respectively and applied on a reservoir scale. The biggest
              ambiguity with either of these processes relates to scale. The
              aim of this study is to analyse the reliability of fracture
              trends between well and seismic data to improve fracture pattern
              identification and delineation in offshore Netherlands (Block E),
              Southern North Sea. Two independent studies were performed, a
              well driven fracture analysis and a seismic driven fault
              analysis, and the two results were compared. The seismic fault
              study was undertaken using Cognitive Interpretation workflows to
              illustrate the potential of small scale faulting and fracture
              lineaments. The fracture study used image logs to identify
              fracture orientation and intensity. When the detailed
              multi-attribute analysis and well image logs analysis are
              compared a distinctive overlapping pattern in the
              faults/fractures begins to appear. Supporting the theory that the
              seismic to well gap is closer than ever before.},
  journal  = {78th EAGE Conference and Exhibition 2016},
  number   = {June},
  year     =  2016,
  url      = {http://www.earthdoc.org/publication/publicationdetails/?publication=85412},
  doi      = {10.3997/2214-4609.201601167}
}

@ARTICLE{Tod2007-is,
  title   = {Fracture prediction from wide-azimuth land seismic data in {SE}
             Algeria},
  author  = {Tod, Simon and Taylor, Brian and Johnston, Rodney and Allen, Tony},
  journal = {Lead. Edge},
  volume  =  26,
  number  =  9,
  pages   = {1154--1160},
  month   =  sep,
  year    =  2007,
  url     = {http://library.seg.org/doi/10.1190/1.2780786},
  issn    = {1070-485X},
  doi     = {10.1190/1.2780786}
}

@ARTICLE{Schoenberg1995-oe,
  title   = {Seismic anisotropy of fractured rock},
  author  = {Schoenberg, Michael and Sayers, Colin M},
  journal = {Geophysics},
  volume  =  60,
  number  =  1,
  pages   = {204--211},
  month   =  jan,
  year    =  1995,
  url     = {http://library.seg.org/doi/10.1190/1.1443748},
  issn    = {0016-8033},
  doi     = {10.1190/1.1443748}
}

@ARTICLE{Iacopini2016-vp,
  title     = {Exploring the seismic expression of fault zones in {3D} seismic
               volumes},
  author    = {Iacopini, D and Butler, R W H and Purves, S and McArdle, N and
               De Freslon, N},
  journal   = {J. Struct. Geol.},
  publisher = {Elsevier Ltd},
  volume    =  89,
  pages     = {54--73},
  month     =  aug,
  year      =  2016,
  url       = {http://linkinghub.elsevier.com/retrieve/pii/S0191814116300645},
  keywords  = {seismic interpretation},
  issn      = {0191-8141},
  doi       = {10.1016/j.jsg.2016.05.005}
}

@INPROCEEDINGS{Mezghani2004-rz,
  title     = {History Matching and Quantitative Use of {4D} Seismic Data for
               an Improved Reservoir Characterization},
  booktitle = {{SPE} Annual Technical Conference and Exhibition},
  author    = {Mezghani, M and Fornel, A and Langlais, V and Lucet, N},
  publisher = {Society of Petroleum Engineers},
  month     =  apr,
  year      =  2004,
  url       = {http://www.onepetro.org/doi/10.2118/90420-MS},
  doi       = {10.2118/90420-MS}
}

@ARTICLE{Tiwary2009-xb,
  title    = {Comparison of seismic upscaling methods: From sonic to seismic},
  author   = {Tiwary, Dileep K and Bayuk, Irina O and Vikhorev, Alexander A and
              Chesnokov, Evgeni M},
  abstract = {The term ``upscaling'' used here means a prediction of
              elastic-wave velocities at lower frequencies from the velocities
              at higher frequencies. Three different methods of upscaling are
              considered, including the simple averaging, Backus averaging, and
              pair correlation function methods. These methods are applied to
              upscale the elastic-wave velocities measured at sonic frequencies
              (2 kHz, logging data) available for a well penetrating layers of
              gas-bearing shales and carbonates. As a result, a velocity
              distribution over depth for V-P and V-S is found in the frequency
              range of 50-500 Hz. The difference in the results obtained for a
              particular depth by the three theoretical methods in the surface
              seismic frequency bandwidth (50-100 Hz) is similar to 600 m/s for
              P-wave and similar to 260 m/s for S-wave velocity. This
              difference is attributed to different theoretical backgrounds
              underlying these methods.},
  journal  = {Geophysics},
  volume   =  74,
  number   =  2,
  pages    = {WA3--WA14},
  month    =  mar,
  year     =  2009,
  url      = {http://library.seg.org/doi/10.1190/1.3054144},
  issn     = {0016-8033},
  doi      = {10.1190/1.3054144}
}

@ARTICLE{Schoenberg1989-xt,
  title    = {A calculus for finely layered anisotropic media},
  author   = {Schoenberg, Michael and Muir, Francis},
  abstract = {Matrix algebra and group theory combine to offer a formalism for
              the simple calculation of the elastic, anisotropic, homogeneous
              medium which is equivalent, in the long-wavelength limit, to a
              heterogeneous distribution of fine layers, each layer itself an
              elastic anisotropic medium. The properties of each anisotropic
              constituent in a set of fine layers map to an element of a
              commutative group. A reverse mapping returns the material
              properties of the constituent. Adding group elements gives the
              group element for the homogeneous medium equivalent to a
              heterogeneous set of layers. Addition of an inverse
              element---that is subtraction---provides the means to remove a
              set of layers from an anisotropic medium; then, if the remaining
              layer is a stable anisotropic medium, a valid decomposition of
              the original medium into anisotropic constituents is obtained.
              Within the group structure, eight subgroups corresponding to
              eight types of elastic symmetry systems may be identified,
              immediately yielding the symmetry of the equivalent medium, given
              the symmetry of its constituents. Sets of parallel fractures or
              aligned microcracks are also represented as group elements,
              allowing fractures and anisotropic rocks to be manipulated in a
              consistent and uniform manner. These group elements depend on at
              most six fracture parameters and are independent of the
              properties of the material in which the fractures are embedded.
              Multiple sets of fractures are easily taken into account by
              rotating (back in model space) a rock to a coordinate system
              appropriate to each fracture system, and then adding the
              appropriate fracture system group element.},
  journal  = {Geophysics},
  volume   =  54,
  number   =  5,
  pages    = {581--589},
  month    =  may,
  year     =  1989,
  url      = {http://library.seg.org/doi/10.1190/1.1442685},
  issn     = {0016-8033},
  doi      = {10.1190/1.1442685}
}

@INPROCEEDINGS{Gosselin2003-jf,
  title     = {History Matching Using Time-lapse Seismic ({HUTS})},
  booktitle = {{SPE} Annual Technical Conference and Exhibition},
  author    = {Gosselin, Olivier and Aanonsen, S I and Aavatsmark, I and
               Cominelli, A and Gonard, R and Kolasinski, M and Ferdinandi, F
               and Kovacic, L and Neylon, K},
  abstract  = {AbstractThis paper describes the results of a two-year
               EC-sponsored project whichuses new information provided by
               repeated seismic acquisitions (4D seismicdata) jointly with
               production data in an extended, efficient and consistenthistory
               matching process. This process involves a simultaneous
               minimisation ofthe mismatch between all types of measured and
               simulated data. A gradient-basedtechnique has been developed and
               tested both in a prototype and in commercialcomputer-aided
               history matching software. We show results on real cases,located
               in the North Sea and the Adriatic Sea, and discuss key issues of
               suchseismic history matching.Most applications of time-lapse
               seismic to date have been qualitative orsemi-quantitative. We
               propose a quantitative workflow. The seismic contributionin the
               objective function is defined in terms of elastic parameter
               variationswithin the reservoir and the data have been properly
               scaled using an estimateof seismic uncertainty (covariance
               matrix). The ``observed'' values are obtainedby inversion of the
               seismic signal. For the ``modelled'' values, the flowsimulator
               is coupled with a petro-elastic model to convert simulated fluid
               andstatic rock properties into simulated elastic properties.The
               techniques described in this paper allow us to reconcile
               productionhistory matched models with 4D information, and to
               reduce the uncertainty inreservoir properties, which haven't a
               real impact on the well history, butwhich significantly drive
               future behaviour of the field. This is a further steptowards the
               necessary integration of available data for better
               predictivesimulations. Focusing on quantitative combined with
               qualitative use of dataenhances the multidisciplinary
               approach.IntroductionThe use of time-lapse, or 4D seismic data
               in reservoir management,characterisation and monitoring is
               steadily increasing as the interpretationsget more reliable.
               Inverted seismic data has proven to be very valuable forlocating
               remaining oil and plan infill drilling.1,2 Better and
               morereliable 4D data also triggers the need for a tool, which
               can help thepetroleum engineers to condition the reservoir
               models to this data.Several authors have considered the problem
               of using 4D data in the processof history matching reservoir
               simulation models, but very few have described acomplete
               software system which can handle the integration of both
               productiondata and seismic data in a computer aided history
               matching loop. Also mostpapers either use synthetic data3-8 or
               include the data in aqualitative way9-14. Landa and Horne15
               presented asensitivity study looking at the relative influence
               of the various types ofdata in the reservoir characterisation
               process. Huang et al.16-17have presented a quantitative approach
               where the misfit between 4D real andsynthetic amplitude from
               reservoir simulations is minimised using a stochasticsearch
               procedure. The misfit function also includes production data,
               but thereis a lack of documentation about the exact definitions
               and algorithms used. Theprocedure was applied to a Gulf of
               Mexico dry gas field and improved thereliability of model
               predictions. Waggoner et al.18 have used asimilar approach to a
               simple gas condensate reservoir. Here the similaritybetween
               acoustic impedance variations from 4D data and impedance
               calculated bya numerical simulator was maximised using a greedy
               global optimisationalgorithm. These approaches, however, apply a
               global optimisation routine,which requires hundreds and even
               thousands of simulation runs to obtain amatch.},
  publisher = {Society of Petroleum Engineers},
  pages     = {1--15},
  month     =  apr,
  year      =  2003,
  url       = {http://www.onepetro.org/doi/10.2118/84464-MS},
  isbn      = {9781555631529},
  doi       = {10.2118/84464-MS}
}

@ARTICLE{Maerten2016-xo,
  title     = {Geomechanical paleostress inversion using fracture data},
  author    = {Maerten, Laurent and Maerten, Frantz and Lejri, Mostfa and
               Gillespie, Paul},
  journal   = {J. Struct. Geol.},
  publisher = {Elsevier Ltd},
  month     =  jun,
  year      =  2016,
  url       = {http://dx.doi.org/10.1016/j.jsg.2016.06.007},
  issn      = {0191-8141},
  doi       = {10.1016/j.jsg.2016.06.007}
}

@INCOLLECTION{Rasmussen2005-wk,
  title     = {Late Cenozoic depositional history of the Danish North Sea
               Basin: implications for the petroleum systems in the Kraka,
               Halfdan, Siri and Nini fields},
  booktitle = {Petroleum Geology: {North-West} Europe and Global Perspectives -
               Proceedings of the 6th Petroleum Geology Conference},
  author    = {Rasmussen, E S and Vejb{\ae}k, O V and Bidstrup, T and Piasecki,
               S and Dybkj{\ae}r, K},
  abstract  = {The Central Graben area was filled with a thick pile of
               sediments during the Middle Miocene -- Quaternary, corresponding
               to a period of 15Ma. As hydrocarbon expulsion from the most
               prolific source rock, the Upper Jurassic Bo Member, was
               initiated only 20 Ma BP and still occurs today, the Middle
               Miocene -- Quaternary evolution is important. In the Middle
               Miocene, the Central Graben area was covered by a sea with water
               depth of 500--700 m. During the Late Miocene (Tortonian), the
               basin was successively filled by prograding slope and deltaic
               sediments from the northeast. The progradational infill resulted
               in local tilting of the substratum due to the loading effect of
               the deposits. In the latest Late Miocene (Messinian), the main
               input of sediments occurred from the south, as illustrated by a
               thick onlapping succession of upper Messinian sediments.
               Pliocene sedimentation was characterized by regular infill from
               the east within a shelf to shallow marine depositional
               environment. Following the Miocene and Pliocene, the North Sea
               Basin tilted due to strong uplift of the Fennoscandian shield
               and increased subsidence and sedimentation rates within the
               Central Graben area. This further complicated the maturation of
               the source rock, migration pathways and accumulation of
               hydrocarbons. The consequence of this complex burial history is
               exemplified by the Kraka and Halfdan fields. The Kraka Field has
               a large down-flank oil accumulation, which is the result of a
               porosity anomaly resulting from an early invasion of oil in this
               position before the late tilting of the North Sea Basin. The
               history of the non-structural accumulation of the Halfdan Field
               can be readily modelled; it constituted a simple four-way dip
               closure during the Late Miocene when peak oil migration
               occurred. The Quaternary tilting of the North Sea Basin due to
               uplift of the Fennoscandian Shield and strong subsidence of the
               Central Graben area resulted in a distinct gradient favouring
               long-distance migration of hydrocarbons. The occurrence of
               viable migration routes, especially within Paleocene sand
               layers, has resulted in long-distance migration of oil into the
               Siri submarine valley system. The most northern indication of
               hydrocarbons has been recognized as far as 75km from the source
               area. Long distance migration of hydrocarbons is also indicated
               by direct hydrocarbon indications (DHIs) throughout the Cenozoic
               succession in the Danish North Sea. DHIs are particularly
               prominent above known hydrocarbon accumulations in the Central
               Graben. This indicates pronounced vertical migration, for
               instance along active faults, above these structures.},
  publisher = {Geological Society of London},
  pages     = {1347--1358},
  month     =  jan,
  year      =  2005,
  url       = {http://pgc.lyellcollection.org/lookup/doi/10.1144/0061347},
  doi       = {10.1144/0061347}
}

@BOOK{Nanda2016-ot,
  title     = {Seismic Data Interpretation and Evaluation for Hydrocarbon
               Exploration and Production},
  author    = {Nanda, Niranjan C},
  publisher = {Springer International Publishing},
  pages     = {224},
  year      =  2016,
  url       = {http://link.springer.com/10.1007/978-3-319-26491-2},
  address   = {Cham},
  isbn      = {9783319264899},
  doi       = {10.1007/978-3-319-26491-2}
}

@ARTICLE{Song2016-iv,
  title    = {Pre-stack-texture-based reservoir characteristics and seismic
              facies analysis},
  author   = {Song, Cheng-Yun and Liu, Zhi-Ning and Cai, Han-Peng and Qian,
              Feng and Hu, Guang-Min},
  journal  = {Appl. Geophys.},
  volume   =  13,
  number   =  1,
  pages    = {69--79},
  month    =  mar,
  year     =  2016,
  url      = {http://link.springer.com/10.1007/s11770-016-0541-5},
  keywords = {clustering; gray level co-occurrence matrix; pre-stack texture
              attributes; reservoir characteristic; seismic facies analysis;
              som},
  issn     = {1672-7975},
  doi      = {10.1007/s11770-016-0541-5}
}

@ARTICLE{Gao2003-hz,
  title   = {Volume texture extraction for {3D} seismic visualization and
             interpretation},
  author  = {Gao, Dengliang},
  journal = {Geophysics},
  volume  =  68,
  number  =  4,
  pages   = {1294--1302},
  month   =  jul,
  year    =  2003,
  url     = {http://library.seg.org/doi/10.1190/1.1598122},
  issn    = {0016-8033},
  doi     = {10.1190/1.1598122}
}

@INPROCEEDINGS{Ponfa_Bitrus2016-ce,
  title     = {Mapping {3D} thin shale and permeability pathway within a
               reservoir system: Case study from the Sleipner Field},
  booktitle = {{EGU} General Assembly Conference Abstracts},
  author    = {Ponfa Bitrus, Roy and Iacopini, David and Bond, Clare},
  abstract  = {Reservoir architecture plays an integral part of seismic
               reservoir characterization. The characteristics of a reservoir
               which includes its external and internal geometry are important
               as they influence the production and development strategy
               employed in the oil and gas sector. Reservoir architecture is
               defined by the interpretation of seismic data, thus identifying
               the basic structural and stratigraphic geometrical framework of
               a trapping and flow system for hydrocarbon and fluids. One major
               issue though is the interpretation of thin shales and
               identification of permeability pathways within the reservoir
               system. This paper employs a method using attributes to map thin
               shales and identify permeability pathways or transmissitives
               that exist within a reservoir taking into consideration the
               seismic resolution and available data. Case study is the Utsira
               Formation in the Sleipner field, Norwegian North sea. The Utsira
               formation presents a classic case of thin beds within a
               sandstone formation and transmissitives that exist as chimneys
               within the formation. A total of 10 intra reservoir horizon
               units of shales where interpreted using complex trace seismic
               attributes. These interpreted horizons where further analysed
               through spectral decomposition to reveal possible facies
               distribution and unit thickness within the horizon. Reservoir
               transmissitives identified as vertical curvilinear structures
               were also analysed using unique seismic attributes in other to
               delineate their extent and characterise their occurrence These
               interpreted shales and pathway transmissitives illuminate the
               geometry of the formation, the reservoir heterogeneities on a
               finer-scale and, in the long term, constrain the migration
               prediction of reservoir fluids, hydrocarbons and injected CO2
               when matched across a 4D seismic data survey. As such, useful
               insights into the key elements operating within the reservoir
               can be provided, giving a good indication of the long and short
               term reservoir performance.},
  volume    =  18,
  pages     = {17228},
  year      =  2016,
  url       = {http://adsabs.harvard.edu/abs/2016EGUGA..1817228P},
  language  = {en}
}

@INPROCEEDINGS{Maestrelli2016-jn,
  title     = {Seismic texture and amplitude analysis of large scale fluid
               escape pipes using time lapses seismic surveys: examples from
               the Loyal Field (Scotland, {UK})},
  booktitle = {{EGU} General Assembly Conference Abstracts},
  author    = {Maestrelli, Daniele and Jihad, Ali and Iacopini, David and Bond,
               Clare},
  abstract  = {Fluid escape pipes are key features of primary interest for the
               analysis of vertical fluid flow and secondary hydrocarbon
               migration in sedimentary basin. Identified worldwide (L{\o}set
               et al., 2009), they acquired more and more importance as they
               represent critical pathways for supply of methane and potential
               structure for leakage into the storage reservoir (Cartwright \&
               Santamarina, 2015). Therefore, understanding their genesis,
               internal characteristics and seismic expression, is of great
               significance for the exploration industry. Here we propose a
               detailed characterization of the internal seismic texture of
               some seal bypass system (e.g fluid escape pipes) from a 4D
               seismic survey (released by the BP) recently acquired in the
               Loyal Field. The seal by pass structure are characterized by
               big-scale fluid escape pipes affecting the Upper
               Paleogene/Neogene stratigraphic succession in the Loyal Field,
               Scotland (UK). The Loyal field, is located on the edge of the
               Faroe-Shetland Channel slope, about 130 km west of Shetland
               (Quadrants 204/205 of the UKCS) and has been recently
               re-appraised and re developed by a consortium led by BP. The 3D
               detailed mapping analysis of the full and partial stack survey
               (processed using amplitude preservation workflows) shows a
               complex system of fluid pipe structure rooted in the pre Lista
               formation and developed across the paleogene and Neogene Units.
               Geometrical analysis show that pipes got diameter varying
               between 100-300 m and a length of 500 m to 2 km. Most pipes seem
               to terminate abruptly at discrete subsurface horizons or in
               diffuse termination suggesting multiple overpressured events and
               lateral fluid migration (through Darcy flows) across the
               overburden units. The internal texture analysis of the large
               pipes, (across both the root and main conduit zones), using
               near, medium and far offset stack dataset (processed through an
               amplitude preserved PSTM workflow) shows a tendency of
               up-bending of reflection (rather than pulls up artefacts)
               affected by large scale fracture (semblance image) and seem
               consistent with a suspended mud/sand mixture non-fluidized fluid
               flow. Near-Middle-Far offsets amplitude analysis confirms that
               most of the amplitude anomalies within the pipes conduit and
               terminus are only partly related to gas. An interpretation of
               the possible texture observed is proposed with a discussion of
               the noise and artefact induced by resolution and migration
               problems. Possible hypothetical formation mechanisms for those
               Pipes are discussed.},
  volume    =  18,
  pages     = {17054},
  year      =  2016,
  url       = {http://adsabs.harvard.edu/abs/2016EGUGA..1817054M},
  language  = {en}
}

@INPROCEEDINGS{Gommesen2007-yk,
  title       = {{4D} Seismic Signatures of North Sea {Chalk-The} Dan Field},
  booktitle   = {2007 {SEG} Annual Meeting},
  author      = {Gommesen, Lars and Dons, Thomas and Hansen, Hans P and
                 Stammeijer, Jan and Hatchell, Paul and {Others}},
  pages       = {2847--2851},
  institution = {Society of Exploration Geophysicists},
  year        =  2007
}

@INPROCEEDINGS{Gommesen2012-hl,
  title     = {Chalk Reservoir Management Through Rock Physics Diagnostics -
               Field Examples from the Danish North Sea},
  booktitle = {{SPE} {Europec/EAGE} Annual Conference},
  author    = {Gommesen, L and Hansen, H P},
  abstract  = {This paper illustrates the value of an integrated approach to
               management of chalk reservoirs and aims to provide the reader
               with 3D and 4D seismic examples that takes offset in the key
               parameters controlling elastic behaviour of chalk without
               discussing theories or models in depth, and only include well
               logs or laboratory derived models to support the examples. The
               examples of this paper show how quantitative geophysical
               analysis through integration with well-established reservoir
               engineering and geoscience processes has impacted reservoir
               management and field development significantly. The diagnostics
               have led to optimized drilling and near field appraisal,
               maturation of wells, identification of remaining potential and
               insight to water flooding dynamics. The paper concludes that an
               integrated approach to field development and reservoir
               management includes quantitative geophysical interpretation and
               that rock physics is an excellent enabler for integration
               between geoscience and petroleum engineering.},
  publisher = {Society of Petroleum Engineers},
  pages     = {4--7},
  month     =  apr,
  year      =  2012,
  url       = {http://www.onepetro.org/doi/10.2118/154870-MS},
  doi       = {10.2118/154870-MS}
}

@INPROCEEDINGS{Zaske2013-qt,
  title       = {{4D} Seismic as a Tool to Support Well and Reservoir
                 Management: Danish Chalk Field Examples},
  booktitle   = {2013 {SEG} Annual Meeting},
  author      = {Zaske, J and Calvert, M and Herbert, I and Hickman, P and
                 Micksch, U and Roende, H and {Others}},
  pages       = {4976--4980},
  institution = {Society of Exploration Geophysicists},
  year        =  2013,
  keywords    = {4D, case history, time-lapse}
}

@ARTICLE{Robinson_undated-jh,
  title    = {Seismically Driven Fractured Reservoir Characterization},
  author   = {Robinson, G},
  abstract = {Characterization of naturally fractured reservoir is a recurring
              challenge for many oil and gas companies that manage and develop
              fractured reservoirs. Several techniques have been applied in the
              past to characterize these complex reservoirs; most of them have
              been proven unreliable. This paper will describe a methodology to
              improve the characterization of fractured reservoir by using
              seismic attributes. The methodology presented in this paper uses
              the simultaneous integration of geophysical, geologic, and
              engineering data to improve the reservoir description. At the
              root of this reservoir characterization technique is the
              increasingly accurate seismic data collected on most of the
              reservoirs world-wide. The initial use of this seismic
              information is made possible through the use of pre-stack and
              post-stack high-resolution, and spectral imaging. These two
              processes allow a better imaging of the geology in the reservoir
              and provide critical rock properties that have a dramatic impact
              on fracture modeling. The resulting fracture models are able to
              reproduce the production and pressure history because they have
              the ability to model correctly the complex ``plumbing'' of the
              fractured reservoirs. This ability comes from the use of key
              seismic attributes in an integrated fracture modeling approach.
              An application of this technology and workflow is presented on a
              very complex fractured reservoir.},
  journal  = {Block 1, Forum 3 paper},
  pages    = {1--13}
}

@ARTICLE{Herwanger2015-qz,
  title    = {Seismic Geomechanics - How to build and calibrate geomechanical
              models using {3D} and {4D} siesmic data},
  author   = {Herwanger, J},
  abstract = {Three-dimensional geomechanical models are becoming more
              frequently used to assess the state of stress inside the Earth.
              Knowledge of the stress-state in a reservoir and the surrounding
              rock allows assessing the risk of reservoir compaction, wellbore
              failure, sanding, breach of seal integrity, fault re-activation
              and allows the design of mitigation for these issues.
              Three-dimensional seismic data and inversion models can be used
              in building geomechanical models and time-lapse (4D) seismic data
              provide a means of calibrating the dynamic behavior of reservoir
              geomechanical models. The purpose of this course is to provide an
              overview of currently available workflows to build and run
              calibrated reservoir geomechanical models maximizing the use of
              3D and 4D seismic data. Rock-physics, relating the state of
              stress in the Earth and the propagation velocity of seismic
              waves, forms the link between seismic observations and the
              geomechanical model, and this link will be discussed both from
              experimental data and from a theoretical viewpoint. Attendees
              will learn how a combination of 3D geomechanical models, coupled
              to flow models, built and calibrated with 3D and 4D seismic data
              help in creating a deep understanding of the reservoir depletion
              processes and the state of stress in the reservoir and
              surrounding rock.},
  journal  = {EAGE Education Tour},
  pages    = {1--219},
  year     =  2015,
  keywords = {Geomechanics rocks; Reservoir geomechanics; Rock physics; Seismic
              inversion}
}

@ARTICLE{Vejbaek2014-hj,
  title    = {{4D} seismic, {4D} geomechanics and hydraulic stimulation in the
              low permeability South Arne chalk field},
  author   = {Vejb{\ae}k, O V and Mohamed, F R and Herwanger, J V},
  abstract = {O.V. Vejb{\ae}k, F.R. Mohamed, and J.V. Herwanger employ a 4D
              geomechanical model calibrated with time-lapse seismic time shift
              data to understand the direction and size of hydraulically
              stimulated fractures.},
  journal  = {First Break},
  volume   =  32,
  number   =  6,
  pages    = {139--148},
  year     =  2014,
  issn     = {0263-5046, 1365-2397}
}

@INPROCEEDINGS{Zaske2014-je,
  title     = {Dan Field Ocean Bottom Node ({OBN}) Survey - A Shallow Water
               Case History},
  booktitle = {76th {EAGE} Conference and Exhibition 2014},
  author    = {Zaske, J and Hickman, P and Roende, H and Mukund, S and
               Halliday, S and Perrier, S},
  abstract  = {In 2012 Maersk Oil acquired an Ocean Bottom Node (OBN) seismic
               survey over the Dan Field located in shallow water in the Danish
               North Sea. The survey took place shortly after a regional
               multi-field 4D monitor streamer survey which included the area
               around the Dan Field. The primary objective of the OBN survey
               was to acquire data in an area affected by surface
               infrastructure not accessible with streamer technology.
               Secondary objectives included evaluating the imaging results in
               comparison with streamer technology on a field wide scale and
               evaluating the matching quality between the vintage streamer and
               OBN survey data. Significant challenges due to the shallow water
               environment were overcome during operations as well as
               processing. The results show a clear improvement with the OBN
               data in the area affected by the platforms when compared to the
               streamer data in-filled with conventional two boat
               undershooting. The OBN image is of a similar or better quality
               over most of the field when compared to the streamer result
               allowing for different strategic options for future seismic
               surveys in this area.},
  year      =  2014
}

@INPROCEEDINGS{Guilbot2002-ph,
  title     = {Interpretation Tools and Methods for Chalk Reservoir
               Characterization},
  booktitle = {64th {EAGE} Conference \& Exhibition 2002},
  author    = {Guilbot, J and Smith, B and Pirera, F},
  abstract  = {Seismic impedance inversion is recognized as a powerful
               technique for detailed reservoir characterization of chalk
               fields. It helps not only for porosity mapping (because of an
               excellent correlation between impedance and porosity) but also
               for detailed reservoir layering. Once inverted, seismic
               amplitude data can lead to a new interpretation of the
               relationships between layers especially in the case of porosity
               variations due to diagenesis. Looking at the conformity of
               seismic porosity with reservoir structure is also a key
               principle for chalk fields. It helps to delineate the downflank
               potential by identifying sudden porosity drops related to
               paleo-OWCs. A third technique that seems mandatory to study
               heavily produced chalk reservoirs is time-lapse seismic
               technology. When adequately processed, 4D seismic data yield
               detailed maps of reservoir compaction and provide calibration
               points for reservoir simulation. All these methods have been
               applied recently on the Ekofisk field to build a new geological
               model of the field.},
  year      =  2002
}

@ARTICLE{Ampilov2009-df,
  title    = {4d Seismic {State-Of-The-Art} Technologies for Monitoring of
              Offshore Oil And Gas Fields Development},
  author   = {Ampilov, Yu P and Baturin, D G},
  abstract = {This article analyzes the current status of the 4D seismic
              technology. We regret to admit that in Russia the 4D seismic is
              used only in one of the offshore fields on the Sakhalin shelf,
              while there are dozens of successful 4D seismic implementations
              worldwide. In the years to come, this technology is expected to
              expand in Russia due to accelerated development of offshore
              fields. The article reviews three options for the 4D seismic data
              acquisition in such fields: 1) consistent acquisition of
              conventional 3D data using a towed seismic streamer at long
              intervals of time; 2) regular seismic surveys with seabed seismic
              cables; 3) installation of the seabed fiber optic 4C system for
              the entire life of the field. The article compares the
              engineering and cost parameters of these modifications.},
  journal  = {Seismic Technology},
  pages    = {1--10},
  year     =  2009,
  url      = {http://dx.doi.org/10.3997/2405-7495.2015047},
  keywords = {4d Seismic technology; Fiber; Fields; Monitoring of production;
              Offshore oil and gas},
  doi      = {10.3997/2405-7495.2015047}
}

@ARTICLE{Landa2011-og,
  title    = {Joint Inversion of {4D} Seismic and Production Data},
  author   = {Landa, J L and Kumar, D},
  abstract = {We present a workflow for the quantitative integration of 4D
              seismic and production data into reservoir simulation models.
              Reservoir models are probabilistically history matched to 4D
              seismic and production historical data simultaneously. The timely
              incorporation of 4D seismic into reservoir models, coupled with
              the associated reduction of production forecast uncertainty, has
              a significant impact in the modern reservoir management of oil
              and gas fields. One of the outstanding features of the work
              presented is the use of the 4D seismic data at the seismic trace
              level (i.e. seismic wiggle) compared to the impedance level. In
              the joint inversion approach, the reservoir models are jointly
              calibrated to the production data and the 4D seismic data
              simultaneously through a single inversion process. There is no
              need for separate seismic inversion for impedance or for
              pressure/saturation. The calibrated reservoir models honor both
              the historical production data and the 4D seismic traces. The
              joint inversion ensures consistency among the observed 4D seismic
              traces, the observed production data, and the geological,
              seismic, petrophysical and flow models. This consistency, while
              it is guaranteed in the joint inversion, is difficult to attain
              through the traditional approach of separate inversion processes
              for 4D seismic and production data. The joint inversion process
              seeks: a) to shorten the time between 4D seismic acquisition and
              its incorporation into reservoir models, b) to use 4D seismic in
              a quantitative way, and c) to reduce uncertainty in reservoir
              models and thus reduce uncertainty in the production forecasts.
              This paper presents and discusses results from application of the
              joint inversion workflow to a synthetic field case based on a
              real field. The example covers the areas of a) history matching
              of flow simulation models to 4D seismic and production history,
              and b) estimation of uncertainty. The joint inversion process
              requires a multidisciplinary effort. It involves the joint
              modeling of geology, flow simulation, rock physics, and seismic
              modeling under a common earth model, and thus it naturally
              fosters the efficient interaction among geologists,
              geophysicists, and reservoir engineers.},
  journal  = {SPE Annual Technical Conference and Exhibition},
  number   = {November},
  pages    = {1--17},
  year     =  2011
}

@ARTICLE{Ouenes2004-up,
  title    = {Seismically Driven Improved Fractured Reservoir Characterization},
  author   = {Ouenes, A and Zellou, A M and Robinson, G and Balogh, D and
              Araktingi, U},
  abstract = {Characterization of naturally fractured reservoir is a recurring
              challenge for many oil and gas companies that manage and develop
              fractured reservoirs. Several techniques have been applied in the
              past to characterize these complex reservoirs; most of them have
              been proven unreliable. This paper will describe a methodology to
              improve the characterization of fractured reservoir using seismic
              attributes derived from pre- stack and post-stack high resolution
              inversion and spectral imaging. The methodology presented in this
              paper uses the simultaneous integration of geophysical, geologic,
              and engineering data to improve the reservoir description. At the
              root of this reservoir characterization technique is the
              increasingly accurate seismic data collected on most of the
              reservoirs world-wide. Extensive use of this seismic information
              is made possible through the use of pre-stack high-resolution
              elastic inversion, post-stack high resolution inversion, and
              spectral imaging. These processes allow the derivation of seismic
              attributes that are extremely relevant to fracturing and could
              also be used as input in the continuous fracture modeling
              approach. Based on this seismically driven reservoir
              characterization, the fractured reservoir properties could be
              accurately estimated in 3D. An application of this technology and
              workflow is presented on a very complex fractured reservoir.
              Introduction},
  journal  = {Spe 92031},
  pages    = {1--9},
  year     =  2004,
  url      = {http://dx.doi.org/10.2523/92031-MS},
  doi      = {10.2523/92031-MS}
}

@INPROCEEDINGS{Ali2012-az,
  title     = {Integration of {4D} Seismic Monitoring Results as History Match
               Indicators for Reservoir Simulation},
  booktitle = {{SPE} Annual Technical Conference and Exhibition},
  author    = {Ali, Amna and Verdiere, Sophie and Brechet, Emmanuelle and
               Corpel, Vincent and Cailly, Frederic and Agar, Elodie and
               Billon, Olivier},
  abstract  = {Abstract 4D seismic has been utilised on several fields for
               improved reservoir monitoring and management. There have been
               ongoing efforts to incorporate 4D seismic interpretation results
               as standard monitoring parameters and encouraging results have
               been achieved for the integration of this data for reservoir
               dynamic analysis. This paper presents new methodologies and
               applications for the use of 4D seismic monitoring inferences as
               history match indicators for different dynamic realisations.
               Matching the historical performance of a reservoir is a
               time-consuming task with a non-unique solution and hence the
               inherent uncertainty questions the credibility of forecasted
               results. Experimental design workflows take into account the
               influence of multiple parameters and their inter-dependency to
               assess the impact of the uncertainties on business decisions.
               The history match quality of a range of realisations has
               generally been assessed in terms of water breakthrough times,
               pressures, production rates, FPWD (formation pressure while
               drilling) data and other monitoring measurements such as PLT
               (production logging tool) data. As 4D seismic acquisition is
               becoming a standard monitoring technology for many fields,
               efforts have been devoted to obtain increased benefit from this
               data for the history matching process and it is now being used
               to assess the history match quality of a range of dynamic
               realisations and improve the response surface modelling. The
               monitoring parameters obtained from 4D seismic are
               case-specific. A turbidite water-flood field is considered here
               and the match of the simulated vs. observed flood-fronts from 4D
               seismic are used as a new parameter amongst others to assess the
               history match of multiple simulation runs. The flood-fronts are
               obtained as 3D geobodies from 4D seismic attribute
               interpretation. The interpretations are validated with geology
               and analytical integration with dynamic data. This validation
               process is considered essential for the effective application of
               this methodology. These workflows show promising results of
               including 4D seismic based history match indicators and hence
               hold potential to facilitate the geological model update loop as
               well as 4D seismic assisted/automated history matching
               approaches.},
  publisher = {Society of Petroleum Engineers},
  pages     = {1--11},
  month     =  apr,
  year      =  2012,
  url       = {http://www.onepetro.org/doi/10.2118/159344-MS},
  isbn      = {9781622764150},
  doi       = {10.2118/159344-MS}
}

@INPROCEEDINGS{Jin2012-my,
  title     = {Workflows for Quantitative {4D} Seismic Data Integration : A
               Case Study},
  booktitle = {International Petroleum Technology Conference},
  author    = {Jin, L and Tiller, G and Weber, D and Fu, S and Ferrandis, J and
               Van Den Hoek, P and Pirmez, C and Fehintola, T and Tendo, F and
               Olaniyan, E},
  abstract  = {This paper describes the full cycle of 4D seismic data
               integration comprised of workflows related to 4D data analysis,
               quality control of reservoir models and reservoir model updating
               using both 4D seismic and well production data. These workflows
               are applied to a deepwater field, where high quality 4D seismic
               data is available. In the first step, we analyze 4D seismic data
               and extract multiple attributes to image changes in reservoir
               properties. Next, we apply different workflows which link 4D
               seismic data with the reservoir model. Finally, we update the
               reservoir model automatically by simultaneously honoring the 4D
               seismic and well production data. We use a novel approach which
               incorporates 4D seismic amplitude differences without explicitly
               modeling the full physics in a joint history matching workflow.},
  pages     = {1--6},
  year      =  2012,
  isbn      = {9781972952948}
}

@INPROCEEDINGS{Calvert2013-ho,
  title     = {Quick Impact of New {4D} over the Halfdan Field , Danish North
               Sea},
  booktitle = {75th {EAGE} Conference \& Exhibition incorporating {SPE}
               {EUROPEC} 2013 London, {UK}, 10-13 June 2013},
  author    = {Calvert, M A and Roende, H H and Herbert, I H and Zaske, J},
  abstract  = {A new repeat time lapse seismic survey was acquired in 2012 over
               the Halfdan Cretaceous Chalk Formation oil field, and the 800
               km2 surrounding area, located in the Danish North Sea Central
               Graben, approximately 250 km west of the Danish west coast. The
               main objectives of the repeat 4D were to understand the lateral
               and vertical sweep, identify unswept areas, guide future well
               interventions and to clarify the reservoir model. A key
               technical objective of the new time lapse was to deliver a fast
               track 4D difference volume 11 weeks after the last shot with the
               aim to influence further processing steps and quickly integrate
               the 4D into the asset management. The volumes were quickly
               compared with the simulation data and the previous 2005 time
               lapse seismic focusing on the changes in lateral \& vertical
               sweep. Field-wide and reservoir specific examples of the time
               lapse response from 2005 to 2012 are presented.},
  year      =  2013,
  isbn      = {9781629937915}
}

@INPROCEEDINGS{Liu2006-ct,
  title     = {Reducing risk and monitoring water injection using time-lapse
               (4D) seismic at the Ekofisk field},
  booktitle = {{SEG/New} Orleans 2006 Annual Meeting},
  author    = {Liu, E and Chapman, M and Loizou, N and Li, X},
  abstract  = {Over the past decade, time-lapse (4D) seismic has evolved into a
               valuable reservoir-monitoring tool used on numerous fields
               throughout the world. 4D seismic has been used at the Ekofisk
               field to monitor water injection and reservoir depletion. The 4D
               seismic signal is complex and can be broken down into two main
               components. The first and most apparent of these being 4D travel
               time differences caused by the geomechanical effects of
               compaction and stress changes occurring in the reservoir and
               overburden. The second and less obvious component of the 4D
               signal is an amplitude difference caused by a change in
               impedance as the reservoir responds to water injection and
               pressure depletion. We use a combination of 4D time shifts and
               amplitude changes to identify water swept areas and optimize
               well placement.},
  pages     = {279--283},
  year      =  2006,
  keywords  = {4D; development and production; monitoring; reservoir
               characterization; time-lapse}
}

@INPROCEEDINGS{Dorn-Lopez2005-qy,
  title     = {Modeling seismic response of danish chalk reservoirs to changes
               induced by production},
  booktitle = {67th European Association of Geoscientists and Engineers, {EAGE}
               Conference and Exhibition, incorporating {SPE} {EUROPE2005} -
               Extended Abstracts},
  author    = {Dorn-Lopez, D and Srensen, A and Mavko, G and Fabricius, I L and
               Hedegaard, K},
  abstract  = {This paper documents a modeling study detailing some predicted
               seismic signatures of production-related changes in chalk
               reservoirs of the Danish North Sea. Our objective was to provide
               a rock physics analysis as a gateway to understanding the
               seismic signatures of porosity, compaction, pore fluids,
               pressure, temperature and induced fractures, with particular
               application to time-lapse seismic. The study was performed in
               steps, including: 1) laboratory measurements of compressional
               and shear velocity, porosity, texture and mineralogy on core
               plugs, 2) analysis of core and log data in order to build an
               elastic model relating the parameters, 3) specification of
               physical parameters associated with various production
               scenarios, 4) modeling the seismic signatures that would result
               from hydrocarbon production, differential compaction and water
               injection. Results of the study indicate that the elastic model
               built for the chalk reservoirs is consistent at the core plug,
               electric log, and seismic scales, and can be applied to the
               entire geographic area from the Gorm, Kraka, Dan and Halfdan
               reservoirs, and possibly to other chalk reservoirs within the
               North Sea. Changes to the rock properties induced by production
               of hydrocarbons and/or injection of water can be expected to
               produce measurable and visible changes to the seismic data
               recorded at the surface. Seismic changes can be differences in
               reflection amplitude, AVO intercept and gradient changes, or
               differences in travel time. For the scenarios modeled, the
               greatest differences in seismic response occur during compaction
               of the reservoir and resulting subsidence of the overburden.
               This gives about 50 pet. change in RMS amplitude of the
               reflection from the top and base of the reservoir, and also a
               measurable change in travel time. Other effects modeled (e.g.
               water injection, movement of the OWC or the GOC) result in
               changes from 8-15 pet. in seismic amplitudes, many of which
               should be observable on a repeated surface seismic survey. This
               study, therefore, supports the idea that time-lapse seismic
               surveys may provide useful information for infill drilling,
               re-development and incremental development projects directed at
               improving hydrocarbon recovery in the producing chalk fields of
               Denmark.},
  year      =  2005,
  keywords  = {Elastic moduli; Mathematical models; Petroleum reser},
  isbn      = {9789073781986}
}

@ARTICLE{Tolstukhin2012-hr,
  title    = {Ekofisk {4D} Seismic - Seismic History Matching Workflow},
  author   = {Tolstukhin, E and Lyngnes, B and Sudan, H H},
  abstract = {Abstract This presentation outlines an integrated workflow that
              incorporates 4D seismic data into the Ekofisk field reservoir
              model history matching process. Successful application and
              associated benefits of the workflow benefits are also presented.
              A seismic monitoring programme has been established at Ekofisk
              with 4D seismic surveys that were acquired over the field in
              1989, 1999, 2003, 2006 and 2008. Ekofisk 4D seismic data is
              becoming a quantitative tool for describing the spatial
              distribution of reservoir properties and compaction. The seismic
              monitoring data is used to optimize the Ekofisk waterflood by
              providing water movement insights and subsequently improving
              infill well placement. Reservoir depletion and water injection in
              Ekofisk lead to reservoir rock compaction and fluid substitution.
              These changes are revealed in space and time through 4D seismic
              differences. Inconsistencies between predicted 4D differences
              (calculated from reservoir model output) and actual 4D
              differences are therefore used to identify reservoir model
              shortcomings. This process is captured using the following
              workflow: (1) prepare and upscale a geologic model, (2) simulate
              fluid flow and associated rockphysics using a reservoir model,
              (3) generate a synthetic 4D seismic response from fluid and rock
              physics forecasts, and (4) update the reservoir model to better
              match actual production/injection data and/or the 4D seismic
              response. The above-mentioned Seismic History Matching (SHM)
              workflow employs rock-physics modeling to quantitatively
              constrain the reservoir model and develop a simulated 4D seismic
              response. Parameterization techniques are then used to constrain
              and update the reservoir model. This workflow updates geological
              parameters in an optimization loop through minimization of a
              misfit function. It is an automated closed loop system, and
              optimization is performed using an in-house computer-assisted
              history matching tool using evolutionary algorithm. In summary,
              the Ekofisk 4D SHM workflow is a multi-disciplinary process that
              requires collaboration between geological, geomechanical,
              geophysical and reservoir engineering disciplines to optimize
              well placement and reservoir management. Introduction The Ekofisk
              Field is located in the Norwegian Sector of the North Sea. It was
              discovered in 1969 and began production in 1971. The field is one
              of the largest fields on the Norwegian Continental Shelf with
              initial oil in place estimate of 7.1 billion STB of oil. The
              produced volumes are extracted from two fractured chalk
              formations. These reservoir formations are characterized by very
              high porosities and low matrix permeabilities. Formation
              productivity is enhanced by the natural fracture systems that
              allow commercial production from the field. The first field
              development phase was natural depletion production. The first
              pilot water injection was initiated in 1981, and large scale
              water injection was initiated in 1987. Expected recovery factor
              have increased from an initial estimate of 17\% OHIP (Original
              Hydrocarbon In Place) to a current estimate of more than 50\%
              OHIP through continuous improvements in field development plans,
              implementation of IOR, application of new technology and
              investments in new and existing facilities. It is also believed
              that a significant upside exists in further development
              optimization. Future development plans at Ekofisk include an
              active drilling program. The program includes replacement of
              mechanically failed wells coupled with new infill wells to
              optimize recovery. Conducting a successful drilling programme in
              a mature chalk field is challenging. A single wellbore can
              experience large reservoir pressure and water saturation
              differences. Furthermore, compaction can alter the target
              interval depth, thickness, and reservoir properties as a function
              of time.},
  journal  = {SPE Europec/EAGE Annual Conference},
  number   = {June},
  pages    = {4--7},
  year     =  2012,
  url      = {http://dx.doi.org/10.2118/154347-ms},
  doi      = {10.2118/154347-ms}
}

@ARTICLE{Christensen2006-wx,
  title    = {Seismically Driven Reservoir Characterization Using an Innovative
              Integrated Approach: Syd Arne Field},
  author   = {Christensen, S and Ebbe-Dalgaard, T and Rosendal, A and
              Christensen, J and Robinson, G and Zellou, A and Royer, T},
  abstract = {This paper presents an innovative integrated workflow applied to
              the characterization of a fractured chalk reservoir in the Danish
              North Sea. The methodology uses simultaneous integration of
              geophysical, geological and engineering data to produce an
              improved reservoir description. Integrating dynamic flow data
              with the geophysical and geologic information in 3D, reservoir
              properties - porosity and effective permeability - are generated
              using artificial intelligence tools. The strength of this
              technique lies in the fact that property modeling is not
              constrained to match upscaled well data and consequently these
              data serve to validate the outcome. This workflow builds upon a
              methodology that has been used successfully for the
              characterization of fracture distribution. The technique has been
              extended to include the generation of seismically derived models
              of porosity and matrix permeability.The objective of the approach
              is to improve the ability to capture the heterogeneity of key
              reservoir properties, and thus use the resulting reservoir model
              to both provide improved predictive ability and identify
              previously undiscovered development opportunities. The
              application and outcome of this integrated workflow to the Syd
              Arne field is presented in this paper.},
  journal  = {Proceedings, SPE Annual Technical Conference and Exhibition},
  pages    = {1--11},
  year     =  2006,
  url      = {http://www.onepetro.org/mslib/servlet/onepetropreview?id=SPE-103282-MS&soc=SPE},
  doi      = {10.2118/103282-MS}
}

@INPROCEEDINGS{Pettersen2006-rp,
  title     = {Time-lapse seismic inversion of data from a compacting chalk
               reservoir {SEG} / New Orleans 2006 Annual Meeting {SEG} / New
               Orleans 2006 Annual Meeting},
  booktitle = {{SEG/New} Orleans 2006 Annual Meeting},
  author    = {Pettersen, R S H and Barkved, O I and Haller, N},
  abstract  = {A permanent seismic array (LoFS) was installed at the Valhall
               field in 2003. Since then, six seismic surveys have been
               acquired to help monitor primary production and injection. The
               4D seismic response is reflected as changes in amplitude and
               travel-times, and is related to saturation and effective stress
               changes in the reservoir and the surrounding rocks. Acoustic
               impedance (AI) volumes are generated using a model based
               inversion scheme. The amplitude and the AI volumes are
               compensated for relative changes in travel-times, and the
               relevant difference volumes are created using an automated
               workflow. In this paper we discuss the value of analyzing the 4D
               seismic response in the AI domain, and show examples on the
               production induced change taken place. We will discuss the
               practicality involved in producing an optimal 4D impedance
               difference volume and compare the model based inversion scheme
               to relative AI results from applying the rapid method of band
               limited Colored Inversion (CI). Introduction},
  pages     = {3225--3229},
  year      =  2006,
  keywords  = {4D; inversion; reservoir characterization; time-la}
}

@INPROCEEDINGS{Svay2013-no,
  title  = {4D-repeatability of Reservoir Illumination - New Quality Indicators
            for Marine Acquisition},
  author = {Svay, Julie and Bousqui{\'e}, N and Mensch, Thomas and Sedova, Anna
            and Hickman, P and Zaske, J},
  pages  = {10--13},
  year   =  2013,
  url    = {http://www.earthdoc.org/publication/publicationdetails/?publication=68367},
  doi    = {10.3997/2214-4609.20130132}
}

@ARTICLE{Dons2007-iu,
  title    = {Observations and Quantitative Analyses of Waterflood Patterns in
              a Chalk Reservoir Using Seismic Data, Halfdan Field, Danish North
              Sea},
  author   = {Dons, T and J{\o}rgensen, O and Gommesen, L},
  abstract = {Reservoir pressure maintenance and sweep of oil with water are
              the main objectives of the Halfdan field water flooding. The
              lower mobility of water compared to oil in the Halfdan field
              facilitates an effective sweep of oil but means that the water
              injectors require larger reservoir contact area in order to
              replace voidage. In Halfdan this has been the focus from first
              development and has been obtained by controlled formation of
              10,000-15,000 ft long injection fractures by injection at
              fracturing conditions. Modelling has indicated that conditions
              for propagating injection fractures along the horizontal
              injectors were present, but until recently a field-wide
              verification of the expected uniform sweep has been pending
              seismic identification of the resulting water flood. After five
              years of production, a seismic survey was acquired covering the
              developed area. Analysis of the seismic data has revealed a
              strong signature reflecting the water flooding of the reservoir.
              The seismic imaging of the sweep patterns is observed directly in
              the 3-D data without any 4-D processing and is of an outstanding
              quality even compared to what is normally seen in dedicated time
              lapse seismic studies. The seismic observations confirm the
              modelled behaviour of the Halfdan field water flood. This paper
              presents examples of the seismic observations made and discusses
              these in a rock physics context including fluid substitution and
              pressure effects on acoustic impedance. It is demonstrated how
              the seismic results together with simple analytical models add to
              the quantitative description of injection under fracturing
              conditions by facilitating measures of fracture height,
              connectivity and extent. Introduction},
  journal  = {Offshore Europe},
  number   = {Figure 1},
  pages    = {1--11},
  year     =  2007
}

@ARTICLE{Klinkby2005-um,
  title    = {Mapping and characterization of thin chalk reservoirs using data
              integration: the Kraka Field, Danish North Sea},
  author   = {Klinkby, L and Kristensen, L and Nielsen, E B and
              Zinck-J{\o}rgensen, K and Stemmerik, L},
  abstract = {The integration of 3D seismic data, well logs and synthetic
              seismic data has been used to identify an additional Intra Danian
              seismic horizon in the chalk reservoir of the Kraka Field, Danish
              North Sea. Mapping of this seismic horizon has allowed production
              of a separate thickness map for the main reservoir unit, the
              Danian Porous, in the greater Kraka area. The unit is less than
              25 m thick in most areas and, to produce reliable reservoir maps,
              it has been necessary to use well data to guide the seismic
              interpretation. It is impossible, however, to resolve the
              reservoir stratigraphy properly in areas where the Danian Porous
              is thinner than c.15 m due to tuning effects. The lateral
              porosity distribution has been mapped using a combination of well
              log data and seismic data inverted for acoustic impedance. The
              Danian Porous unit is characterized by average porosities over
              28\% and shows no evidence of depth-related porosity reduction.
              Rather, the impedance data indicate the presence of positive
              porosity anomalies both over the crest and downflank towards the
              southeast. Comparison of impedance-derived porosities with those
              derived from well data indicates that the seismic-based data
              reflect the variations in porosity but underestimate the highest
              porosity by 3--4\%. Faults and fractures are important for
              production of the Kraka Field. Detailed mapping of seismic
              horizons, supplemented with seismic attribute mapping, has proved
              useful for outlining areas with high fault intensity in the
              northwestern part of the field but has been unsuccessful in
              identifying individual faults as recognized from log data},
  journal  = {Pet. Geosci.},
  volume   =  11,
  number   =  2,
  pages    = {113--124},
  month    =  may,
  year     =  2005,
  url      = {http://pg.lyellcollection.org/cgi/doi/10.1144/1354-079304-632},
  keywords = {Chalk; Danian; Porosity estimation; Seismic interpretation},
  issn     = {1354-0793},
  pmid     = {16198},
  doi      = {10.1144/1354-079304-632}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Lindelow-Marsden2013-mr,
  title   = {Using {4D} Seismic to Validate the Geomodel for the South Arne
             Chalk Field},
  author  = {Lindelow-Marsden, C and Jensen, L},
  journal = {SPE Reservoir …},
  number  = {September},
  pages   = {16--18},
  year    =  2013,
  url     = {http://www.onepetro.org/mslib/servlet/onepetropreview?id=SPE-166022-MS}
}

@ARTICLE{Calvert2014-we,
  title   = {Insights into sweep efficiency using {4D} seismic at Halfdan field
             in the North Sea},
  author  = {Calvert, M A and Vagg, L D and Lafond, K B and Hoover, A R and
             Ooi, K C and Herbert, I H},
  journal = {Lead. Edge},
  number  =  2,
  pages   = {182--187},
  year    =  2014,
  url     = {http://dx.doi.org/10.1190/tle33020182.1},
  issn    = {1070-485X},
  doi     = {10.1190/tle33020182.1}
}

@TECHREPORT{Ramboll2015-bv,
  title  = {{MAERSK} {OIL} {ESIA-16} {ENVIRONMENTAL} {AND} {SOCIAL} {IMPACT}
            {STATEMENT} - {DAN}},
  author = {{Ramboll}},
  year   =  2015
}

@TECHREPORT{Ramboll2015-kw,
  title  = {{MAERSK} {OIL} {ESIA-16} {ENVIRONMENTAL} {AND} {SOCIAL} {IMPACT}
            {STATEMENT} - {HALFDAN}},
  author = {{Ramboll}},
  year   =  2015
}

@ARTICLE{Jakobsen2010-rx,
  title    = {Late Cretaceous basin development of the southern Danish Central
              Graben},
  author   = {Jakobsen, Finn and Andersen, Claus},
  journal  = {Bull. Geol. Soc. Den.},
  pages    = {15--18},
  year     =  2010,
  url      = {http://academicpublishingplatforms.com/downloads/pdfs/gsdg/volume1/201112301211_GSDG_2010_1.pdf},
  keywords = {Denmark; Geological Survey of Denmark and Greenland, survey;
              Greenland; current research; survey organisations}
}

@INPROCEEDINGS{Thomasen1994-dp,
  title     = {Dipping Fluid Contacts in the Kraka Field, Danish North Sea},
  booktitle = {{SPE} Annual Technical Conference and Exhibition},
  author    = {Thomasen, J B and Jacobsen, N L},
  abstract  = {The orientation of fluid contacts in chalk fields of the
               southern North Sea is influenced by a regional hydrodynamic
               gradient in the chalk aquifer. This paper describes how dipping
               contacts have been modelled in the Kraka field by integration of
               geophysical, geological, petrophysical and reservoir engineering
               data. The Kraka field is a thin oil accuumulation developed with
               long horizontal wells. The main reservoir is fractured chalk of
               Palaeocene (Danian) age. The field is located in the southern
               part of the Danish North Sea. The orientation of the fracture
               free water level (FWL) in Kraka was initially inferred from a
               lateral gradient in the virgin aquifer pressures between three
               wells. Subsequently, during the process of matching a
               theoretical saturation curve to the logged water saturations, a
               tilt of the matrix oil-water contact (OWC) was identified. In
               order to model this tilt it was necessary to assume a FWL with
               the same orientation as the fracture FWL interpreted from
               pressure data. Further support of the existence of dipping fluid
               levels was provided by a seismically mapped dipping planar
               anomaly interpreted as a fluid contact. The outline of this
               anomaly is in very good agreement with the OWC obtained from
               saturation modelling. Thus, three data sources (pressures,
               saturation modelling and seismic mapping) have independently
               provided evidence of tilted fluid contacts in the Kraka field.
               The validity of the model has subsequently been supported by
               data from new wells.},
  publisher = {Society of Petroleum Engineers},
  month     =  apr,
  year      =  1994,
  url       = {http://www.onepetro.org/doi/10.2118/28435-MS},
  doi       = {10.2118/28435-MS}
}

@ARTICLE{Lumley1998-yq,
  title    = {Practical Issues of {4D} Seismic Reservoir Monitoring: What an
              Engineer Needs to Know},
  author   = {Lumley, D E and Behrens, R A},
  abstract = {Time-lapse three-dimensional (3D) seismic, which geophysicists
              often abbreviate to four-dimensional (4D) seismic, has the
              ability to image fluid flow in the interwell volume by repeating
              a series of 3D seismic surveys over time. Four-dimensional
              seismic shows great potential in reservoir monitoring and
              management for mapping bypassed oil, monitoring fluid contacts
              and injection fronts, identifying pressure compartmentalization,
              and characterizing the fluid-flow properties of faults. However,
              many practical issues can complicate the simple underlying
              concept of a 4D project. We address these practical issues from
              the perspective of a reservoir engineer on an asset team by
              asking a series of practical questions and discussing them with
              examples from several of Chevron's ongoing 4D projects. We
              discuss feasibility tests, technical risks, and the cost of doing
              4D seismic. A 4D project must pass three critical tests to be
              successful in a particular reservoir: Is the reservoir rock
              highly compressible and porous? Is there a large compressibility
              contrast and sufficient saturation changes over time between the
              monitored fluids? and Is it possible to obtain high-quality 3D
              seismic data in the area with clear reservoir images and highly
              repeatable seismic acquisition? The risks associated with a 4D
              seismic project include false anomalies caused by artifacts of
              time-lapse seismic acquisition and processing and the ambiguity
              of seismic interpretation in trying to relate time-lapse changes
              in seismic data to changes in saturation, pressure, temperature,
              or rock properties. The cost of 4D seismic can be viewed as a
              surcharge on anticipated well work and expressed as a cost ratio
              (seismic/wells), which our analysis shows ranges from 5 to 35\%
              on land, 10 to 50\% on marine shelf properties, and 5 to 10\% in
              deepwater fields. Four-dimensional seismic is an emerging
              technology that holds great promise for reservoir management
              applications, but the significant practical issues involved can
              make or break any 4D project and need to be carefully considered.
              Introduction Four-dimensional seismic reservoir monitoring is the
              process of repeating a series of 3D seismic surveys over a
              producing reservoir in time-lapse mode. It has a potentially huge
              impact in reservoir management because it is the first technique
              that may allow engineers to image dynamic reservoir processes1
              such as fluid movement,2 pressure build-up,3 and heat flow4,5 in
              a reservoir in a true volumetric sense. However, we demonstrate
              that practical operational issues easily can complicate the
              simple underlying concept. These issues include requiring the
              right mix of business drivers, a favorable technical risk
              assessment and feasibility study, a highly repeatable seismic
              acquisition survey design, careful high-resolution
              amplitude-preserved seismic data processing, and an ultimate
              reconciliation of 4D seismic images with independent reservoir
              borehole data and history-matched flow simulations. The practical
              issues associated with 4D seismic suggest that it is not a
              panacea. Four-dimensional seismic is an exciting new emerging
              technology that requires careful analysis and integration with
              traditional engineering data and workflows to be successful. Our
              objective in this paper is to provide an overview of the 4D
              seismic method and illuminate the practical issues important to
              an asset team reservoir engineer. For this reason, we do not
              present a comprehensive case study of a single 4D project here,
              but instead draw examples from several Chevron 4D projects to
              illustrate each of our points. We have structured this paper as a
              series of questions an engineer should ask before undertaking any
              4D seismic project: What is 4D seismic? What can 4D seismic do
              for me? Will 4D seismic work in my reservoir? What are the risks
              with 4D seismic? What does 4D seismic cost? We answer these
              questions, highlight important issues, and offer lessons learned,
              rules of thumb, and general words of advice. What Is 4D Seismic?
              To describe the basic concepts underlying 4D seismic, we briefly
              review the seismic method in general6 and then consider the
              advantages of the time-lapse aspect of 4D seismic. In a single 3D
              seismic survey, seismic sources (dynamite, airguns, vibrators,
              etc.) generate seismic waves at or near the earth's surface.
              These source waves reflect off subsurface seismic impedance
              contrasts that are a function of rock and fluid compressibility,
              shear modulus, and bulk density. Arrays of receivers (geophones
              or hydrophones) record the reflected seismic waves as they arrive
              back at the earth's surface. Applying a wave-equation-imaging
              algorithm7 to the recorded wavefield creates a 3D seismic image
              of the reservoir rock and fluid property contrasts that are
              responsible for the reflections. Four-dimensional seismic
              analysis involves simply repeating the 3D seismic surveys, such
              that the fourth dimension is calendar time,8 to construct and
              compare seismic images in time-lapse mode to monitor time-varying
              processes in the subsurface during reservoir production. The term
              4D seismic is usually reserved for time-lapse 3D seismic, as
              opposed to other time-lapse seismic techniques that do not have
              3D volumetric coverage [e.g., twodimensional (2D) surface
              seismic, and the borehole seismic methods of vertical seismic
              profiling and crosswell seismic9,10]. Four-dimensional seismic
              has all the traditional reservoir characterization benefits of 3D
              seismic,11 plus the major additional benefit that fluid-flow
              features may be imaged directly. To first order, seismic images
              are sensitive to spatial contrasts in two distinct types of
              reservoir properties: time-invariant static geology properties
              such as lithology, porosity, and shale content; and time-varying
              dynamic fluid-flow properties such as fluid saturation, pore
              pressure, and temperature. Fig. 1 shows how the seismic impedance
              of rock samples with varying porosity changes as the pore
              saturation changes from oil-full to water-swept conditions. Given
              a single 3D seismic survey, representing a single snapshot in
              time of the reservoir, the static geology and dynamic fluid-flow
              contributions to the seismic image couple nonuniquely and are,
              therefore, difficult to separate unambiguously. For example, it
              may be impossible to distinguish a fluid contact from a
              lithologic boundary in a single seismic image, as shown in Frames
              1 and 2 of Fig. 2. Examining the difference between time-lapse 3D
              seismic images (i.e., 4D seismic) allows the time-invariant
              geologic contributions to cancel, resulting in a direct image of
              the time-varying changes caused by reservoir fluid flow (Frame 3
              of Fig. 2). In this way, the 4D seismic technique has the
              potential to image reservoirscale changes in fluid saturation,
              pore pressure, and temperature during production.},
  journal  = {SPE Reserv. Eval. Eng.},
  volume   =  1,
  number   =  06,
  pages    = {528--538},
  month    =  dec,
  year     =  1998,
  url      = {http://www.onepetro.org/mslib/servlet/onepetropreview?id=00053004},
  issn     = {1094-6470},
  doi      = {10.2118/53004-PA}
}

@ARTICLE{Cho2013-vd,
  title   = {
             4D-attenuation-analysis-for-permeability-estimates-in-hydraulically-induced
             induced fractures},
  author  = {Cho, D and Goodway, B and Perez, M and Iverson, A and Margrave, G},
  journal = {CSEG Recorder},
  volume  =  38,
  number  =  1,
  pages   = {1--7},
  year    =  2013
}

@INPROCEEDINGS{Cho2013-xo,
  title  = {Time Lapse Attenuation Analysis to Estimate Permeability in
            Hydraulically Induced Fractures},
  author = {Cho, D and Goodway, B and Perez, M and Iverson, A and Margrave, G F},
  year   =  2013,
  url    = {http://www.earthdoc.org/publication/publicationdetails/?publication=69165},
  doi    = {10.3997/2214-4609.20130289}
}

@ARTICLE{Sagi2013-bd,
  title    = {Quantifying fracture density and connectivity of fractured chalk
              reservoirs from core samples: implications for fluid flow},
  author   = {Sagi, D A and Arnhild, M and Karlo, J F},
  abstract = {Fractured carbonate reservoirs, characterized by high structural
              porosity/permeability, are of great economic importance because
              in such systems a single well can access large volumes of easily
              migrating hydrocarbons. Therefore, the accurate quantification of
              fracture density and connectivity values within a reservoir can
              be an important input for reservoir models and field development
              plans. However, a large number of the fractures that are present
              in a field are smaller than the resolution of most industry
              standards methods. In this paper we use two independent methods
              to quantify small-scale fracture density and connectivity, such
              as two-dimensional image analysis of slabbed cores and
              rubble-size measurements.},
  journal  = {Geological Society, London, Special Publications},
  volume   =  374,
  year     =  2013,
  url      = {http://dx.doi.org/10.1144/SP374.16},
  issn     = {0305-8719},
  doi      = {10.1144/SP374.16}
}

@ARTICLE{Gennaro2013-ae,
  title    = {Seismic stratigraphy of the Chalk Group in the Norwegian Central
              Graben, North Sea},
  author   = {Gennaro, M and Wonham, J P and Gawthorpe, R and S{\ae}len, G},
  abstract = {The Late Cretaceous to Early Palaeogene Chalk Group in the
              Norwegian Central Graben contains prolific hydrocarbon reservoirs
              that have been producing at high rate for more than forty years.
              Based on integration of regionally extensive 3D seismic data and
              numerous wells, this paper describes the seismic development of
              the Chalk Group with particular focus to the syndepositional
              geomorphological features produced by the activity of bottom
              currents and large-scale gravity flows. Using standard seismic
              stratigraphic interpretation techniques, eight seismic sequence
              boundaries are identified, which in turn define seven seismic
              stratigraphic sequences characterized by different seismic facies
              and well log signatures. The seismic sequences can be grouped
              into three sequence groups that reflect the general
              tectono-stratigraphic evolution of the chalk depositional system
              in the Norwegian Central Graben. During the Late Cretaceous,
              uplift of the Lindesnes Ridge and the Albuskjell Anticline due to
              inversion tectonic and halokinesis modified the physiography of
              the Norwegian Central Graben basin and affected the style of
              chalk sedimentation by influencing the location and importance of
              gravity flows. In addition, bottom currents, sea-level
              fluctuations and environment changes significantly influenced the
              chalk depositional system creating regional unconformities and
              influencing the input of terrigenous material in the chalk
              epeiric sea. ?? 2013 Elsevier Ltd.},
  journal  = {Mar. Pet. Geol.},
  volume   =  45,
  year     =  2013,
  url      = {http://dx.doi.org/10.1016/j.marpetgeo.2013.04.010},
  issn     = {0264-8172},
  doi      = {10.1016/j.marpetgeo.2013.04.010}
}

@ARTICLE{Stewart2007-bh,
  title    = {Salt tectonics in the North Sea Basin: a structural style
              template for seismic interpreters},
  author   = {Stewart, S a},
  abstract = {The North Sea Basin contains a widespread Permian salt layer that
              reached a depositional thickness of c. 1 km in the basin centre.
              This layer profoundly affected structural style of the post-salt
              succession and the basin can be divided into structural domains
              on this basis. In combination with regional 3D seismic data and
              several thousand wells this makes the North Sea a natural
              laboratory for salt tectonics. Four principal structural domains
              are illustrated here. (1) Minibasin subsidence and salt wall
              growth on the West Central Shelf in the Late Permian to Triassic.
              This area was exhumed and differentially eroded prior to Jurassic
              rifting, creating palaeogeomorphology analogous to the
              present-day Paradox Basin, Utah. (2) Regional tilt during the
              Mesozoic and Cenozoic led to basin-scale gravity sliding with
              updip detached extensional faults and downdip compressional
              structures, similar to gravity sliding in the circum-Atlantic
              salt basins. (3) Jurassic rifting propagated across the salt
              basin, displaying spatial variation in extensional fault style,
              partly as a function of salt layer thickness. (4) North Sea salt
              thickness was not sufficient for salt canopy development but
              there are two suites of minor intrusions: cylindrical, passive
              diapirs with associated fault and fracture patterns in the
              central North Sea, and sills where Permian salt from reactive
              diapirs intruded along thin Triassic salt layers in the southern
              North Sea. Cretaceous to Palaeogene regional shortening affected
              all these domains, resulting in a variety of reactivation styles
              that do not fit within commonly used definitions of inversion
              tectonics. The North Sea salt tectonic domains form the basis of
              a matrix approach to salt structure initiating and driving
              mechanisms, and a mechanostratigraphic scheme for tectonic
              structure classification.},
  journal  = {Geological Society, London, Special Publications},
  volume   =  272,
  number   =  1,
  pages    = {361--396},
  year     =  2007,
  url      = {http://dx.doi.org/10.1144/GSL.SP.2007.272.01.19},
  issn     = {0305-8719},
  doi      = {10.1144/GSL.SP.2007.272.01.19}
}

@ARTICLE{Barkved2005-md,
  title   = {Seismic time-lapse effects and stress changes: Examples from a
             compacting reservoir},
  author  = {Barkved, Olav I and Kristiansen, Tron},
  journal = {Lead. Edge},
  volume  =  24,
  number  =  12,
  pages   = {1244--1248},
  month   =  dec,
  year    =  2005,
  url     = {http://library.seg.org/doi/10.1190/1.2149636},
  issn    = {1070-485X},
  doi     = {10.1190/1.2149636}
}

@ARTICLE{Russell_undated-zt,
  title  = {Integrating rock physics modeling , pre- stack inversion and
            Bayesian classification},
  author = {Russell, Brian}
}

@MISC{Frykman2003-cn,
  title   = {Modelling of dynamic fluid contacts in chalk reservoirs},
  author  = {Frykman, P and Vejbaek, O V and Beck, Niels},
  journal = {GEUS Report},
  year    =  2003
}

@ARTICLE{Oliver2011-eo,
  title    = {Recent progress on reservoir history matching: A review},
  author   = {Oliver, Dean S and Chen, Yan},
  abstract = {History matching is a type of inverse problem in which observed
              reservoir behavior is used to estimate reservoir model variables
              that caused the behavior. Obtaining even a single history-matched
              reservoir model requires a substantial amount of effort, but the
              past decade has seen remarkable progress in the ability to
              generate reservoir simulation models that match large amounts of
              production data. Progress can be partially attributed to an
              increase in computational power, but the widespread adoption of
              geostatistics and Monte Carlo methods has also contributed
              indirectly. In this review paper, we will summarize key
              developments in history matching and then review many of the
              accomplishments of the past decade, including developments in
              reparameterization of the model variables, methods for
              computation of the sensitivity coefficients, and methods for
              quantifying uncertainty. An attempt has been made to compare
              representative procedures and to identify possible limitations of
              each.},
  journal  = {Computational Geosciences},
  volume   =  15,
  number   =  1,
  pages    = {185--221},
  year     =  2011,
  url      = {http://dx.doi.org/10.1007/s10596-010-9194-2},
  keywords = {Ensemble Kalman filter; History matching; Parameterization;
              Review},
  issn     = {1420-0597},
  doi      = {10.1007/s10596-010-9194-2}
}

@ARTICLE{Herwanger2005-uh,
  title   = {Predicting time-lapse stress effects in seismic data},
  author  = {Herwanger, Jorg and Horne, Steve},
  journal = {Lead. Edge},
  volume  =  24,
  number  =  12,
  pages   = {1234--1242},
  month   =  dec,
  year    =  2005,
  url     = {http://library.seg.org/doi/10.1190/1.2149632},
  issn    = {1070-485X},
  doi     = {10.1190/1.2149632}
}

@ARTICLE{Kenter2004-uj,
  title  = {Geomechanics and {4D} : Evaluation of reservoir characteristics
            from timeshifts in the overburden},
  author = {{Kenter}},
  year   =  2004
}

@ARTICLE{Herwanger2009-wp,
  title   = {Linking reservoir geomechanics and time-lapse seismics: Predicting
             anisotropic velocity changes and seismic attributes},
  author  = {Herwanger, Jorg V and Horne, Steve A},
  journal = {Geophysics},
  volume  =  74,
  number  =  4,
  pages   = {W13--W33},
  month   =  jul,
  year    =  2009,
  url     = {http://library.seg.org/doi/10.1190/1.3122407},
  issn    = {0016-8033},
  doi     = {10.1190/1.3122407}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Hatchell2005-fg,
  title     = {Measuring reservoir compaction using time‐lapse timeshifts},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2005},
  author    = {Hatchell, P J and Bourne, S J},
  publisher = {Society of Exploration Geophysicists},
  pages     = {2500--2503},
  month     =  jan,
  year      =  2005,
  url       = {http://library.seg.org/doi/abs/10.1190/1.2148230},
  doi       = {10.1190/1.2148230}
}

@INPROCEEDINGS{Hatchell2003-le,
  title     = {Whole earth 4D: Reservoir monitoring geomechanics},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2003},
  author    = {Hatchell, P J and van den Beukel, A and Molenaar, M M and Maron,
               K P and Kenter, C J and Stammeijer, J G F and van der Velde, J J
               and Sayers, C M},
  publisher = {Society of Exploration Geophysicists},
  pages     = {1330--1333},
  month     =  jan,
  year      =  2003,
  url       = {http://library.seg.org/doi/abs/10.1190/1.1817532},
  doi       = {10.1190/1.1817532}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Minkoff1999-ez,
  title     = {Coupled geomechanics and flow simulation for time‐lapse seismic
               modeling},
  booktitle = {{SEG} Technical Program Expanded Abstracts 1999},
  author    = {Minkoff, Susan E and Stone, Charles M and Arguello, J Guadalupe
               and Bryant, Steve and Eaton, Joe and Peszynska, Malgo and
               Wheeler, Mary},
  publisher = {Society of Exploration Geophysicists},
  pages     = {1667--1670},
  month     =  jan,
  year      =  1999,
  url       = {http://library.seg.org/doi/abs/10.1190/1.1820852},
  doi       = {10.1190/1.1820852}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Hall2002-dt,
  title     = {Time‐lapse seismic monitoring of compaction and subsidence at
               Valhall through cross‐matching and interpreted warping of {3D}
               streamer and {OBC} data},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2002},
  author    = {Hall, Stephen A and MacBeth, Colin and Barkved, Olav I and Wild,
               Phil},
  publisher = {Society of Exploration Geophysicists},
  pages     = {1696--1699},
  month     =  jan,
  year      =  2002,
  url       = {http://library.seg.org/doi/abs/10.1190/1.1817004},
  doi       = {10.1190/1.1817004}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Hatchell2007-zw,
  title     = {Monitoring reservoir compaction from subsidence and time‐lapse
               time shifts in the Dan field},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2007},
  author    = {Hatchell, P J and Jorgensen, O and Gommesen, L and Stammeijer, J},
  publisher = {Society of Exploration Geophysicists},
  pages     = {2867--2871},
  month     =  jan,
  year      =  2007,
  url       = {http://library.seg.org/doi/abs/10.1190/1.2793062},
  doi       = {10.1190/1.2793062}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Hudson2005-fb,
  title     = {Genesis field, Gulf of Mexico, 4‐D project status and
               preliminary lookback},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2005},
  author    = {Hudson, Tom and Regel, Bernard and Bretches, John and Rickett,
               James and Cerney, Brian and Inderwiesen, Phil},
  publisher = {Society of Exploration Geophysicists},
  pages     = {2436--2439},
  month     =  jan,
  year      =  2005,
  url       = {http://library.seg.org/doi/abs/10.1190/1.2148214},
  doi       = {10.1190/1.2148214}
}

@INPROCEEDINGS{R_Schiott2006-iw,
  title  = {Plan, Acquire, Process and Interpret - How to Turn Around a Time
            Lapse Survey in Three Weeks},
  author = {R. Schiott, C and King, A},
  month  =  jun,
  year   =  2006,
  url    = {http://www.earthdoc.org/publication/publicationdetails/?publication=507},
  doi    = {10.3997/2214-4609.201402397}
}

@INPROCEEDINGS{Herwanger2007-vn,
  title  = {Field Observations and Modeling {Production-Induced} {Time-Shifts}
            in {4D} Seismic Data at South Arne, Danish North Sea},
  author = {Herwanger, J and Palmer, E and R. Schi{\o}tt, C},
  month  =  jun,
  year   =  2007,
  url    = {http://www.earthdoc.org/publication/publicationdetails/?publication=6801},
  doi    = {10.3997/2214-4609.201401716}
}

@INPROCEEDINGS{Barkved2005-pq,
  title     = {The {4D} seismic response of a compacting reservoir---examples
               from the Valhall Field, Norway},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2005},
  author    = {Barkved, Olav I and Kristiansen, Tron and Fj{\ae}r, Erling},
  publisher = {Society of Exploration Geophysicists},
  pages     = {2508--2511},
  month     =  jan,
  year      =  2005,
  url       = {http://library.seg.org/doi/abs/10.1190/1.2148232},
  doi       = {10.1190/1.2148232}
}

@ARTICLE{Guilbot2002-fo,
  title   = {{4-D} constrained depth conversion for reservoir compaction
             estimation: Application to Ekofisk Field},
  author  = {Guilbot, J{\'e}r{\^o}me and Smith, Brackin},
  journal = {Lead. Edge},
  volume  =  21,
  number  =  3,
  pages   = {302--308},
  month   =  mar,
  year    =  2002,
  url     = {http://library.seg.org/doi/10.1190/1.1463782},
  issn    = {1070-485X},
  doi     = {10.1190/1.1463782}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Janssen2006-tq,
  title     = {Measuring velocity sensitivity to production‐induced strain at
               the Ekofisk Field using time‐lapse time‐shifts and compaction
               logs},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2006},
  author    = {Janssen, Aaron L and Smith, Brackin A and Byerley, Grant W},
  publisher = {Society of Exploration Geophysicists},
  pages     = {3200--3204},
  month     =  jan,
  year      =  2006,
  url       = {http://library.seg.org/doi/abs/10.1190/1.2370195},
  doi       = {10.1190/1.2370195}
}


@ARTICLE{Lary2016-aa,
  title    = {Machine learning in geosciences and remote sensing},
  author   = {Lary, David J and Alavi, Amir H and Gandomi, Amir H and Walker,
              Annette L},
  abstract = {Learning incorporates a broad range of complex procedures.
              Machine learning (ML) is a subdivision of artificial intelligence
              based on the biological learning process. The ML approach deals
              with the design of algorithms to learn from machine readable
              data. ML covers main domains such as data mining,
              difficult-to-program applications, and software applications. It
              is a collection of a variety of algorithms (e.g. neural networks,
              support vector machines, self-organizing map, decision trees,
              random forests, case-based reasoning, genetic programming, etc.)
              that can provide multivariate, nonlinear, nonparametric
              regression or classification. The modeling capabilities of the
              ML-based methods have resulted in their extensive applications in
              science and engineering. Herein, the role of ML as an effective
              approach for solving problems in geosciences and remote sensing
              will be highlighted. The unique features of some of the ML
              techniques will be outlined with a specific attention to genetic
              programming paradigm. Furthermore, nonparametric regression and
              classification illustrative examples are presented to demonstrate
              the efficiency of ML for tackling the geosciences and remote
              sensing problems.},
  journal  = {Geoscience Frontiers},
  volume   =  7,
  number   =  1,
  pages    = {3--10},
  month    =  jan,
  year     =  2016,
  url      = {http://www.sciencedirect.com/science/article/pii/S1674987115000821},
  keywords = {Machine learning; Geosciences; Remote sensing; Regression;
              Classification},
  issn     = {1674-9871},
  doi      = {10.1016/j.gsf.2015.07.003}
}



% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Goodfellow2014-ax,
  title     = {Generative Adversarial Nets},
  booktitle = {Advances in Neural Information Processing Systems 27},
  author    = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu,
               Bing and Warde-Farley, David and Ozair, Sherjil and Courville,
               Aaron and Bengio, Yoshua},
  editor    = {Ghahramani, Z and Welling, M and Cortes, C and Lawrence, N D and
               Weinberger, K Q},
  abstract  = {… Like generative adversarial networks , variational
               autoencoders pair a differentiable generator network with a
               second neural network . Unlike generative adversarial networks ,
               the sec- ond network in a VAE is a recognition model that
               performs approximate inference …},
  publisher = {Curran Associates, Inc.},
  pages     = {2672--2680},
  year      =  2014,
  url       = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf}
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Goldberg1988-ch,
  title     = {Genetic Algorithms and Machine Learning},
  author    = {Goldberg, David E and Holland, John H},
  abstract  = {There is no a priori reason why machine learning must borrow
               from nature. A field could exist, complete with well-defined
               algorithms, data structures, and theories of learning , without
               once referring to organisms, cognitive or genetic structures,
               and psychological or …},
  journal   = {Mach. Learn.},
  publisher = {Kluwer Academic Publishers-Plenum Publishers},
  volume    =  3,
  number    = {2-3},
  pages     = {95--99},
  month     =  oct,
  year      =  1988,
  url       = {https://link.springer.com/article/10.1023/A:1022602019183},
  language  = {en},
  issn      = {0885-6125, 1573-0565},
  doi       = {10.1023/A:1022602019183}
}


@ARTICLE{Goodfellow2016-jf,
  title   = {Deep learning (adaptive computation and machine learning series)},
  author  = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  journal = {Adaptive Computation and Machine Learning series},
  pages   = {800},
  year    =  2016
}


@ARTICLE{Mjolsness2001-fq,
  title    = {Machine learning for science: state of the art and future
              prospects},
  author   = {Mjolsness, E and DeCoste, D},
  abstract = {Recent advances in machine learning methods, along with
              successful applications across a wide variety of fields such as
              planetary science and bioinformatics, promise powerful new tools
              for practicing scientists. This viewpoint highlights some useful
              characteristics of modern machine learning methods and their
              relevance to scientific applications. We conclude with some
              speculations on near-term progress and promising directions.},
  journal  = {Science},
  volume   =  293,
  number   =  5537,
  pages    = {2051--2055},
  month    =  sep,
  year     =  2001,
  url      = {http://dx.doi.org/10.1126/science.293.5537.2051},
  language = {en},
  issn     = {0036-8075},
  pmid     = {11557883},
  doi      = {10.1126/science.293.5537.2051}
}


@ARTICLE{Jordan2015-hj,
  title    = {Machine learning: Trends, perspectives, and prospects},
  author   = {Jordan, M I and Mitchell, T M},
  abstract = {Machine learning addresses the question of how to build computers
              that improve automatically through experience. It is one of
              today's most rapidly growing technical fields, lying at the
              intersection of computer science and statistics, and at the core
              of artificial intelligence and data science. Recent progress in
              machine learning has been driven both by the development of new
              learning algorithms and theory and by the ongoing explosion in
              the availability of online data and low-cost computation. The
              adoption of data-intensive machine-learning methods can be found
              throughout science, technology and commerce, leading to more
              evidence-based decision-making across many walks of life,
              including health care, manufacturing, education, financial
              modeling, policing, and marketing.},
  journal  = {Science},
  volume   =  349,
  number   =  6245,
  pages    = {255--260},
  month    =  jul,
  year     =  2015,
  url      = {http://dx.doi.org/10.1126/science.aaa8415},
  language = {en},
  issn     = {0036-8075, 1095-9203},
  pmid     = {26185243},
  doi      = {10.1126/science.aaa8415}
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Sambridge1993-tx,
  title     = {Earthquake hypocenter location using genetic algorithms},
  author    = {Sambridge, Malcolm and Gallagher, Kerry},
  abstract  = {A new method for hypocenter location is proposed introducing
               some recent developments in global optimization techniques. The
               approach is based on the use of genetic algorithms to minimize
               some misfit criteria of the data. The method does not use
               derivative information …},
  journal   = {Bull. Seismol. Soc. Am.},
  publisher = {GeoScienceWorld},
  volume    =  83,
  number    =  5,
  pages     = {1467--1491},
  month     =  oct,
  year      =  1993,
  url       = {https://pubs.geoscienceworld.org/ssa/bssa/article-abstract/83/5/1467/119743},
  issn      = {0037-1106}
}


@ARTICLE{Walda2015-ec,
  title   = {Global optimization of the {CRS} operator using a genetic
             algorithm: 77th Annual International Conference and Exhibition,
             {EAGE}},
  author  = {Walda, J and Gajewski, D},
  journal = {Extended Abstracts, We N},
  volume  =  107,
  pages   = {09},
  year    =  2015
}

@misc{tensorflow,
title={{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={http://tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dan~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

  
@inproceedings{pytorch,
  title={Automatic Differentiation in {PyTorch}},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  booktitle={NIPS Autodiff Workshop},
  year={2017}
}

@ARTICLE{Kadurin2017-oq,
  title     = {{druGAN}: An Advanced Generative Adversarial Autoencoder Model
               for de Novo Generation of New Molecules with Desired Molecular
               Properties in Silico},
  author    = {Kadurin, Artur and Nikolenko, Sergey and Khrabrov, Kuzma and
               Aliper, Alex and Zhavoronkov, Alex},
  abstract  = {Deep generative adversarial networks (GANs) are the emerging
               technology in drug discovery and biomarker development. In our
               recent work, we demonstrated a proof-of-concept of implementing
               deep generative adversarial autoencoder (AAE) to identify new
               molecular fingerprints with predefined anticancer properties.
               Another popular generative model is the variational autoencoder
               (VAE), which is based on deep neural architectures. In this
               work, we developed an advanced AAE model for molecular feature
               extraction problems, and demonstrated its advantages compared to
               VAE in terms of (a) adjustability in generating molecular
               fingerprints; (b) capacity of processing very large molecular
               data sets; and (c) efficiency in unsupervised pretraining for
               regression model. Our results suggest that the proposed AAE
               model significantly enhances the capacity and efficiency of
               development of the new molecules with specific anticancer
               properties using the deep generative models.},
  journal   = {Mol. Pharm.},
  publisher = {ACS Publications},
  volume    =  14,
  number    =  9,
  pages     = {3098--3104},
  month     =  sep,
  year      =  2017,
  url       = {http://dx.doi.org/10.1021/acs.molpharmaceut.7b00346},
  keywords  = {adversarial autoencoder; deep learning; drug discovery;
               generative adversarial network; variational autoencoder},
  language  = {en},
  issn      = {1543-8384, 1543-8392},
  pmid      = {28703000},
  doi       = {10.1021/acs.molpharmaceut.7b00346}
}

@ARTICLE{Shen2017-nt,
  title    = {Deep Learning in Medical Image Analysis},
  author   = {Shen, Dinggang and Wu, Guorong and Suk, Heung-Il},
  abstract = {This review covers computer-assisted analysis of images in the
              field of medical imaging. Recent advances in machine learning,
              especially with regard to deep learning, are helping to identify,
              classify, and quantify patterns in medical images. At the core of
              these advances is the ability to exploit hierarchical feature
              representations learned solely from data, instead of features
              designed by hand according to domain-specific knowledge. Deep
              learning is rapidly becoming the state of the art, leading to
              enhanced performance in various medical applications. We
              introduce the fundamentals of deep learning methods and review
              their successes in image registration, detection of anatomical
              and cellular structures, tissue segmentation, computer-aided
              disease diagnosis and prognosis, and so on. We conclude by
              discussing research issues and suggesting future directions for
              further improvement.},
  journal  = {Annu. Rev. Biomed. Eng.},
  volume   =  19,
  pages    = {221--248},
  month    =  jun,
  year     =  2017,
  url      = {http://dx.doi.org/10.1146/annurev-bioeng-071516-044442},
  keywords = {deep learning; medical image analysis; unsupervised feature
              learning},
  language = {en},
  issn     = {1523-9829, 1545-4274},
  pmid     = {28301734},
  doi      = {10.1146/annurev-bioeng-071516-044442},
  pmc      = {PMC5479722}
}

@BOOK{Bishop2016-mj,
  title     = {Pattern Recognition and Machine Learning},
  author    = {Bishop, Christopher M},
  abstract  = {Pattern recognition has its origins in engineering, whereas
               machine learning grew out of computer science. However, these
               activities can be viewed as two facets of the same field, and
               together they have undergone substantial development over the
               past ten years. In particular, Bayesian methods have grown from
               a specialist niche to become mainstream, while graphical models
               have emerged as a general framework for describing and applying
               probabilistic models. Also, the practical applicability of
               Bayesian methods has been greatly enhanced through the
               development of a range of approximate inference algorithms such
               as variational Bayes and expectation pro- gation. Similarly, new
               models based on kernels have had signi?cant impact on both
               algorithms and applications. This new textbook re?ects these
               recent developments while providing a comp- hensive introduction
               to the ?elds of pattern recognition and machine learning. It is
               aimed at advanced undergraduates or ?rst year PhD students, as
               well as researchers and practitioners, and assumes no previous
               knowledge of pattern recognition or - chine learning concepts.
               Knowledge of multivariate calculus and basic linear algebra is
               required, and some familiarity with probabilities would be
               helpful though not - sential as the book includes a
               self-contained introduction to basic probability theory.},
  publisher = {Springer New York},
  month     =  aug,
  year      =  2016,
  url       = {https://market.android.com/details?id=book-kOXDtAEACAAJ},
  language  = {en},
  isbn      = {9781493938438}
}

@ARTICLE{Schutt2017-sh,
  title    = {Quantum-chemical insights from deep tensor neural networks},
  author   = {Sch{\"u}tt, Kristof T and Arbabzadah, Farhad and Chmiela, Stefan
              and M{\"u}ller, Klaus R and Tkatchenko, Alexandre},
  abstract = {Learning from data has led to paradigm shifts in a multitude of
              disciplines, including web, text and image search, speech
              recognition, as well as bioinformatics. Can machine learning
              enable similar breakthroughs in understanding quantum many-body
              systems? Here we develop an efficient deep learning approach that
              enables spatially and chemically resolved insights into
              quantum-mechanical observables of molecular systems. We unify
              concepts from many-body Hamiltonians with purpose-designed deep
              tensor neural networks, which leads to size-extensive and
              uniformly accurate (1 kcal mol-1) predictions in compositional
              and configurational chemical space for molecules of intermediate
              size. As an example of chemical relevance, the model reveals a
              classification of aromatic rings with respect to their stability.
              Further applications of our model for predicting atomic energies
              and local chemical potentials in molecules, reliable isomer
              energies, and molecules with peculiar electronic structure
              demonstrate the potential of machine learning for revealing
              insights into complex quantum-chemical systems.},
  journal  = {Nat. Commun.},
  volume   =  8,
  pages    = {13890},
  month    =  jan,
  year     =  2017,
  url      = {http://dx.doi.org/10.1038/ncomms13890},
  language = {en},
  issn     = {2041-1723},
  pmid     = {28067221},
  doi      = {10.1038/ncomms13890},
  pmc      = {PMC5228054}
}

@ARTICLE{Ching2018-hg,
  title    = {Opportunities and obstacles for deep learning in biology and
              medicine},
  author   = {Ching, Travers and Himmelstein, Daniel S and Beaulieu-Jones,
              Brett K and Kalinin, Alexandr A and Do, Brian T and Way, Gregory
              P and Ferrero, Enrico and Agapow, Paul-Michael and Zietz, Michael
              and Hoffman, Michael M and Xie, Wei and Rosen, Gail L and
              Lengerich, Benjamin J and Israeli, Johnny and Lanchantin, Jack
              and Woloszynek, Stephen and Carpenter, Anne E and Shrikumar,
              Avanti and Xu, Jinbo and Cofer, Evan M and Lavender, Christopher
              A and Turaga, Srinivas C and Alexandari, Amr M and Lu, Zhiyong
              and Harris, David J and DeCaprio, Dave and Qi, Yanjun and
              Kundaje, Anshul and Peng, Yifan and Wiley, Laura K and Segler,
              Marwin H S and Boca, Simina M and Swamidass, S Joshua and Huang,
              Austin and Gitter, Anthony and Greene, Casey S},
  abstract = {Deep learning describes a class of machine learning algorithms
              that are capable of combining raw inputs into layers of
              intermediate features. These algorithms have recently shown
              impressive results across a variety of domains. Biology and
              medicine are data-rich disciplines, but the data are complex and
              often ill-understood. Hence, deep learning techniques may be
              particularly well suited to solve problems of these fields. We
              examine applications of deep learning to a variety of biomedical
              problems-patient classification, fundamental biological processes
              and treatment of patients-and discuss whether deep learning will
              be able to transform these tasks or if the biomedical sphere
              poses unique challenges. Following from an extensive literature
              review, we find that deep learning has yet to revolutionize
              biomedicine or definitively resolve any of the most pressing
              challenges in the field, but promising advances have been made on
              the prior state of the art. Even though improvements over
              previous baselines have been modest in general, the recent
              progress indicates that deep learning methods will provide
              valuable means for speeding up or aiding human investigation.
              Though progress has been made linking a specific neural network's
              prediction to input features, understanding how users should
              interpret these models to make testable hypotheses about the
              system under study remains an open challenge. Furthermore, the
              limited amount of labelled data for training presents problems in
              some domains, as do legal and privacy constraints on work with
              sensitive health records. Nonetheless, we foresee deep learning
              enabling changes at both bench and bedside with the potential to
              transform several areas of biology and medicine.},
  journal  = {J. R. Soc. Interface},
  volume   =  15,
  number   =  141,
  month    =  apr,
  year     =  2018,
  url      = {http://dx.doi.org/10.1098/rsif.2017.0387},
  keywords = {deep learning; genomics; machine learning; precision medicine},
  language = {en},
  issn     = {1742-5689, 1742-5662},
  pmid     = {29618526},
  doi      = {10.1098/rsif.2017.0387},
  pmc      = {PMC5938574}
}

@ARTICLE{Hornik1989-bl,
  title    = {Multilayer feedforward networks are universal approximators},
  author   = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  abstract = {This paper rigorously establishes that standard multilayer
              feedforward networks with as few as one hidden layer using
              arbitrary squashing functions are capable of approximating any
              Borel measurable function from one finite dimensional space to
              another to any desired degree of accuracy, provided sufficiently
              many hidden units are available. In this sense, multilayer
              feedforward networks are a class of universal approximators.},
  journal  = {Neural Netw.},
  volume   =  2,
  number   =  5,
  pages    = {359--366},
  month    =  jan,
  year     =  1989,
  url      = {http://www.sciencedirect.com/science/article/pii/0893608089900208},
  keywords = {Feedforward networks; Universal approximation; Mapping networks;
              Network representation capability; Stone-Weierstrass Theorem;
              Squashing functions; Sigma-Pi networks; Back-propagation networks},
  issn     = {0893-6080},
  doi      = {10.1016/0893-6080(89)90020-8}
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Ebaid2009-oe,
  title     = {Time‐lapse seismic makes a significant business impact at
               Holstein},
  booktitle = {{SEG} Technical Program Expanded Abstracts 2009},
  author    = {Ebaid, Hesham and Nasser, Mosab and Hatchell, Paul and Stanley,
               Darrell},
  publisher = {Society of Exploration Geophysicists},
  pages     = {3810--3814},
  month     =  jan,
  year      =  2009,
  url       = {http://library.seg.org/doi/abs/10.1190/1.3255661},
  doi       = {10.1190/1.3255661}
}




@incollection{huang1990self,
  title={Self-organizing neural network for picking seismic horizons},
  author={Huang, Kou-Yuan and Chang, William RI and Yen, HT},
  booktitle={SEG Technical Program Expanded Abstracts 1990},
  pages={313--316},
  year={1990},
  publisher={Society of Exploration Geophysicists}
}
@inproceedings{akhmetov2018operational,
  title={Operational Selection of Wells for Hydraulic Fracturing Treatment Through Machine Learning},
  author={Akhmetov, A and Shishaev, G},
  booktitle={Saint Petersburg 2018},
  year={2018}
}
@article{alregib2018subsurface,
  title={Subsurface Structure Analysis Using Computational Interpretation and Learning: A Visual Signal Processing Perspective},
  author={AlRegib, Ghassan and Deriche, Mohamed and Long, Zhiling and Di, Haibin and Wang, Zhen and Alaudah, Yazeed and Shafiq, Muhammad Amir and Alfarraj, Motaz},
  journal={IEEE Signal Processing Magazine},
  volume={35},
  number={2},
  pages={82--98},
  year={2018},
  publisher={IEEE}
}
@inproceedings{anifowose2017carbonate,
  title={Carbonate Reservoir Cementation Factor Modeling Using Wireline Logs and Artificial Intelligence Methodology},
  author={Anifowose, F and Ayadiuno, C and Rashedian, F},
  booktitle={79th EAGE Conference and Exhibition 2017-Workshops},
  year={2017}
}
@article{araya2017automated,
  title={Automated fault detection without seismic processing},
  author={Araya-Polo, Mauricio and Dahlke, Taylor and Frogner, Charlie and Zhang, Chiyuan and Poggio, Tomaso and Hohl, Detlef},
  journal={The Leading Edge},
  volume={36},
  number={3},
  pages={208--214},
  year={2017},
  publisher={Society of Exploration Geophysicists}
}
@article{araya2018deep,
  title={Deep-learning tomography},
  author={Araya-Polo, Mauricio and Jennings, Joseph and Adler, Amir and Dahlke, Taylor},
  journal={The Leading Edge},
  volume={37},
  number={1},
  pages={58--66},
  year={2018},
  publisher={Society of Exploration Geophysicists}
}
@article{asefa2005support,
  title={Support vector machines for nonlinear state space reconstruction: Application to the Great Salt Lake time series},
  author={Asefa, Tirusew and Kemblowski, Mariush and Lall, Upmanu and Urroz, Gilberto},
  journal={Water resources research},
  volume={41},
  number={12},
  year={2005},
  publisher={Wiley Online Library}
}
@article{bauer2008neural,
  title={Neural network analysis of crosshole tomographic images: The seismic signature of gas hydrate bearing sediments in the Mackenzie Delta (NW Canada)},
  author={Bauer, K and Pratt, RG and Haberland, C and Weber, M},
  journal={Geophysical Research Letters},
  volume={35},
  number={19},
  year={2008},
  publisher={Wiley Online Library}
}

@misc{keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  howpublished={\url{https://keras.io}},
}
@article{turing1950,
    author = {Turing, Alan M.},
    title = {{I.—Computing Machinery and Intelligence}},
    journal = {Mind},
    volume = {LIX},
    number = {236},
    pages = {433-460},
    year = {1950},
    month = {10},
    issn = {0026-4423},
    doi = {10.1093/mind/LIX.236.433},
    url = {https://doi.org/10.1093/mind/LIX.236.433},
    eprint = {http://oup.prod.sis.lan/mind/article-pdf/LIX/236/433/30123314/lix-236-433.pdf},
}


@article{belson1959matching,
  title={Matching and prediction on the principle of biological classification},
  author={Belson, William A},
  journal={Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  volume={8},
  number={2},
  pages={65--75},
  year={1959},
  publisher={Wiley Online Library}
}

@book{taylor1843scientific,
  title={Scientific memoirs, selected from the transactions of foreign academies of science and learned societies, and from foreign journals},
  author={Taylor, Richard},
  volume={3},
  year={1843},
  publisher={R. and JE Taylor}
}

@article{bayes1763lii,
  title={LII. An essay towards solving a problem in the doctrine of chances. By the late Rev. Mr. Bayes, FRS communicated by Mr. Price, in a letter to John Canton, AMFR S},
  author={Bayes, Thomas},
  journal={Philosophical transactions of the Royal Society of London},
  number={53},
  pages={370--418},
  year={1763},
  publisher={The Royal Society London}
}


@article{markov1906rasprostranenie,
  title={Rasprostranenie zakona bol’shih chisel na velichiny, zavisyaschie drug ot druga},
  author={Markov, Andrei Andreevich},
  journal={Izvestiya Fiziko-matematicheskogo obschestva pri Kazanskom universitete},
  volume={15},
  number={135-156},
  pages={18},
  year={1906}
}

@article{markov1971extension,
  title={Extension of the limit theorems of probability theory to a sum of variables connected in a chain},
  author={Andrey Andreyevich Markov},
  journal={Dynamic probabilistic systems},
  volume={1},
  pages={552--577},
  year={1971},
  publisher={Wiley New York},
  note={Reprint in English of \citep{markov1906rasprostranenie}}
}

@book{russelnorvig,
  author    = {Stuart J. Russell and
               Peter Norvig},
  title     = {Artificial Intelligence - {A} Modern Approach, Third International
               Edition},
  publisher = {Pearson Education},
  year      = {2010},
  url       = {http://vig.pearsoned.com/store/product/1,1207,store-12521\_isbn-0136042597,00.html},
  isbn      = {978-0-13-207148-2},
  timestamp = {Mon, 15 Jul 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/bib/books/daglib/0023820},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{rosenblatt1958perceptron,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Frank Rosenblatt},
  journal={Psychological review},
  volume={65},
  number={6},
  pages={386},
  year={1958},
  publisher={American Psychological Association}
}

@article{cover1967nearest,
  title={Nearest neighbor pattern classification},
  author={Cover, Thomas and Hart, Peter},
  journal={IEEE transactions on information theory},
  volume={13},
  number={1},
  pages={21--27},
  year={1967},
  publisher={IEEE}
}

@phdthesis{Krige1951,
address = {Johannesburg},
author = {Krige, D G},
language = {English},
publisher = {Univ. of the Witwatersrand},
title = {{A statistical approach to some mine valuation and allied problems on the Witwatersrand}},
year = {1951}
}

@inproceedings{gulrajani2017improved,
  title={Improved training of wasserstein gans},
  author={Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
  booktitle={Advances in neural information processing systems},
  pages={5767--5777},
  year={2017}
}

@article{nash1951non,
  title={Non-cooperative games},
  author={Nash, John},
  journal={Annals of mathematics},
  pages={286--295},
  year={1951},
  publisher={JSTOR}
}

@book{deeplearningbook,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{kolmogorov1939interpolation,
  title={Sur l’interpolation et extrapolation des suites stationnaires},
  author={Kolmogorov, Andrei Nikolaevitch},
  journal={CR Acad Sci},
  volume={208},
  pages={2043--2045},
  year={1939},
  publisher={Paris}
}

@article{watkins1989learning,
  title={Learning from delayed rewards},
  author={Watkins, Christopher John Cornish Hellaby},
  year={1989},
  publisher={King's College, Cambridge}
}

@inproceedings{ho1995random,
  title={Random decision forests},
  author={Ho, Tin Kam},
  booktitle={Proceedings of 3rd international conference on document analysis and recognition},
  volume={1},
  pages={278--282},
  year={1995},
  organization={IEEE}
}

@article{cortes1995support,
  title={Support-vector networks},
  author={Cortes, Corinna and Vapnik, Vladimir},
  journal={Machine learning},
  volume={20},
  number={3},
  pages={273--297},
  year={1995},
  publisher={Springer}
}

@article{linnainmaa1970representation,
  title={The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors},
  author={Linnainmaa, Seppo},
  journal={Master's Thesis (in Finnish), Univ. Helsinki},
  pages={6--7},
  year={1970}
}

@article{rumelhart1988learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J and others},
  journal={Cognitive modeling},
  volume={5},
  number={3},
  pages={1},
  year={1988}
}

@techreport{collobert2002torch,
  title={Torch: a modular machine learning software library},
  author={Collobert, Ronan and Bengio, Samy and Mari{\'e}thoz, Johnny},
  year={2002},
  institution={Idiap}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@article{imagenetresults,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@inproceedings{sklearn_api,
  author    = {Lars Buitinck and Gilles Louppe and Mathieu Blondel and
               Fabian Pedregosa and Andreas Mueller and Olivier Grisel and
               Vlad Niculae and Peter Prettenhofer and Alexandre Gramfort
               and Jaques Grobler and Robert Layton and Jake VanderPlas and
               Arnaud Joly and Brian Holt and Ga{\"{e}}l Varoquaux},
  title     = {{API} design for machine learning software: experiences from the scikit-learn
               project},
  booktitle = {ECML PKDD Workshop: Languages for Data Mining and Machine Learning},
  year      = {2013},
  pages = {108--122},
}

@article{libsvm,
 author = {Chang, Chih-Chung and Lin, Chih-Jen},
 title = {LIBSVM: A Library for Support Vector Machines},
 journal = {ACM Trans. Intell. Syst. Technol.},
 issue_date = {April 2011},
 volume = {2},
 number = {3},
 month = may,
 year = {2011},
 issn = {2157-6904},
 pages = {27:1--27:27},
 articleno = {27},
 numpages = {27},
 url = {http://doi.acm.org/10.1145/1961189.1961199},
 doi = {10.1145/1961189.1961199},
 acmid = {1961199},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Classification LIBSVM optimization regression support vector machines SVM},
}

@inproceedings{xgboost,
 author = {Chen, Tianqi and Guestrin, Carlos},
 title = {{XGBoost}: A Scalable Tree Boosting System},
 booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '16},
 year = {2016},
 isbn = {978-1-4503-4232-2},
 location = {San Francisco, California, USA},
 pages = {785--794},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2939672.2939785},
 doi = {10.1145/2939672.2939785},
 acmid = {2939785},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {large-scale machine learning},
}

@inproceedings{bennett2007netflix,
  title={The netflix prize},
  author={Bennett, James and Lanning, Stan and others},
  booktitle={Proceedings of KDD cup and workshop},
  volume={2007},
  pages={35},
  year={2007},
  organization={New York, NY, USA.}
}

@inproceedings{goodfellow2013challenges,
  title={Challenges in representation learning: A report on three machine learning contests},
  author={Goodfellow, Ian J and Erhan, Dumitru and Carrier, Pierre Luc and Courville, Aaron and Mirza, Mehdi and Hamner, Ben and Cukierski, Will and Tang, Yichuan and Thaler, David and Lee, Dong-Hyun and others},
  booktitle={International Conference on Neural Information Processing},
  pages={117--124},
  year={2013},
  organization={Springer}
}

@inproceedings{ILSVRCanalysis_ICCV2013,
 author = {Olga Russakovsky and Jia Deng and Zhiheng Huang and Alexander C. Berg and Li Fei-Fei},
 title = {Detecting avocados to zucchinis: what have we done, and where are we going?},
 booktitle = {International Conference on Computer Vision (ICCV)},
 year = {2013}
}

@article{fukushima1980neocognitron,
  title={Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
  author={Fukushima, Kunihiko},
  journal={Biological cybernetics},
  volume={36},
  number={4},
  pages={193--202},
  year={1980},
  publisher={Springer}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{hopfield1982neural,
  title={Neural networks and physical systems with emergent collective computational abilities},
  author={Hopfield, John J},
  journal={Proceedings of the national academy of sciences},
  volume={79},
  number={8},
  pages={2554--2558},
  year={1982},
  publisher={National Acad Sciences}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@inproceedings{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}

@incollection{lecun2012efficient,
  title={Efficient backprop},
  author={LeCun, Yann A and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  booktitle={Neural networks: Tricks of the trade},
  pages={9--48},
  year={2012},
  publisher={Springer}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010}
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}

@article{kelley1960gradient,
  title={Gradient theory of optimal flight paths},
  author={Kelley, Henry J},
  journal={Ars Journal},
  volume={30},
  number={10},
  pages={947--954},
  year={1960}
}

@inproceedings{bryson1961gradient,
  title={A gradient method for optimizing multi-stage allocation processes},
  author={Bryson, Arthur E},
  booktitle={Proc. Harvard Univ. Symposium on digital computers and their applications},
  volume={72},
  year={1961}
}

@article{dreyfus1962numerical,
  title={The numerical solution of variational problems},
  author={Dreyfus, Stuart},
  journal={Journal of Mathematical Analysis and Applications},
  volume={5},
  number={1},
  pages={30--45},
  year={1962},
  publisher={Academic Press}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv},
  eprint={arXiv:1412.6980},
  year={2014}
}

@article{bishop1995training,
  title={Training with noise is equivalent to Tikhonov regularization},
  author={Bishop, Chris M},
  journal={Neural computation},
  volume={7},
  number={1},
  pages={108--116},
  year={1995},
  publisher={MIT Press}
}

@InProceedings{pmlr-v28-sutskever13,
  title = 	 {On the importance of initialization and momentum in deep learning},
  author = 	 {Ilya Sutskever and James Martens and George Dahl and Geoffrey Hinton},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {1139--1147},
  year = 	 {2013},
  editor = 	 {Sanjoy Dasgupta and David McAllester},
  volume = 	 {28},
  number =       {3},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/sutskever13.pdf},
  url = 	 {http://proceedings.mlr.press/v28/sutskever13.html},
  abstract = 	 {Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned.     Our success training these models suggests that previous attempts to train deep and recurrent neural networks from random initializations have likely failed due to poor initialization schemes. Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods.}
}


@inproceedings{krogh1992simple,
  title={A simple weight decay can improve generalization},
  author={Krogh, Anders and Hertz, John A},
  booktitle={Advances in neural information processing systems},
  pages={950--957},
  year={1992}
}

@incollection{schwarzacher1972semi,
  title={The semi-Markov process as a general sedimentation model},
  author={Schwarzacher, Walther},
  booktitle={Mathematical Models of Sedimentary Processes},
  pages={247--268},
  year={1972},
  publisher={Springer}
}

@article{bergstra2015hyperopt,
  title={Hyperopt: a python library for model selection and hyperparameter optimization},
  author={Bergstra, James and Komer, Brent and Eliasmith, Chris and Yamins, Dan and Cox, David D},
  journal={Computational Science \& Discovery},
  volume={8},
  number={1},
  pages={014008},
  year={2015},
  publisher={IOP Publishing}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}


@inproceedings{real2019regularized,
  title={Regularized evolution for image classifier architecture search},
  author={Real, Esteban and Aggarwal, Alok and Huang, Yanping and Le, Quoc V},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={4780--4789},
  year={2019}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@article{tan2019efficientnet,
  title={EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  author={Tan, Mingxing and Le, Quoc V},
  journal={arXiv preprint arXiv:1905.11946},
  year={2019}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

@inproceedings{szegedy2017inception,
  title={Inception-v4, inception-resnet and the impact of residual connections on learning},
  author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander A},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}


@article{tan2019mixconv,
  title={MixConv: Mixed Depthwise Convolutional Kernels},
  author={Tan, Mingxing and Le, Quoc V},
  journal={CoRR, abs/1907.09595},
  year={2019}
}

@inproceedings{zoph2018learning,
  title={Learning transferable architectures for scalable image recognition},
  author={Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8697--8710},
  year={2018}
}

@inproceedings{tan2019mnasnet,
  title={Mnasnet: Platform-aware neural architecture search for mobile},
  author={Tan, Mingxing and Chen, Bo and Pang, Ruoming and Vasudevan, Vijay and Sandler, Mark and Howard, Andrew and Le, Quoc V},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2820--2828},
  year={2019}
}

@article{touvron2019fixing,
  title={Fixing the train-test resolution discrepancy},
  author={Touvron, Hugo and Vedaldi, Andrea and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:1906.06423},
  year={2019}
}

@inproceedings{he2019bag,
  title={Bag of tricks for image classification with convolutional neural networks},
  author={He, Tong and Zhang, Zhi and Zhang, Hang and Zhang, Zhongyue and Xie, Junyuan and Li, Mu},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={558--567},
  year={2019}
}

@inproceedings{xie2017aggregated,
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1492--1500},
  year={2017}
}

@article{chen2019drop,
  title={Drop an octave: Reducing spatial redundancy in convolutional neural networks with octave convolution},
  author={Chen, Yunpeng and Fang, Haoqi and Xu, Bing and Yan, Zhicheng and Kalantidis, Yannis and Rohrbach, Marcus and Yan, Shuicheng and Feng, Jiashi},
  journal={arXiv preprint arXiv:1904.05049},
  year={2019}
}