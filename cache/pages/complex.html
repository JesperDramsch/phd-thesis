<p><a class="reference external" href="../2019.1.pdf"><img alt="image9" src="https://img.shields.io/badge/PDF-Download-important" /></a> <a class="reference external" href="https://github.com/JesperDramsch/Complex-CNN-Seismic"><img alt="image10" src="https://img.shields.io/github/repo-size/JesperDramsch/Complex-CNN-Seismic" /></a> <img alt="image11" src="https://img.shields.io/badge/license-Apache--2.0-green" /></p>
<blockquote>
<p>Preprint: <a class="reference external" href="https://orcid.org/0000-0001-8273-905X">Dramsch, J. S.</a>,
<a class="reference external" href="https://orcid.org/0000-0003-2715-1653">Lüthje, M.</a>, &amp;
<a class="reference external" href="https://orcid.org/0000-0002-3668-3128">Christensen, A. N.</a>
(2019). Complex-valued neural networks for machine learning on
non-stationary physical data. arXiv preprint
arXiv:<a class="reference external" href="https://arxiv.org/abs/1905.12321">1905.12321</a>.</p>
</blockquote>
<ul class="simple">
<li><p>Github: <a class="reference external" href="https://github.com/JesperDramsch/Complex-CNN-Seismic">https://github.com/JesperDramsch/Complex-CNN-Seismic</a></p></li>
</ul>
<hr class="docutils" />
<p>In the paper (Jesper Sören Dramsch, Lüthje, and Christensen 2019) I
explore complex-valued deep convolutional networks to show that phase
content in non-stationary data improves generalization of cnns. This
work implements self-supervised aes that compress the data and measure
the reconstruction of the seismic data.</p>
<p>Four different deep convolutional aes are constructed. Two aes are
real-valued and two aes are complex-valued. The complex-valued cnn is
implemented as two real-valued feature maps, one for the real component
<span class="math">\(a\)</span> and one for the complex component <span class="math">\(b\)</span> each, which are
combined into a complex-valued number with <span class="math">\(a + b\text{i}\)</span>. The
complex convolution is then implemented explicitly in the calculation to
avoid some drawbacks of using complex numbers by a computer. However,
matching the networks proved to be a complicated task with regard to the
number of parameters. This led to building four different architectures
that get progressively bigger and compare the results.</p>
<p>This study implements aes to increase the validity of this experiment.
While vaes have shown better performance on reconstruction tasks, it
would also introduce more variability in the network to control for.
Considering that asi is a fairly new discipline, it is difficult to
disambiguate effects on misclassification. These effects include
erroneous labels, the difficulty of the task of asi, as well as the
choice of architecture.</p>
<p>Therefore, this leads us to the decision to inspect the reconstructed
seismic data numerically. Signal analysis is well-explored in the
seismic data processing. Moreover, this enables analysing the result in
the fk-domain providing additional insight to the denoising effect of
the aes. Overall, the complex-valued networks result in smaller networks
compared to a larger real-valued network achieving comparable
reconstruction error.</p>
<div class="section" id="journal-paper-complex-valued-neural-networks-for-machine-learning-on-non-stationary-physical-data">
<span id="sec-complexpaper"></span><h1>Journal Paper: Complex-valued neural networks for machine learning on non-stationary physical data</h1>
<div class="section" id="introduction">
<span id="introduction-2"></span><h2>Introduction</h2>
<p>Seismic data has its caveats due to the complicated nature of
bandwidth-limited wave-based imaging. Common problems are cycle-skipping
of wavelets and nullspaces in inversion problems (Özdoğan Yilmaz 2001).
Automatic seismic interpretation is complicated, as the modelling of
seismic data is computationally expensive and often proprietary. Seismic
field data is often not available and their interpretation is highly
subjective and ground truth is not available. The lack of training data
has been delaying the adoption of existing methods and hindering the
development of specific geophysical deep learning methods. Incorporating
domain knowledge into general deep learning models has been successful
in other fields (Paganini, Oliveira, and Nachman 2017).</p>
<p>The state-of-the-art method has been an iterative windowed Fourier
transform for phase reconstruction (Griffin and Lim 1984). Modern neural
audio synthesis focuses on methods that do not require explicit
reconstruction of the phase (Mehri et al. 2016; Oord et al. 2016, 2017;
Prenger, Valle, and Catanzaro 2018). Mehri et al. (2016) introduced a
recurrent neural network formulation, where Oord et al. (2016)
reformulated the network for audio synthesis in a strided convolutional
network. The original WaveNet formulation in Oord et al. (2016) is slow
due to the autoregressive filter, warranting the parallel formulation in
Oord et al. (2017).</p>
<p>We explicitly incorporate phase information in a deep convolutional
neural network. These have been heavily explored in the digital signal
processing community, before the recent renaissance of neural networks
and deep learning. Relevant examples to seismic data processing include
source separation (Scarpiniti et al. 2008), adaptive noise reduction
(Suksmono and Hirose 2002), and optical flow (Miyauchi et al. 1993) with
complex-valued neural networks. Sarroff (2018) gives a comprehensive
overview of applications of complex-valued neural networks in signal and
image processing.</p>
<p>In this work, we evaluate the reconstruction error after compression in
an autoencoder to test how reliable information can be contained within
a network with and without explicit phase information. This insight can
be transferred to the aforementioned applications that benefit from an
increase in information recovery. We calculate the complex-valued
seismic trace by applying the Hilbert transform to each trace. Phase
information has been shown to be valuable in the processing (Liner 2002)
and interpretation of seismic data (Rocky Roden and Sepúlveda 1999;
Mavko, Mukerji, and Dvorkin 2003). Steve Purves (2014) provides a
tutorial that shows the implementation details of Hilbert transforms.</p>
<p>In this paper we give a brief overview of convolutional neural networks
and then introduce the extension to complex neural networks and seismic
data. We show that including explicit phase information provides
superior results to real-valued convolutional neural networks for
seismic data. Difficult areas that contain seismic discontinuities due
to geologic faulting are resolved better without leakage of seismic
horizons. We train and evaluate several complex-valued and real-valued
autoencoders to show and compare these properties. These results can be
directly extended to automatic seismic interpretation problems.</p>
</div>
<div class="section" id="complex-convolutional-neural-networks">
<h2>Complex Convolutional Neural Networks</h2>
<div class="section" id="basic-principles">
<h3>Basic principles</h3>
<p>Convolutional neural networks (Y. LeCun et al. 1999) use multiple layers
of convolution and subsampling to extract relevant information from the
data (see Figure <a class="reference external" href="#complex:fig:3">[complex:fig:3]</a>)</p>
<p>The input image is repeatedly convolved with filters and subsampled.
This creates many, but smaller and smaller images. For a classification
task, the final step is then a weighting of these very small images
leading to a decision about what was in the original image. The filters
are learned as part of the training process by exposing the network to
training images. The salient point is, that the convolution kernels are
learned based on the training. If the goal is - for example - to
classify geological facies, the convolutional kernels will learn to
extract information from the input, that helps with that task. It is
thus a very strong methodology, that can be adapted to many tasks.</p>
</div>
<div class="section" id="real-and-complex-valued-convolution">
<span id="sec-conv"></span><h3>Real- and Complex-valued Convolution</h3>
<p>Convolution is an operation on two signals f and g or a signal and a
filter that produce a third signal, containing information from both of
the inputs. An example is the moving average filter, which smoothes the
input, acting as a low-pass filter. Convolution is defined as</p>
<div class="math">
\begin{equation*}
f(t)*g(t)=\int_{-\infty}^\infty f(\tau)g(t-\tau)d\tau,
\end{equation*}
</div>
<p>at the location <span class="math">\(\tau\)</span>. While often applied to real value signals,
convolution can be used on complex signals. For the integral to exist
both <span class="math">\(f\)</span> and <span class="math">\(g\)</span> must decay when approaching infinity.
Convolution is directly generalizable to N-dimensions by multiple
integrations and maintains commutativity, distributivity, and
associativity. In digital signals this extends to discrete values by
replacing the integration with summation.</p>
</div>
<div class="section" id="id1">
<span id="complex-convolutional-neural-networks-1"></span><h3>Complex Convolutional Neural Networks</h3>
<div class="figure">
<img alt="Implementation details of Complex Convolution (Courtesy Trabelsi et al. (2017))" id="complex-fig-4" src="../images/image9.png" />
<p class="caption">Implementation details of Complex Convolution (Courtesy Trabelsi et al. (2017))</p>
</div>
<p>Complex convolutional networks provide the benefit of explicitly
modelling the phase space of physical systems (Trabelsi et al. 2017).
Unfortunately it is not possible to feed complex numbers directly to a
CNN, as they are not supported by any of the standard implementations
(PyTorch or Tensorflow). Instead, we can represent them in another form.
The complex convolution introduced in Section <a class="reference external" href="#sec:conv">14.1.2.2</a>,
can be explicitly implemented as convolutions of the real and complex
components of both kernels and the data. A complex-valued data matrix in
cartesian notation is defined as <span class="math">\(\textbf{M} = M_\Re + i M_\Im\)</span>
and equally, the complex-valued convolutional kernel is defined as
<span class="math">\(\textbf{K} = K_\Re + i K_\Im\)</span>. The individual coefficients
<span class="math">\((M_\Re, M_\Im, K_\Re, K_\Im)\)</span> are real-valued matrices,
considering vectors are special cases of matrices with one of two
dimensions being one.</p>
<p>Solving the convolution of</p>
<div class="math">
\begin{equation*}
M' = K * M = (M_\Re + i M_\Im) * (K_\Re + i K_\Im),
\end{equation*}
</div>
<p>we can apply the distributivity of convolutions
(cf. section <a class="reference external" href="#sec:conv">14.1.2.2</a>) to obtain</p>
<div class="math">
\begin{equation*}
M' =  \{M_\Re * K_\Re - M_\Im * K_\Im\} + i \{ M_\Re * K_\Im + M_\Im * K_\Re\},
\end{equation*}
</div>
<p>where <span class="math">\(K\)</span> is the Kernel and <span class="math">\(M\)</span> is a data vector (see
Figure <a class="reference external" href="#complex:fig:4">14.1</a>).</p>
<p>We can reformulate this in algebraic notation</p>
<div class="math">
\begin{equation*}
\begin{bmatrix} \Re\{M * K\} \\ \Im\{M * K\} \end{bmatrix} = \begin{bmatrix} K_{\Re} &amp; -K_{\Im} \\ K_{\Im} &amp; K_{\Re} \end{bmatrix} * \begin{bmatrix}  M_{\Re} \\ M_{\Im} \end{bmatrix}
\end{equation*}
</div>
<p>Complex convolutional neural networks learn by back-propagation.
Sarroff, Shepardson, and Casey (2015) state that the activation
functions, as well as the loss function must be complex differentiable
(holomorphic). Trabelsi et al. (2017) suggest that employing complex
losses and activation functions is valid for speed, however, refers that
Hirose and Yoshida (2012) show that complex-valued networks can be
optimized individually with real-valued loss functions and contain
piecewise real-valued activations. We reimplement the code Trabelsi et
al. (2017) provides in keras (Chollet and others 2015a) with tensorflow
(Abadi et al. 2015a), which provides convenience functions implementing
a multitude of real-valued loss functions and activations.</p>
<p>While common up- and downsampling functions like MaxPooling, UpSampling,
or striding do not suffer from complex-valued neural networks, batch
normalization (BN) (Ioffe and Szegedy 2015) does. Real-valued batch
normalization normalizes the data to zero mean and a standard deviation
of 1. This does not guarantee normalization in complex values. Trabelsi
et al. (2017) suggest implementing a 2D whitening operation as
normalization in the following way.</p>
<div class="math">
\begin{equation*}
\widetilde{x} = V^{-\frac{1}{2}} ( x - \mathbb{E}[x] ),
\end{equation*}
</div>
<p>where <span class="math">\(x\)</span> is the data and <span class="math">\(V\)</span> is the 2x2 covariance matrix,
with the covariance matrix being</p>
<div class="math">
\begin{equation*}
V = \begin{bmatrix} V_{\Re\Re} &amp; V_{\Re\Im} \\ V_{\Im\Re} &amp; V_{\Im\Im} \end{bmatrix}
\end{equation*}
</div>
<p>Effectively, this multiplies the inverse of the square root of the
covariance matrix with the zero-centred data. This scales the covariance
of the components instead of the variance of the data (Trabelsi et al.
2017).</p>
</div>
<div class="section" id="autoencoders">
<h3>Autoencoders</h3>
<div class="figure">
<img alt="Typical autoencoder architecture. The data is compressed to a low dimensional bottleneck, and then reconstructed. In the encoder convolutional layers (yellow) are followed by a down-sampling operation (red) to reduce the spatial extend of the input image. The bottleneck contains a lower-dimensional compressed representation of the input. The decoder contains upsampling operations (blue) followed by convolutional layers symmetrical to the encoder. Alternatively, the encoder is sometimes made up of transpose convolutions." id="complex-fig-autoencoder" src="../images/encdec.png" />
<p class="caption">Typical autoencoder architecture. The data is compressed to a low
dimensional bottleneck, and then reconstructed. In the encoder
convolutional layers (yellow) are followed by a down-sampling
operation (red) to reduce the spatial extend of the input image. The
bottleneck contains a lower-dimensional compressed representation of
the input. The decoder contains upsampling operations (blue) followed
by convolutional layers symmetrical to the encoder. Alternatively,
the encoder is sometimes made up of transpose convolutions.</p>
</div>
<p>Autoencoders (Hinton and Salakhutdinov 2006) are a special configuration
of the encoder-decoder network that map data to a low-level
representation and back to the original data. This low-level
representation - the latent space - is often called bottleneck or code
layer. Autoencoder networks map <span class="math">\(f(x) = x\)</span>, where <span class="math">\(x\)</span> is the
data and <span class="math">\(f\)</span> is an arbitrary network. The architecture of
autoencoders is an example of lossy compression and recovery from the
lossy representation. Commonly, recovered data is blurred by this
process.</p>
<p>The principle is illustrated in
figure <a class="reference external" href="#complex:fig:autoencoder">14.2</a>. The input is transformed to
a low-dimensional representation - called a code or latent space - and
then reconstructed again from this low dimensional representation. The
intuition is, that the network has to extract the most salient parts
from the data, to be able to perform a reconstruction. As opposed to
other methods for dimensionality reduction - e.g. principal component
analysis - an autoencoder can find a non-linear representation of the
data. The low-dimensional representation can then be used for anomaly
detection, or classification.</p>
</div>
</div>
<div class="section" id="aliasing-in-patch-based-training">
<h2>Aliasing in Patch-based training</h2>
<div class="section" id="mean-shift-in-neural-networks">
<h3>Mean-Shift in Neural Networks</h3>
<p>A single neuron in a neural network can be described by
<span class="math">\(\sigma ( w \cdot x + b )\)</span>, where <span class="math">\(w\)</span> is the network
weights, <span class="math">\(x\)</span> is the input data, <span class="math">\(b\)</span> is the network bias, and
<span class="math">\(\sigma\)</span> is a non-linear activation function. During training, the
network weights <span class="math">\(w\)</span> and biases <span class="math">\(b\)</span> are are adjusted to a
value that represents the training minimum. Learning on a mean-shift of
<span class="math">\(q\)</span> of an arbitrary distribution over <span class="math">\(x\)</span> leads to
<span class="math">\(\sigma( w \cdot (x + q) + b )\)</span>, which increases the neuron
response by <span class="math">\(q\)</span>, weighted by <span class="math">\(w\)</span>. During inference, both
<span class="math">\(w\)</span> and <span class="math">\(b\)</span> are fixed, by extension the mean-shift <span class="math">\(q\)</span>
is fixed as well. The mean-shift over larger inference data disappears,
introducing an additional bias of <span class="math">\(w \cdot q\)</span> before non-linear
activation. This training bias may lead to prediction errors of the
neuron and consequently the full neural network.</p>
</div>
<div class="section" id="windowed-aliasing">
<h3>Windowed Aliasing</h3>
<p>Non-stationary data such as seismic data can contain sections within the
data that contain spurious offsets from the mean.
Figure <a class="reference external" href="#complex:fig:aliasing">14.3</a> shows varying sizes of cutouts,
with 101 and 256 samples respectively. In the middle, the full
normalised amplitude spectra are presented. On the right, the
corresponding phase spectra are presented. On the left, we focus on the
frequency content of the amplitude spectra around 0 Hz. The cutouts were
Hanning tapered, however, a mean shift appears for any patch size.</p>
<p>These concepts of mean-shift corresponds to a DC offset in spectral
data, which can be audio, seismic or electrical data. In images this
corresponds to a non-zero alpha channel. While batch normalization can
correct the mean shift in individual mini-batches (Ioffe and Szegedy
2015), this may shift the entire spectrum by the aliased offset.
Additionally, batch normalization may not be feasible in some physical
applications pertaining to regression tasks.</p>
<div class="figure">
<img alt="Spectral aliasing dependent on window-size (modified from Jesper Sören Dramsch and Lüthje (2018d)). The true amplitude spectrum (green) is 0 at a frequency of 0 Hz, whereas windows of the data experience low-frequency aliasing that introduce a non-zero offset at 0 Hz analogous to the Nyquist-Shannon theorem for high frequencies." id="complex-fig-aliasing" src="../images/spectral2.png" />
<p class="caption">Spectral aliasing dependent on window-size (modified from Jesper
Sören Dramsch and Lüthje (2018d)). The true amplitude spectrum
(green) is 0 at a frequency of 0 Hz, whereas windows of the data
experience low-frequency aliasing that introduce a non-zero offset at
0 Hz analogous to the Nyquist-Shannon theorem for high frequencies.</p>
</div>
</div>
</div>
<div class="section" id="complex-seismic-data">
<h2>Complex Seismic Data</h2>
<p>Complex seismic traces are calculated by applying the Hilbert transform
to the real-valued signal. The Hilbert transform applies a convolution
with to the signal, which is equivalent to a -90-degree phase rotation.
It is essential that the signal does not contain a DC component, as this
would not have a phase rotation.</p>
<p>The Hilbert transform is defined as</p>
<div class="math">
\begin{equation*}
H(u)(t) = \frac{1}{\pi}\int_{-\infty}^\infty \frac{u(\tau)}{t-\tau}\,d\tau,
\end{equation*}
</div>
<p>of a real-valued time series <span class="math">\(u(t)\)</span>, where the improper integral
has to be interpreted as the Cauchy principal value. In the Fourier
domain, the Hilbert transform has a convenient formulation, where
frequencies are set zero and the remaining frequencies are multiplied by
2. This can be written as</p>
<div class="math">
\begin{equation*}
x_a = F^{-1}(F(x) 2U ) = x + iy
\end{equation*}
</div>
<p>where <span class="math">\(x_a\)</span> is the analytical signal, <span class="math">\(x\)</span> is the real
signal, <span class="math">\(F\)</span> is the Fourier transform, and <span class="math">\(U\)</span> is the step
function. The imaginary component <span class="math">\(y\)</span> is simultaneously the
quadrature of the real-valued trace. This provides locality to explicit
phase information, where the Fourier transform itself does not lend
itself to the resolution of the phase in the time domain. In
conventional seismic trace analysis, the complex data is used to
calculate the instantaneous amplitude and instantaneous frequency. These
are beneficial seismic attributes for interpretation (Barnes 2007).</p>
</div>
<div class="section" id="experiments">
<h2>Experiments</h2>
<div class="section" id="data">
<h3>Data</h3>
<p>The data is the F3 seismic data, acquired in the Dutch North Sea in 1987
over an area of 375.31 km<sup>2</sup>. The sampling-rates are 4 ms in time
and inline/crossline bins of 25 m. The extent being 650 inline traces
and 950 crossline traces with a total length of 1.848 s. The data
contains faulted reflector packets, of which the lowest one overlays a
salt diapir. The data contains some noise that masks lower-amplitude
events.</p>
<p>We generate 2D patches of size 64x64 in the inline and crossline
direction from the 3D volume to train our network. We obtain inline and
crossline 64x64 patches that are taken overlapping with a stride of 8
samples. The total amount of data is 188736 patches with 141552 for
training and 47184 for validation in a 75/25 train-validation split. The
test data is the holdout Alaudah et al. (2019) stored in test_once. The
seismic data is normalized to values in the range of [-1, 1]. To obtain
complex-valued seismic data we apply a Hilbert transform to every trace
of the data and subtract the real-valued seismic from the real component
as laid out in Taner, Koehler, and Sheriff (1979).</p>
</div>
<div class="section" id="architecture">
<h3>Architecture</h3>
<div class="docutils container" id="tab-1">
<table>
<caption>Layers used in the four autoencoders and according
parameter count on the computational graph for complex-valued
convolutions and real-valued convolutions respectively. The spatial
extents in X and Y per layer are kept constant across all networks,
varying the amount of filters. The compression is calculated by
number comparing the total input parameters to the bottleneck
parameters.</caption>
<colgroup>
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 7%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
</colgroup>
<tbody>
<tr><td><p>Layer</p></td>
<td><p>Spatial</p></td>
<td></td>
<td><p>Complex</p></td>
<td><p>Real</p></td>
<td><p>Complex</p></td>
<td><p>Real</p></td>
</tr>
<tr><td><p>(Size)</p></td>
<td><p>X</p></td>
<td><p>Y</p></td>
<td><p>Small</p></td>
<td><p>Small</p></td>
<td><p>Large</p></td>
<td><p>Large</p></td>
</tr>
<tr><td><p>Input</p></td>
<td><p>64</p></td>
<td><p>64</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
</tr>
<tr><td><p>CConv2D</p></td>
<td><p>64</p></td>
<td><p>64</p></td>
<td><p>8</p></td>
<td><p>8</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
</tr>
<tr><td><p>CConv2D
+ BN</p></td>
<td><p>64</p></td>
<td><p>64</p></td>
<td><p>8</p></td>
<td><p>8</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
</tr>
<tr><td><p>Pool +
CConv2D
+ BN</p></td>
<td><p>32</p></td>
<td><p>32</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
<td><p>32</p></td>
<td><p>32</p></td>
</tr>
<tr><td><p>Pool +
CConv2D
+ BN</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
<td><p>32</p></td>
<td><p>32</p></td>
<td><p>64</p></td>
<td><p>64</p></td>
</tr>
<tr><td><p>Pool +
CConv2D
+ BN</p></td>
<td><p>8</p></td>
<td><p>8</p></td>
<td><p>64</p></td>
<td><p>64</p></td>
<td><p>128</p></td>
<td><p>128</p></td>
</tr>
<tr><td><p>Pool +
CConv2D</p></td>
<td><p>4</p></td>
<td><p>4</p></td>
<td><p>128</p></td>
<td><p>128</p></td>
<td><p>256</p></td>
<td><p>256</p></td>
</tr>
<tr><td><p>Up +
CConv2D
+ BN</p></td>
<td><p>8</p></td>
<td><p>8</p></td>
<td><p>64</p></td>
<td><p>64</p></td>
<td><p>128</p></td>
<td><p>128</p></td>
</tr>
<tr><td><p>Up +
CConv2D
+ BN</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
<td><p>32</p></td>
<td><p>32</p></td>
<td><p>64</p></td>
<td><p>64</p></td>
</tr>
<tr><td><p>Up +
CConv2D
+ BN</p></td>
<td><p>32</p></td>
<td><p>32</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
<td><p>32</p></td>
<td><p>32</p></td>
</tr>
<tr><td><p>Up +
CConv2D</p></td>
<td><p>64</p></td>
<td><p>64</p></td>
<td><p>8</p></td>
<td><p>8</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
</tr>
<tr><td><p>CConv2D</p></td>
<td><p>64</p></td>
<td><p>64</p></td>
<td><p>8</p></td>
<td><p>8</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
</tr>
<tr><td><p>CConv2D</p></td>
<td><p>64</p></td>
<td><p>64</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
</tr>
<tr><td><p>Par
ameters
on
Graph</p></td>
<td></td>
<td></td>
<td><p>100,226</p></td>
<td><p>198,001</p></td>
<td><p>397,442</p></td>
<td><p>790,945</p></td>
</tr>
<tr><td><p>Comp
ression
Ratio</p></td>
<td></td>
<td></td>
<td><p>4:1</p></td>
<td><p>2:1</p></td>
<td><p>2:1</p></td>
<td><p>1:1</p></td>
</tr>
<tr><td><p>Size on
Disk
[MB]</p></td>
<td></td>
<td></td>
<td><p>1.4</p></td>
<td><p>2.5</p></td>
<td><p>4.8</p></td>
<td><p>9.2</p></td>
</tr>
</tbody>
</table>
</div>
<p>The autoencoder architecture compresses the input data to a lower
dimensional representation, i.e. bottleneck
(cf. Figure <a class="reference external" href="#complex:fig:autoencoder">14.2</a>), with an encoder
network and reconstruct the input data from the bottleneck with a
decoder network. It is common that the encoder and decoder networks are
formulated symmetrically, as we have done in this paper. We reduce a
64x64 input 4 times by a factor of two spatially to encode a 4x4
encoding layer. We define varying amounts of filters during the
downsampling steps and in the code layer to achieve varying amounts of
compression shown in Table <a class="reference external" href="#tab:1">14.1</a>. The architecture for the
complex convolutional network is identical to the real network, except
for replacing the real-valued 2D convolutions with complex-valued
convolutions represented by two feature maps instead of one. The layers
for each network are shown in Table <a class="reference external" href="#tab:1">14.1</a> with additional
values, including learnable parameters counted on the computational
graph, compression ratio, and size on disk. In total four network
architectures are presented, two real-valued and complex-valued networks
each matched in the number of feature maps, resulting in different
amounts of parameters and compression ratio. The parameters are counted
on the computational graph compiled by Tensorflow.</p>
<p>The neural networks specifically use 2D convolutions with 3x3 kernels.
We employ batch normalization to regularize and speed up training (Ioffe
and Szegedy 2015). The down and up sampling is achieved by MaxPooling
and the UpSampling operation respectively.</p>
<p>Complex-valued neural networks contain two feature maps for every
feature map contained in a real-valued network. Conceptually, this is
equivalent to <span class="math">\(a + \text{i}b\)</span>, with <span class="math">\(b=0\)</span> for the
real-valued network. The information in the complex complement for these
two feature maps is derived from the input data using the Hilbert
transform. Following the argument of deep learning, this input could be
derived from a neural network directly and should not provide an
improvement to the networks reconstruction error. We define a
complex-valued network that has the same number of filters as the
real-valued network in both the &quot;small&quot; and &quot;large&quot; formulation in
Table <a class="reference external" href="#tab:1">14.1</a>. This network effectively has half the available
feature maps for the real-valued seismic input, as the other half is
used for the complex-valued information. That means the smaller
real-valued network contains as many feature maps for the real-valued
seismic as the large complex network, the large real-valued network
contains an additional feature map for every real-valued input for the
complex component.</p>
</div>
<div class="section" id="training">
<h3>Training</h3>
<p>We train the networks with an Adam optimizer (Diederik P. Kingma and Ba
2014) and a learning rate of <span class="math">\(10^{-3}\)</span> without decay, for 100
epochs. The loss function is mean squared error, as the seismic data
contains values in the range of [-1,1]. All networks reach stable
convergence without overfitting, shown in
Figure <a class="reference external" href="#complex:fig:loss">14.4</a>.</p>
<div class="figure">
<img alt="Validation Loss (MSE) on 7 random seeds per network. (Real-valued loss on real-valued seismic and combined complex-valued loss on complex-valued seismic, as the network &quot;sees&quot; it.)" id="complex-fig-loss" src="../images/All-Losses-log.png" />
<p class="caption">Validation Loss (MSE) on 7 random seeds per network. (Real-valued
loss on real-valued seismic and combined complex-valued loss on
complex-valued seismic, as the network &quot;sees&quot; it.)</p>
</div>
</div>
<div class="section" id="evaluation">
<h3>Evaluation</h3>
<p>We compare the complex autoencoders with the real-valued autoencoders,
through the reconstruction error on unseen test data on 7 individual
realizations of the respective four networks and qualitative analysis of
reconstructed images. We focus on evaluating the real-valued
reconstruction of the seismic data for both networks.</p>
</div>
</div>
<div class="section" id="results">
<span id="results-1"></span><h2>Results</h2>
<p>We trained four neural network autoencoders with seven random
initializations for each network, to allow for error bars on the
estimates in Figure <a class="reference external" href="#complex:fig:loss">14.4</a>. The mean squared error
and the mean absolute error for each parameter configuration during
training is given in Table <a class="reference external" href="#tab:2">14.2</a>. There is a clear
correspondence of the reconstruction error of the autoencoder to the
size of network. The real-valued networks outperform the complex-valued
networks in both the mean squared error and mean absolute error,
however, we see that a real-valued network needs around twice as many
parameters as a complex-valued network to attain the same reconstruction
errors.</p>
<div class="figure">
<img alt="Seismic Test Data with marked section for closer inspection. We chose the &quot;top&quot; section for it’s faulted chaotic texture, &quot;bottom&quot; for the faulted blocks, and &quot;silent&quot; for a noisy but geologically uninteresting section." id="complex-fig-eval-seis" src="../images/seismic.png" style="width: 120.0%;" />
<p class="caption">Seismic Test Data with marked section for closer inspection. We chose
the &quot;top&quot; section for it’s faulted chaotic texture, &quot;bottom&quot; for the
faulted blocks, and &quot;silent&quot; for a noisy but geologically
uninteresting section.</p>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="docutils container" id="tab-2">
<table>
<caption>Compression, parameters and errors for networks (lower is better). Losses on network validation. The complex-valued networks achieve similar reconstruction errors at twice the compression values.</caption>
<colgroup>
<col style="width: 19%" />
<col style="width: 19%" />
<col style="width: 18%" />
<col style="width: 22%" />
<col style="width: 22%" />
</colgroup>
<thead>
<tr><th class="head"><p>Network</p></th>
<th class="head"><p>Compression</p></th>
<th class="head"><p>Parameters</p></th>
<th class="head"><p>MSE [x10^-2]</p></th>
<th class="head"><p>MAE [x10^-2]</p></th>
</tr>
</thead>
<tbody>
<tr><td><ol class="arabic simple">
<li><p>C_small</p></li>
</ol>
</td>
<td><p>4:1</p></td>
<td><p>100,226</p></td>
<td><p>0.484 ± 0.013</p></td>
<td><p>4.695 ± 0.058</p></td>
</tr>
<tr><td><ol class="arabic simple" start="2">
<li><p>R_small</p></li>
</ol>
</td>
<td><p>2:1</p></td>
<td><p>198,001</p></td>
<td><p>0.436 ± 0.006</p></td>
<td><p>4.500 ± 0.028</p></td>
</tr>
<tr><td><ol class="arabic simple" start="3">
<li><p>C_big</p></li>
</ol>
</td>
<td><p>2:1</p></td>
<td><p>397,442</p></td>
<td><p>0.227 ± 0.003</p></td>
<td><p>3.247 ± 0.025</p></td>
</tr>
<tr><td><ol class="arabic simple" start="4">
<li><p>R_big</p></li>
</ol>
</td>
<td><p>1:1</p></td>
<td><p>790,945</p></td>
<td><p>0.196 ± 0.002</p></td>
<td><p>3.050 ± 0.013</p></td>
</tr>
</tbody>
</table>
</div>
<p>The seismic sections in Figure <a class="reference external" href="#complex:fig:eval_seis">14.5</a> show
the unseen test seismic section. We perform a closer inspection of the
regions &quot;top&quot; and &quot;bottom&quot; to focus on geologically relevant sections in
the reconstruction process. The noisy segment without strong reflectors
is a good baseline to evaluate the noise reduction of the autoencoder
and the behaviour of the different networks on low amplitude data.
Overall, all networks denoise the original seismic, with the lowest
reconstruction errors being root-mean-squared (RMS) of 0.1187 and MAE of
0.0947 (cf. Table <a class="reference external" href="#tab:errors">14.3</a>).
Figure <a class="reference external" href="#complex:fig:silent_fk">[complex:fig:silent_fk]</a> shows the
frequency-wavenumber (FK) of the ground truth
(<a class="reference external" href="#complex:fig:silent_fk">[complex:fig:silent_fk]</a> (a)) and the large
complex network reconstruction
(<a class="reference external" href="#complex:fig:silent_fk">[complex:fig:silent_fk]</a> (b)). These show a
decrease in the 0 - 60 Hz band for larger absolute wavenumbers.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="docutils container" id="tab-errors">
<table>
<caption>RMS and MAE on real component of Data Patches.</caption>
<colgroup>
<col style="width: 12%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
</colgroup>
<tbody>
<tr><td></td>
<td colspan="2"><p>Full</p></td>
<td colspan="2"><p>Silent</p></td>
<td colspan="2"><p>Top</p></td>
<td colspan="2"><p>Bottom</p></td>
</tr>
<tr><td><p>Network</p></td>
<td><p>RMS</p></td>
<td><p>MAE</p></td>
<td><p>RMS</p></td>
<td><p>MAE</p></td>
<td><p>RMS</p></td>
<td><p>MAE</p></td>
<td><p>RMS</p></td>
<td><p>MAE</p></td>
</tr>
<tr><td><p>C_small</p></td>
<td><p>0.1549</p></td>
<td><p>0.1145</p></td>
<td><p>0.1265</p></td>
<td><p>0.1010</p></td>
<td><p>0.2315</p></td>
<td><p>0.1759</p></td>
<td><p>0.1588</p></td>
<td><p>0.1200</p></td>
</tr>
<tr><td><p>R_small</p></td>
<td><p>0.1581</p></td>
<td><p>0.1153</p></td>
<td><p>0.1247</p></td>
<td><p>0.0994</p></td>
<td><p>0.2395</p></td>
<td><p>0.1810</p></td>
<td><p>0.1612</p></td>
<td><p>0.1205</p></td>
</tr>
<tr><td><p>C_big</p></td>
<td><p>0.1508</p></td>
<td><p>0.1101</p></td>
<td><p>0.1187</p></td>
<td><p>0.0947</p></td>
<td><p>0.2301</p></td>
<td><p>0.1747</p></td>
<td><p>0.1514</p></td>
<td><p>0.1135</p></td>
</tr>
<tr><td><p>R_big</p></td>
<td><p>0.1469</p></td>
<td><p>0.1072</p></td>
<td><p>0.1214</p></td>
<td><p>0.0967</p></td>
<td><p>0.2222</p></td>
<td><p>0.1679</p></td>
<td><p>0.1459</p></td>
<td><p>0.1088</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="top-seismic-section">
<h3>&quot;Top&quot; seismic section</h3>
<p>The &quot;top&quot; segment contains strong reflections that are very faulted with
strong reflectors. Figure <a class="reference external" href="#complex:fig:top">[complex:fig:top]</a> shows
the top segment and the reconstructions of the four networks. All
networks display various amounts of smoothing. The quantitative results
show that the complex networks perform very similar regardless of size.
The large real-valued network outperforms the complex networks by 2.5 %
on RMS, while the small real-valued network underperforms by 2.5 % on
RMS. The panel in Figure <a class="reference external" href="#complex:fig:top_sr">[complex:fig:top_sr]</a>
shows a very smooth result. Despite the close score of the complex
networks, it appears that the complex-valued network restores more
high-frequency content. We can also see less smearing of discontinuities
in the larger complex network, particularly visible in the lower part
(1.2 s) at 6000 m offset, which is smeared to appear like a diffraction
in the smaller network. The large real-valued network shows good
reconstruction with minor smearing with higher amplitude fidelity in
areas like 1.1 s at 2000 m, however, some of the steeply dipping
artifacts are visible below the reflector packet between 0 m and 2000 m
offset.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="bottom-seismic-section">
<h3>&quot;Bottom&quot; seismic section</h3>
<p>The data marke as &quot;bottom&quot; in Figure <a class="reference external" href="#complex:fig:eval_seis">14.5</a>
contains a faulted anticline and relatively strong noise levels. The
small complex network in
Figure <a class="reference external" href="#complex:fig:bottom_sc">[complex:fig:bottom_sc]</a> reconstructs
a denoised image with good reconstruction of the visible
discontinuities. Some leakage of the reflector starting at 1.5 s across
discontinuities is visible. The real small network in
Figure <a class="reference external" href="#complex:fig:bottom_sr">[complex:fig:bottom_sr]</a> reconstructs
a strongly smoothed image, with some ringing below the main reflector,
which is not visible in the other reconstructions. The dipping reflector
at an offset of 16000 m is well reconstructed, however, it seems like
the reconstruction introduced ringing noise over the vertical image. The
large real-valued network in
Figure <a class="reference external" href="#complex:fig:bottom_br">[complex:fig:bottom_br]</a> performs
best quantitatively (cf. Table <a class="reference external" href="#tab:errors">14.3</a>). The
complex-valued large network in
Figure <a class="reference external" href="#complex:fig:bottom_bc">[complex:fig:bottom_bc]</a> does a
fairly good job at reconstructing the image, similar to the large
real-valued network. However, the amplitude reconstruction of
high-amplitude events particularly in the main reflector around 1.5 s is
showing.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="full-seismic-test-data">
<h3>Full seismic test data</h3>
<p>It is evident, that the small real-valued network does not match the
performance of the smaller complex-valued network, even less so when
compared to the large complex-valued network. We therefore compare the
large networks on the full seismic data.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>Overall, both networks return a smoothed image. The findings for the
strongly faulted sections in the &quot;top&quot; panel hold across the entire
faulted area around 1.1 s in
Figure <a class="reference external" href="#complex:fig:full">[complex:fig:full]</a>. The complex-valued
network does a better job at reconstructing faults and discontinuities.
The real-valued network is better at reconstructing high-amplitude
regions that appear dimmer in the complex-valued region. The
reconstruction of both networks seems adequately close to the ground
truth, with differences in the details. Quantitatively, the real-valued
network does the better reconstruction in Table <a class="reference external" href="#tab:errors">14.3</a>
with an improvement of 2.5 % over the large complex-valued network. The
FK domain shows a very similar reduction in noise in the sub 50 Hz band
in Figure <a class="reference external" href="#complex:fig:full_fk">[complex:fig:full_fk]</a>. All networks
introduce an increase of energy across all frequencies at wave-number
<span class="math">\(k=0~km^{-1}\)</span>. Additionally, a dimming of the frequencies around
<span class="math">\(k=2.5~km^{-1}\)</span> appears in all reconstructions, but is more
prominent in the large complex-valued network. The ground truth seismic
contains some scattered energy in the high-frequency mid-wavenumber
region, visible as &quot;diagonal stripes&quot;. These were attenuated in the
complex-valued network in
Figure <a class="reference external" href="#complex:fig:full_bc_fk">[complex:fig:full_bc_fk]</a>, but are
partially present in the real-valued reconstruction in
Figure <a class="reference external" href="#complex:fig:full_br_fk">[complex:fig:full_br_fk]</a>.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
</div>
<div class="section" id="discussion">
<h2>Discussion</h2>
<p>We evaluated the outputs of the real-valued and complex-valued neural
networks. All autoencoder outputs are blurred to different degrees and
denoised. The denoising effect of the seismic was most visible in the
frequency band below 50 Hz. Additionally, some scattered high-frequency
energy was attenuated by the networks.</p>
<p>The largest differences of the outputs in real-valued and complex-valued
networks can be observed in discontinuous areas. Particularly, the
faulted blocks in the top quarter and in the bottom center of the
seismic section show inconsistencies. The real-valued network smooths
over discontinuities and steep reflectors. Fault lines are imaged better
in the complex-valued network output.</p>
<p>In seismic data processing, including phase information stabilizes
discontinuities and disambiguates cycle-skipping in horizons. This could
be observed in the network performance and reconstruction. The increase
in performance of the real-valued networks was significant (7.0 % RMS),
while the complex-valued networks already had an acceptable performance
on the smaller network architecture (2.6 % RMS). We provide the
complex-valued networks with a bias towards learning phase information,
by providing the Hilbert transformed analytical trace, while the
real-valued network needs to learn this information implicitly from the
data itself. Considering, that during the training, the complex network
evaluates both the real-valued seismic, which we primarily care about in
addition to the complex-valued component, we can see how the losses in
Figure <a class="reference external" href="#complex:fig:loss">14.4</a> differ from the real-valued
networks.</p>
<p>The largest network with 790,945 trainable parameters quantitatively
performed the best on the reconstruction of the data. However, analysis
of the reconstructed seismic shows, that while the high-amplitude
regions are reconstructed to higher fidelity, discontinuous sections may
be smeared by the real-valued network. The real-valued network that was
matched to contain as many filters for the real-valued component of the
seismic as the large complex-valued network, did not perform well.
Furthermore, the smaller complex-valued network with 100,226 parameters
that contains as many filter maps as the real-valued network in total,
and half the trainable parameters, outperformed the smaller real-valued
network across all test cases.</p>
</div>
<div class="section" id="conclusion">
<span id="conclusion-1"></span><h2>Conclusion</h2>
<p>The inclusion of phase-information leads to a better representation of
seismic data in convolutional neural networks. Complex-valued networks
perform consistently, where real-valued networks have to learn
phase-representations through implicit correlation, which requires
larger networks. We show that complex trace information in deep neural
networks improves the imaging of discontinuities as well as steep
reflectors, particularly in chaotic seismic textures that are smoothed
by real-valued neural networks of the same size and level of
compression.</p>
<p>We show that convolutional neural networks can perform lossy compression
on seismic data, where the reconstruction error is dependent on both
network architecture and implementation details, like providing explicit
phase information. During this compression, noise and scattered energy
get attenuated. The real-valued network is prone to introduce steeply
dipping artifacts in the reconstruction and is matched by complex-valued
networks half the size with twice the amount of compression. This is
particularly interesting in the light of the complex complement of the
data being derived from the real-valued data through a Hilbert
transform, which should have been possible to approximate by a neural
network.</p>
<p>The stabilization of the reconstruction can be useful in other seismic
applications. While automatic seismic interpretation may benefit from
the inclusion of information on discontinuities, we see the main
application to be lossy seismic compression. The open source tool
developed to make this research possible, enables further research and
development of complex-valued solutions to non-stationary physics
problems that benefit from explicit phase information.</p>
<p>This research also shows that a change as small as 2.5 % in RMS can
change the reconstruction from being acceptable to very smeared to a
geoscientist. This touches on the fact that better metrics to evaluate
computer vision tasks in geoscience are necessary. Additionally, these
tasks have to be noise-robust and, while amplitude-preserving, be robust
against outliers. Moreover, more research in the frequency dimming of
bands in the network reconstruction is necessary.</p>
<p>Overall, the computational memory footprint of the complex convolution
is higher than real-valued convolutional neural networks comparing
singular convolutional operations. A significant increase in depth and
width of networks to obtain an acceptable result in real-valued neural
network to implicitly learn the phase information is necessary. The
complex-valued networks an 8<sup>th</sup> of the size already performs
well, suggesting that domains where a significant part pf the
information is in the phase of signals, could benefit from applying
complex convolutional networks.</p>
</div>
<div class="section" id="acknowledgments">
<span id="acknowledgments-1"></span><h2>Acknowledgments</h2>
<p>We thank Andrew Ferlitsch for his valuable insights. The research
leading to these results has received funding from the Danish
Hydrocarbon Research and Technology Centre under the Advanced Water
Flooding program. We thank DTU Compute for access to the GPU Cluster.</p>
</div>
</div>
<div class="section" id="contributions-of-this-study">
<span id="contributions-of-this-study-3"></span><h1>Contributions of this Study</h1>
<p>This chapter and Jesper Sören Dramsch, Lüthje, and Christensen (2019)
investigate the application of complex trace analysis to cnns. It uses
lossy compression to measure the reconstruction error and therefore, the
informational content in complex-valued nns. We were able to show that
networks containing phase information in the complex complement of data
reduce the error as compared to real-valued networks. Moreover, the code
to reproduce the findings in this paper (Jesper Sören Dramsch 2019b), as
well as, a standalone Python library for complex-valued cnns in
tensorflow has been made available as foss (Jesper Sören Dramsch and
Contributors 2019).</p>
</div>
